bash launch/attack-transfer-18.sh 0 mean 10 1 3

==> Resuming from checkpoint for DPN92..
==> Resuming from checkpoint for SENet18..
==> Resuming from checkpoint for ResNet50..
==> Resuming from checkpoint for ResNeXt29_2x64d..
==> Resuming from checkpoint for GoogLeNet..
==> Resuming from checkpoint for MobileNetV2..
==> Resuming from checkpoint for DPN92..
==> Resuming from checkpoint for SENet18..
==> Resuming from checkpoint for ResNet50..
==> Resuming from checkpoint for ResNeXt29_2x64d..
==> Resuming from checkpoint for GoogLeNet..
==> Resuming from checkpoint for MobileNetV2..
==> Resuming from checkpoint for DPN92..
==> Resuming from checkpoint for SENet18..
==> Resuming from checkpoint for ResNet50..
==> Resuming from checkpoint for ResNeXt29_2x64d..
==> Resuming from checkpoint for GoogLeNet..
==> Resuming from checkpoint for MobileNetV2..
subs nets, effective num: 18
Loading the victims networks
==> Resuming from checkpoint for DPN92..
==> Resuming from checkpoint for SENet18..
==> Resuming from checkpoint for ResNet50..
==> Resuming from checkpoint for ResNeXt29_2x64d..
==> Resuming from checkpoint for GoogLeNet..
==> Resuming from checkpoint for MobileNetV2..
==> Resuming from checkpoint for ResNet18..
==> Resuming from checkpoint for DenseNet121..
Namespace(chk_path='attack-results-10poisons/100-overlap/linear-transfer-learning', chk_subdir='poisons', device='cuda', dset_path='datasets', end2end=False, eval_poison_path='', gpu='0', lr_decay_epoch=[30, 45], mode='mean', model_resume_path='model-chks', nearest=False, net_repeat=1, num_per_class=50, original_grad=True, poison_decay_ites=[], poison_decay_ratio=0.1, poison_epsilon=0.1, poison_ites=4000, poison_label=8, poison_lr=0.04, poison_momentum=0.9, poison_num=3, poison_opt='adam', resume_poison_ite=0, retrain_bsize=64, retrain_epochs=60, retrain_lr=0.1, retrain_momentum=0.9, retrain_opt='adam', retrain_wd=0, subs_chk_name=['ckpt-%s-4800-dp0.200-droplayer0.000-seed1226.t7', 'ckpt-%s-4800-dp0.250-droplayer0.000-seed1226.t7', 'ckpt-%s-4800-dp0.300-droplayer0.000.t7'], subs_dp=[0.2, 0.25, 0.3], subset_group=0, substitute_nets=['DPN92', 'SENet18', 'ResNet50', 'ResNeXt29_2x64d', 'GoogLeNet', 'MobileNetV2'], target_dset='cifar10', target_index=10, target_label=6, target_net=['DPN92', 'SENet18', 'ResNet50', 'ResNeXt29_2x64d', 'GoogLeNet', 'MobileNetV2', 'ResNet18', 'DenseNet121'], test_chk_name='ckpt-%s-4800.t7', tol=1e-06, train_data_path='datasets/CIFAR10_TRAIN_Split.pth')
Path: attack-results-10poisons/100-overlap/linear-transfer-learning/mean/4000/10
Selected base image indices: [213, 225, 227]
/home/pengkai/anaconda3/envs/palearn/lib/python3.7/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
 2022-02-12 20:38:33 Iteration 0         Training Loss: 1.117e+00        Loss in Target Net: 3.920e-01    
 2022-02-12 20:39:01 Iteration 50        Training Loss: 9.214e-02        Loss in Target Net: 7.114e-03    
 2022-02-12 20:39:28 Iteration 100       Training Loss: 7.862e-02        Loss in Target Net: 8.241e-03    
 2022-02-12 20:39:55 Iteration 150       Training Loss: 8.322e-02        Loss in Target Net: 7.159e-03    
 2022-02-12 20:40:21 Iteration 200       Training Loss: 7.815e-02        Loss in Target Net: 7.514e-03    
 2022-02-12 20:40:49 Iteration 250       Training Loss: 7.268e-02        Loss in Target Net: 4.651e-03    
 2022-02-12 20:41:18 Iteration 300       Training Loss: 8.216e-02        Loss in Target Net: 5.159e-03    
 2022-02-12 20:41:48 Iteration 350       Training Loss: 6.830e-02        Loss in Target Net: 4.516e-03    
 2022-02-12 20:42:15 Iteration 400       Training Loss: 7.835e-02        Loss in Target Net: 7.107e-03    
 2022-02-12 20:42:42 Iteration 450       Training Loss: 6.831e-02        Loss in Target Net: 4.477e-03    
 2022-02-12 20:43:09 Iteration 500       Training Loss: 7.247e-02        Loss in Target Net: 8.156e-03    
 2022-02-12 20:43:37 Iteration 550       Training Loss: 7.044e-02        Loss in Target Net: 8.835e-03    
 2022-02-12 20:44:04 Iteration 600       Training Loss: 6.482e-02        Loss in Target Net: 4.143e-03    
 2022-02-12 20:44:30 Iteration 650       Training Loss: 7.238e-02        Loss in Target Net: 6.844e-03    
 2022-02-12 20:44:57 Iteration 700       Training Loss: 7.330e-02        Loss in Target Net: 9.224e-03    
 2022-02-12 20:45:24 Iteration 750       Training Loss: 7.125e-02        Loss in Target Net: 8.119e-03    
 2022-02-12 20:45:51 Iteration 800       Training Loss: 7.264e-02        Loss in Target Net: 9.612e-03    
 2022-02-12 20:46:18 Iteration 850       Training Loss: 7.107e-02        Loss in Target Net: 6.425e-03    
 2022-02-12 20:46:45 Iteration 900       Training Loss: 7.946e-02        Loss in Target Net: 1.946e-02    
 2022-02-12 20:47:12 Iteration 950       Training Loss: 6.733e-02        Loss in Target Net: 6.929e-03    
 2022-02-12 20:47:39 Iteration 1000      Training Loss: 7.621e-02        Loss in Target Net: 1.027e-02    
 2022-02-12 20:48:05 Iteration 1050      Training Loss: 7.171e-02        Loss in Target Net: 1.021e-02    
 2022-02-12 20:48:32 Iteration 1100      Training Loss: 7.684e-02        Loss in Target Net: 5.621e-03    
 2022-02-12 20:48:58 Iteration 1150      Training Loss: 7.495e-02        Loss in Target Net: 6.263e-03    
 2022-02-12 20:49:26 Iteration 1200      Training Loss: 7.059e-02        Loss in Target Net: 1.209e-02    
 2022-02-12 20:49:53 Iteration 1250      Training Loss: 7.671e-02        Loss in Target Net: 8.378e-03    
 2022-02-12 20:50:21 Iteration 1300      Training Loss: 7.130e-02        Loss in Target Net: 1.183e-02    
 2022-02-12 20:50:48 Iteration 1350      Training Loss: 7.194e-02        Loss in Target Net: 4.874e-03    
 2022-02-12 20:51:14 Iteration 1400      Training Loss: 7.498e-02        Loss in Target Net: 6.866e-03    
 2022-02-12 20:51:43 Iteration 1450      Training Loss: 7.112e-02        Loss in Target Net: 1.281e-02    
 2022-02-12 20:52:10 Iteration 1500      Training Loss: 7.667e-02        Loss in Target Net: 1.477e-02    
 2022-02-12 20:52:37 Iteration 1550      Training Loss: 6.840e-02        Loss in Target Net: 8.623e-03    
 2022-02-12 20:53:04 Iteration 1600      Training Loss: 7.439e-02        Loss in Target Net: 8.186e-03    
 2022-02-12 20:53:31 Iteration 1650      Training Loss: 7.395e-02        Loss in Target Net: 7.248e-03    
 2022-02-12 20:53:58 Iteration 1700      Training Loss: 7.084e-02        Loss in Target Net: 4.722e-03    
 2022-02-12 20:54:25 Iteration 1750      Training Loss: 6.689e-02        Loss in Target Net: 8.068e-03    
 2022-02-12 20:54:52 Iteration 1800      Training Loss: 7.547e-02        Loss in Target Net: 1.187e-02    
 2022-02-12 20:55:18 Iteration 1850      Training Loss: 6.781e-02        Loss in Target Net: 1.008e-02    
 2022-02-12 20:55:45 Iteration 1900      Training Loss: 6.590e-02        Loss in Target Net: 5.450e-03    
 2022-02-12 20:56:12 Iteration 1950      Training Loss: 7.984e-02        Loss in Target Net: 5.216e-03    
 2022-02-12 20:56:38 Iteration 2000      Training Loss: 7.006e-02        Loss in Target Net: 5.458e-03    
 2022-02-12 20:57:05 Iteration 2050      Training Loss: 7.073e-02        Loss in Target Net: 9.459e-03    
 2022-02-12 20:57:31 Iteration 2100      Training Loss: 7.180e-02        Loss in Target Net: 6.232e-03    
 2022-02-12 20:57:58 Iteration 2150      Training Loss: 7.461e-02        Loss in Target Net: 7.587e-03    
 2022-02-12 20:58:24 Iteration 2200      Training Loss: 6.903e-02        Loss in Target Net: 7.490e-03    
 2022-02-12 20:58:51 Iteration 2250      Training Loss: 7.564e-02        Loss in Target Net: 3.694e-03    
 2022-02-12 20:59:17 Iteration 2300      Training Loss: 7.719e-02        Loss in Target Net: 7.215e-03    
 2022-02-12 20:59:44 Iteration 2350      Training Loss: 7.729e-02        Loss in Target Net: 4.861e-03    
 2022-02-12 21:00:11 Iteration 2400      Training Loss: 6.877e-02        Loss in Target Net: 9.182e-03    
 2022-02-12 21:00:37 Iteration 2450      Training Loss: 7.241e-02        Loss in Target Net: 1.119e-02    
 2022-02-12 21:01:03 Iteration 2500      Training Loss: 7.435e-02        Loss in Target Net: 5.113e-03    
 2022-02-12 21:01:30 Iteration 2550      Training Loss: 7.546e-02        Loss in Target Net: 7.091e-03    
 2022-02-12 21:01:57 Iteration 2600      Training Loss: 7.237e-02        Loss in Target Net: 5.603e-03    
 2022-02-12 21:02:23 Iteration 2650      Training Loss: 6.959e-02        Loss in Target Net: 7.642e-03    
 2022-02-12 21:02:49 Iteration 2700      Training Loss: 7.633e-02        Loss in Target Net: 8.203e-03    
 2022-02-12 21:03:16 Iteration 2750      Training Loss: 7.177e-02        Loss in Target Net: 4.878e-03    
 2022-02-12 21:03:42 Iteration 2800      Training Loss: 6.935e-02        Loss in Target Net: 4.009e-03    
 2022-02-12 21:04:08 Iteration 2850      Training Loss: 7.435e-02        Loss in Target Net: 6.123e-03    
 2022-02-12 21:04:34 Iteration 2900      Training Loss: 6.292e-02        Loss in Target Net: 4.365e-03    
 2022-02-12 21:05:00 Iteration 2950      Training Loss: 6.900e-02        Loss in Target Net: 8.711e-03    
 2022-02-12 21:05:26 Iteration 3000      Training Loss: 7.165e-02        Loss in Target Net: 5.530e-03    
 2022-02-12 21:05:52 Iteration 3050      Training Loss: 6.912e-02        Loss in Target Net: 6.321e-03    
 2022-02-12 21:06:18 Iteration 3100      Training Loss: 7.257e-02        Loss in Target Net: 6.050e-03    
 2022-02-12 21:06:44 Iteration 3150      Training Loss: 6.966e-02        Loss in Target Net: 4.121e-03    
 2022-02-12 21:07:10 Iteration 3200      Training Loss: 7.347e-02        Loss in Target Net: 6.326e-03    
 2022-02-12 21:07:36 Iteration 3250      Training Loss: 6.659e-02        Loss in Target Net: 6.947e-03    
 2022-02-12 21:08:02 Iteration 3300      Training Loss: 7.258e-02        Loss in Target Net: 4.961e-03    
 2022-02-12 21:08:28 Iteration 3350      Training Loss: 7.037e-02        Loss in Target Net: 4.728e-03    
 2022-02-12 21:08:53 Iteration 3400      Training Loss: 7.368e-02        Loss in Target Net: 7.602e-03    
 2022-02-12 21:09:19 Iteration 3450      Training Loss: 7.495e-02        Loss in Target Net: 4.671e-03    
 2022-02-12 21:09:45 Iteration 3500      Training Loss: 6.600e-02        Loss in Target Net: 3.728e-03    
 2022-02-12 21:10:11 Iteration 3550      Training Loss: 6.244e-02        Loss in Target Net: 5.745e-03    
 2022-02-12 21:10:38 Iteration 3600      Training Loss: 7.311e-02        Loss in Target Net: 3.909e-03    
 2022-02-12 21:11:05 Iteration 3650      Training Loss: 7.129e-02        Loss in Target Net: 9.329e-03    
 2022-02-12 21:11:30 Iteration 3700      Training Loss: 7.667e-02        Loss in Target Net: 7.476e-03    
 2022-02-12 21:11:56 Iteration 3750      Training Loss: 7.400e-02        Loss in Target Net: 3.393e-03    
 2022-02-12 21:12:22 Iteration 3800      Training Loss: 7.372e-02        Loss in Target Net: 9.188e-03    
 2022-02-12 21:12:48 Iteration 3850      Training Loss: 6.943e-02        Loss in Target Net: 7.898e-03    
 2022-02-12 21:13:14 Iteration 3900      Training Loss: 6.820e-02        Loss in Target Net: 6.152e-03    
 2022-02-12 21:13:40 Iteration 3950      Training Loss: 7.441e-02        Loss in Target Net: 8.772e-03    
 2022-02-12 21:14:06 Iteration 3999      Training Loss: 6.725e-02        Loss in Target Net: 3.669e-03    
Evaluating against victims networks
DPN92
Using Adam for retraining
Files already downloaded and verified
2022-02-12 21:14:12, Epoch 0, Iteration 7, loss 1.106 (3.136), acc 88.462 (72.000)
2022-02-12 21:14:12, Epoch 30, Iteration 7, loss 0.001 (0.269), acc 100.000 (96.800)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[20.514416, -10.541246, -41.64176, 8.457752, -65.74235, -2.0195444, 49.540432, -57.66881, 44.853935, -159.72324], Poisons' Predictions:[8, 8, 8]
2022-02-12 21:14:18 Epoch 59, Val iteration 0, acc 92.000 (92.000)
2022-02-12 21:14:31 Epoch 59, Val iteration 19, acc 91.400 (92.150)
* Prec: 92.1500015258789
--------
SENet18
Using Adam for retraining
Files already downloaded and verified
2022-02-12 21:14:33, Epoch 0, Iteration 7, loss 0.425 (0.760), acc 86.538 (88.200)
2022-02-12 21:14:34, Epoch 30, Iteration 7, loss 0.067 (0.156), acc 98.077 (96.200)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[2.5640247, 6.768731, -13.737491, -4.091199, 10.695689, -7.7122464, 26.099133, -5.1591444, 15.75916, -19.469524], Poisons' Predictions:[6, 8, 6]
2022-02-12 21:14:35 Epoch 59, Val iteration 0, acc 92.200 (92.200)
2022-02-12 21:14:38 Epoch 59, Val iteration 19, acc 93.000 (91.420)
* Prec: 91.42000160217285
--------
ResNet50
Using Adam for retraining
Files already downloaded and verified
2022-02-12 21:14:41, Epoch 0, Iteration 7, loss 0.000 (1.020), acc 100.000 (88.200)
2022-02-12 21:14:42, Epoch 30, Iteration 7, loss 0.000 (0.061), acc 100.000 (99.400)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-27.227507, -1.566699, -24.57563, 1.2048292, -155.23502, -34.1761, 33.226845, -15.974679, 34.50284, -21.825235], Poisons' Predictions:[8, 8, 8]
2022-02-12 21:14:43 Epoch 59, Val iteration 0, acc 93.400 (93.400)
2022-02-12 21:14:50 Epoch 59, Val iteration 19, acc 94.600 (93.950)
* Prec: 93.9500015258789
--------
ResNeXt29_2x64d
Using Adam for retraining
Files already downloaded and verified
2022-02-12 21:14:53, Epoch 0, Iteration 7, loss 1.579 (2.077), acc 78.846 (75.800)
2022-02-12 21:14:53, Epoch 30, Iteration 7, loss 0.162 (0.054), acc 96.154 (98.000)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-31.281624, 8.116741, -7.0824995, 7.5658717, -77.724915, -29.727282, 30.75557, -32.810204, 25.406199, -32.134266], Poisons' Predictions:[8, 8, 8]
2022-02-12 21:14:55 Epoch 59, Val iteration 0, acc 93.000 (93.000)
2022-02-12 21:15:02 Epoch 59, Val iteration 19, acc 93.400 (93.150)
* Prec: 93.1500015258789
--------
GoogLeNet
Using Adam for retraining
Files already downloaded and verified
2022-02-12 21:15:05, Epoch 0, Iteration 7, loss 0.539 (0.459), acc 86.538 (87.800)
2022-02-12 21:15:05, Epoch 30, Iteration 7, loss 0.037 (0.066), acc 98.077 (96.200)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-9.569584, -6.152125, -6.2856503, -2.0330508, -15.858806, -3.8535476, 11.693947, -4.7848377, 9.231466, -24.99256], Poisons' Predictions:[8, 8, 8]
2022-02-12 21:15:08 Epoch 59, Val iteration 0, acc 91.600 (91.600)
2022-02-12 21:15:16 Epoch 59, Val iteration 19, acc 92.200 (92.080)
* Prec: 92.08000106811524
--------
MobileNetV2
Using Adam for retraining
Files already downloaded and verified
2022-02-12 21:15:19, Epoch 0, Iteration 7, loss 2.675 (3.419), acc 73.077 (62.600)
2022-02-12 21:15:19, Epoch 30, Iteration 7, loss 0.263 (0.336), acc 94.231 (93.000)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[0.31590965, 7.8958807, -9.868835, 12.565987, -17.290293, -10.786609, 31.371847, -27.971872, 19.932178, -20.508776], Poisons' Predictions:[8, 8, 6]
2022-02-12 21:15:20 Epoch 59, Val iteration 0, acc 89.000 (89.000)
2022-02-12 21:15:24 Epoch 59, Val iteration 19, acc 88.400 (87.230)
* Prec: 87.23000144958496
--------
ResNet18
Using Adam for retraining
Files already downloaded and verified
2022-02-12 21:15:26, Epoch 0, Iteration 7, loss 0.866 (0.694), acc 92.308 (86.200)
2022-02-12 21:15:27, Epoch 30, Iteration 7, loss 0.000 (0.018), acc 100.000 (99.600)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-44.11153, -14.277241, -14.360122, 5.574217, -29.282358, -4.434775, 13.513442, -13.223865, 11.7778015, -24.518158], Poisons' Predictions:[8, 8, 8]
2022-02-12 21:15:27 Epoch 59, Val iteration 0, acc 93.600 (93.600)
2022-02-12 21:15:30 Epoch 59, Val iteration 19, acc 93.600 (92.800)
* Prec: 92.80000076293945
--------
DenseNet121
Using Adam for retraining
Files already downloaded and verified
2022-02-12 21:15:33, Epoch 0, Iteration 7, loss 0.520 (0.420), acc 90.385 (91.800)
2022-02-12 21:15:34, Epoch 30, Iteration 7, loss 0.006 (0.005), acc 100.000 (100.000)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-5.00574, -11.511604, -8.009214, -1.6919092, -1.0447308, -2.9285917, 10.106577, -27.396906, 11.139143, -17.746832], Poisons' Predictions:[8, 8, 8]
2022-02-12 21:15:36 Epoch 59, Val iteration 0, acc 93.800 (93.800)
2022-02-12 21:15:43 Epoch 59, Val iteration 19, acc 92.800 (93.090)
* Prec: 93.09000167846679
--------
------SUMMARY------
TIME ELAPSED (mins): 35
TARGET INDEX: 10
DPN92 0
SENet18 0
ResNet50 1
ResNeXt29_2x64d 0
GoogLeNet 0
MobileNetV2 0
ResNet18 0
DenseNet121 1