Namespace(chk_path='chk-black-ourmean/', chk_subdir='poisons', device='cuda', dset_path='datasets', end2end=False, eval_poison_path='', gpu='2', lr_decay_epoch=[30, 45], mode='mean', model_resume_path='model-chks', nearest=False, net_repeat=3, num_per_class=50, original_grad=True, poison_decay_ites=[], poison_decay_ratio=0.1, poison_epsilon=0.1, poison_ites=4000, poison_label=8, poison_lr=0.04, poison_momentum=0.9, poison_num=5, poison_opt='adam', resume_poison_ite=0, retrain_bsize=64, retrain_epochs=60, retrain_lr=0.1, retrain_momentum=0.9, retrain_opt='adam', retrain_wd=0, subs_chk_name=['ckpt-%s-4800-dp0.200-droplayer0.000-seed1226.t7', 'ckpt-%s-4800-dp0.250-droplayer0.000-seed1226.t7', 'ckpt-%s-4800-dp0.300-droplayer0.000.t7'], subs_dp=[0.2, 0.25, 0.3], subset_group=0, substitute_nets=['DPN92', 'SENet18', 'ResNet50', 'ResNeXt29_2x64d', 'GoogLeNet', 'MobileNetV2'], target_index=38, target_label=6, target_net=['DPN92', 'SENet18', 'ResNet50', 'ResNeXt29_2x64d', 'GoogLeNet', 'MobileNetV2', 'ResNet18', 'DenseNet121'], test_chk_name='ckpt-%s-4800.t7', tol=1e-06, train_data_path='datasets/CIFAR10_TRAIN_Split.pth')
Path: chk-black-ourmean/mean-3Repeat/4000/38
Selected base image indices: [213, 225, 227, 247, 249]
 2020-02-05 02:25:42 Iteration 0 	 Training Loss: 1.059e+00 	 Loss in Target Net: 3.628e-01	  
 2020-02-05 02:26:49 Iteration 50 	 Training Loss: 7.953e-02 	 Loss in Target Net: 1.158e-02	  
 2020-02-05 02:27:57 Iteration 100 	 Training Loss: 6.995e-02 	 Loss in Target Net: 9.150e-03	  
 2020-02-05 02:29:03 Iteration 150 	 Training Loss: 6.722e-02 	 Loss in Target Net: 1.351e-02	  
 2020-02-05 02:30:10 Iteration 200 	 Training Loss: 6.072e-02 	 Loss in Target Net: 1.092e-02	  
 2020-02-05 02:31:17 Iteration 250 	 Training Loss: 6.162e-02 	 Loss in Target Net: 1.614e-02	  
 2020-02-05 02:32:22 Iteration 300 	 Training Loss: 6.286e-02 	 Loss in Target Net: 1.664e-02	  
 2020-02-05 02:33:28 Iteration 350 	 Training Loss: 5.998e-02 	 Loss in Target Net: 1.406e-02	  
 2020-02-05 02:34:34 Iteration 400 	 Training Loss: 6.167e-02 	 Loss in Target Net: 1.164e-02	  
 2020-02-05 02:35:39 Iteration 450 	 Training Loss: 5.466e-02 	 Loss in Target Net: 1.036e-02	  
 2020-02-05 02:36:59 Iteration 500 	 Training Loss: 5.880e-02 	 Loss in Target Net: 1.515e-02	  
 2020-02-05 02:38:04 Iteration 550 	 Training Loss: 5.731e-02 	 Loss in Target Net: 1.273e-02	  
 2020-02-05 02:39:12 Iteration 600 	 Training Loss: 6.096e-02 	 Loss in Target Net: 1.204e-02	  
 2020-02-05 02:40:22 Iteration 650 	 Training Loss: 5.964e-02 	 Loss in Target Net: 1.412e-02	  
 2020-02-05 02:41:31 Iteration 700 	 Training Loss: 5.519e-02 	 Loss in Target Net: 1.073e-02	  
 2020-02-05 02:42:36 Iteration 750 	 Training Loss: 6.001e-02 	 Loss in Target Net: 6.938e-03	  
 2020-02-05 02:43:42 Iteration 800 	 Training Loss: 5.603e-02 	 Loss in Target Net: 9.692e-03	  
 2020-02-05 02:44:48 Iteration 850 	 Training Loss: 5.963e-02 	 Loss in Target Net: 1.412e-02	  
 2020-02-05 02:45:54 Iteration 900 	 Training Loss: 5.838e-02 	 Loss in Target Net: 1.453e-02	  
 2020-02-05 02:46:57 Iteration 950 	 Training Loss: 5.996e-02 	 Loss in Target Net: 1.129e-02	  
 2020-02-05 02:48:01 Iteration 1000 	 Training Loss: 5.806e-02 	 Loss in Target Net: 8.389e-03	  
 2020-02-05 02:49:06 Iteration 1050 	 Training Loss: 5.649e-02 	 Loss in Target Net: 1.203e-02	  
 2020-02-05 02:50:09 Iteration 1100 	 Training Loss: 5.898e-02 	 Loss in Target Net: 8.868e-03	  
 2020-02-05 02:51:13 Iteration 1150 	 Training Loss: 5.659e-02 	 Loss in Target Net: 1.390e-02	  
 2020-02-05 02:52:17 Iteration 1200 	 Training Loss: 5.584e-02 	 Loss in Target Net: 1.191e-02	  
 2020-02-05 02:53:20 Iteration 1250 	 Training Loss: 6.229e-02 	 Loss in Target Net: 2.262e-02	  
 2020-02-05 02:54:24 Iteration 1300 	 Training Loss: 5.571e-02 	 Loss in Target Net: 1.836e-02	  
 2020-02-05 02:55:28 Iteration 1350 	 Training Loss: 5.881e-02 	 Loss in Target Net: 2.256e-02	  
 2020-02-05 02:56:32 Iteration 1400 	 Training Loss: 5.585e-02 	 Loss in Target Net: 1.599e-02	  
 2020-02-05 02:57:36 Iteration 1450 	 Training Loss: 5.564e-02 	 Loss in Target Net: 2.122e-02	  
 2020-02-05 02:58:40 Iteration 1500 	 Training Loss: 5.564e-02 	 Loss in Target Net: 2.620e-02	  
 2020-02-05 02:59:44 Iteration 1550 	 Training Loss: 5.486e-02 	 Loss in Target Net: 1.795e-02	  
 2020-02-05 03:00:48 Iteration 1600 	 Training Loss: 5.595e-02 	 Loss in Target Net: 1.349e-02	  
 2020-02-05 03:01:52 Iteration 1650 	 Training Loss: 5.585e-02 	 Loss in Target Net: 1.927e-02	  
 2020-02-05 03:02:56 Iteration 1700 	 Training Loss: 5.618e-02 	 Loss in Target Net: 1.286e-02	  
 2020-02-05 03:04:00 Iteration 1750 	 Training Loss: 5.652e-02 	 Loss in Target Net: 2.258e-02	  
 2020-02-05 03:05:04 Iteration 1800 	 Training Loss: 5.716e-02 	 Loss in Target Net: 2.184e-02	  
 2020-02-05 03:06:08 Iteration 1850 	 Training Loss: 5.629e-02 	 Loss in Target Net: 1.837e-02	  
 2020-02-05 03:07:11 Iteration 1900 	 Training Loss: 5.824e-02 	 Loss in Target Net: 1.904e-02	  
 2020-02-05 03:08:15 Iteration 1950 	 Training Loss: 5.356e-02 	 Loss in Target Net: 2.120e-02	  
 2020-02-05 03:09:20 Iteration 2000 	 Training Loss: 6.021e-02 	 Loss in Target Net: 2.215e-02	  
 2020-02-05 03:10:24 Iteration 2050 	 Training Loss: 5.716e-02 	 Loss in Target Net: 2.080e-02	  
 2020-02-05 03:11:27 Iteration 2100 	 Training Loss: 5.583e-02 	 Loss in Target Net: 2.246e-02	  
 2020-02-05 03:12:31 Iteration 2150 	 Training Loss: 5.426e-02 	 Loss in Target Net: 2.112e-02	  
 2020-02-05 03:13:35 Iteration 2200 	 Training Loss: 5.502e-02 	 Loss in Target Net: 2.559e-02	  
 2020-02-05 03:14:39 Iteration 2250 	 Training Loss: 5.570e-02 	 Loss in Target Net: 1.981e-02	  
 2020-02-05 03:15:52 Iteration 2300 	 Training Loss: 5.769e-02 	 Loss in Target Net: 2.095e-02	  
 2020-02-05 03:16:58 Iteration 2350 	 Training Loss: 5.515e-02 	 Loss in Target Net: 2.719e-02	  
 2020-02-05 03:18:04 Iteration 2400 	 Training Loss: 5.538e-02 	 Loss in Target Net: 2.318e-02	  
 2020-02-05 03:19:11 Iteration 2450 	 Training Loss: 5.824e-02 	 Loss in Target Net: 2.270e-02	  
 2020-02-05 03:20:17 Iteration 2500 	 Training Loss: 5.519e-02 	 Loss in Target Net: 1.757e-02	  
 2020-02-05 03:21:24 Iteration 2550 	 Training Loss: 5.869e-02 	 Loss in Target Net: 1.917e-02	  
 2020-02-05 03:22:32 Iteration 2600 	 Training Loss: 5.591e-02 	 Loss in Target Net: 2.198e-02	  
 2020-02-05 03:23:56 Iteration 2650 	 Training Loss: 5.881e-02 	 Loss in Target Net: 1.198e-02	  
 2020-02-05 03:25:03 Iteration 2700 	 Training Loss: 5.721e-02 	 Loss in Target Net: 2.056e-02	  
 2020-02-05 03:26:10 Iteration 2750 	 Training Loss: 5.526e-02 	 Loss in Target Net: 2.183e-02	  
 2020-02-05 03:27:16 Iteration 2800 	 Training Loss: 5.918e-02 	 Loss in Target Net: 1.810e-02	  
 2020-02-05 03:28:23 Iteration 2850 	 Training Loss: 5.540e-02 	 Loss in Target Net: 1.699e-02	  
 2020-02-05 03:29:30 Iteration 2900 	 Training Loss: 5.734e-02 	 Loss in Target Net: 2.414e-02	  
 2020-02-05 03:30:36 Iteration 2950 	 Training Loss: 5.696e-02 	 Loss in Target Net: 1.957e-02	  
 2020-02-05 03:31:43 Iteration 3000 	 Training Loss: 5.611e-02 	 Loss in Target Net: 2.577e-02	  
 2020-02-05 03:32:49 Iteration 3050 	 Training Loss: 5.865e-02 	 Loss in Target Net: 2.789e-02	  
 2020-02-05 03:33:57 Iteration 3100 	 Training Loss: 5.751e-02 	 Loss in Target Net: 2.300e-02	  
 2020-02-05 03:35:02 Iteration 3150 	 Training Loss: 6.016e-02 	 Loss in Target Net: 2.121e-02	  
 2020-02-05 03:36:09 Iteration 3200 	 Training Loss: 5.809e-02 	 Loss in Target Net: 1.711e-02	  
 2020-02-05 03:37:20 Iteration 3250 	 Training Loss: 5.943e-02 	 Loss in Target Net: 1.737e-02	  
 2020-02-05 03:38:34 Iteration 3300 	 Training Loss: 5.466e-02 	 Loss in Target Net: 1.982e-02	  
 2020-02-05 03:39:50 Iteration 3350 	 Training Loss: 5.700e-02 	 Loss in Target Net: 1.884e-02	  
 2020-02-05 03:41:06 Iteration 3400 	 Training Loss: 5.273e-02 	 Loss in Target Net: 2.153e-02	  
 2020-02-05 03:42:34 Iteration 3450 	 Training Loss: 5.635e-02 	 Loss in Target Net: 2.062e-02	  
 2020-02-05 03:44:02 Iteration 3500 	 Training Loss: 5.767e-02 	 Loss in Target Net: 1.715e-02	  
 2020-02-05 03:45:35 Iteration 3550 	 Training Loss: 5.823e-02 	 Loss in Target Net: 1.704e-02	  
 2020-02-05 03:47:01 Iteration 3600 	 Training Loss: 5.706e-02 	 Loss in Target Net: 1.671e-02	  
 2020-02-05 03:48:29 Iteration 3650 	 Training Loss: 5.620e-02 	 Loss in Target Net: 1.797e-02	  
 2020-02-05 03:49:55 Iteration 3700 	 Training Loss: 5.580e-02 	 Loss in Target Net: 1.435e-02	  
 2020-02-05 03:51:09 Iteration 3750 	 Training Loss: 5.422e-02 	 Loss in Target Net: 1.422e-02	  
 2020-02-05 03:52:12 Iteration 3800 	 Training Loss: 5.594e-02 	 Loss in Target Net: 1.511e-02	  
 2020-02-05 03:53:16 Iteration 3850 	 Training Loss: 4.987e-02 	 Loss in Target Net: 1.596e-02	  
 2020-02-05 03:54:19 Iteration 3900 	 Training Loss: 5.573e-02 	 Loss in Target Net: 1.472e-02	  
 2020-02-05 03:55:22 Iteration 3950 	 Training Loss: 5.714e-02 	 Loss in Target Net: 1.481e-02	  
 2020-02-05 03:56:25 Iteration 3999 	 Training Loss: 6.096e-02 	 Loss in Target Net: 1.651e-02	  
Evaluating against victims networks
DPN92
Using Adam for retraining
Files already downloaded and verified
2020-02-05 03:56:29, Epoch 0, Iteration 7, loss 1.432 (3.172), acc 90.385 (73.400)
2020-02-05 03:56:29, Epoch 30, Iteration 7, loss 0.097 (0.257), acc 98.077 (97.000)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[8.41297, -13.998116, -71.116325, -7.347003, -47.284546, -12.552094, 35.69831, -70.9286, 28.221546, -141.00374], Poisons' Predictions:[8, 8, 8, 8, 6]
2020-02-05 03:56:33 Epoch 59, Val iteration 0, acc 92.600 (92.600)
2020-02-05 03:56:41 Epoch 59, Val iteration 19, acc 92.600 (92.470)
* Prec: 92.47000198364258
--------
SENet18
Using Adam for retraining
Files already downloaded and verified
2020-02-05 03:56:43, Epoch 0, Iteration 7, loss 1.437 (0.997), acc 86.538 (89.200)
2020-02-05 03:56:43, Epoch 30, Iteration 7, loss 0.032 (0.142), acc 98.077 (97.000)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-7.7936645, -9.090751, -21.081196, -9.786541, 2.0612044, -17.78078, 21.605478, -20.47855, 22.222267, -18.763464], Poisons' Predictions:[8, 8, 8, 8, 6]
2020-02-05 03:56:44 Epoch 59, Val iteration 0, acc 91.200 (91.200)
2020-02-05 03:56:46 Epoch 59, Val iteration 19, acc 92.800 (90.940)
* Prec: 90.94000205993652
--------
ResNet50
Using Adam for retraining
Files already downloaded and verified
2020-02-05 03:56:48, Epoch 0, Iteration 7, loss 0.016 (1.602), acc 100.000 (85.000)
2020-02-05 03:56:48, Epoch 30, Iteration 7, loss 0.000 (0.066), acc 100.000 (98.400)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-100.92237, -40.22885, -19.7989, -12.982043, -26.677372, -66.26792, 17.936285, -26.469656, 21.91815, -45.851936], Poisons' Predictions:[8, 8, 6, 8, 8]
2020-02-05 03:56:50 Epoch 59, Val iteration 0, acc 92.000 (92.000)
2020-02-05 03:56:54 Epoch 59, Val iteration 19, acc 92.600 (92.410)
* Prec: 92.41000213623047
--------
ResNeXt29_2x64d
Using Adam for retraining
Files already downloaded and verified
2020-02-05 03:56:56, Epoch 0, Iteration 7, loss 1.217 (2.504), acc 86.538 (71.200)
2020-02-05 03:56:56, Epoch 30, Iteration 7, loss 0.283 (0.265), acc 94.231 (95.200)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-31.302135, -25.462196, -5.896141, 4.0874043, -55.6771, -30.742096, 20.335325, -21.442532, 8.526106, -26.714504], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-02-05 03:56:58 Epoch 59, Val iteration 0, acc 93.000 (93.000)
2020-02-05 03:57:02 Epoch 59, Val iteration 19, acc 92.200 (92.610)
* Prec: 92.6100025177002
--------
GoogLeNet
Using Adam for retraining
Files already downloaded and verified
2020-02-05 03:57:04, Epoch 0, Iteration 7, loss 0.368 (0.527), acc 88.462 (88.200)
2020-02-05 03:57:04, Epoch 30, Iteration 7, loss 0.057 (0.057), acc 96.154 (97.800)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-19.879673, -10.942613, -10.029453, -0.64080846, -2.7185576, -1.1421335, 10.227848, -5.781724, 8.455595, -14.471458], Poisons' Predictions:[8, 8, 8, 8, 6]
2020-02-05 03:57:07 Epoch 59, Val iteration 0, acc 90.600 (90.600)
2020-02-05 03:57:11 Epoch 59, Val iteration 19, acc 91.800 (91.880)
* Prec: 91.88000106811523
--------
MobileNetV2
Using Adam for retraining
Files already downloaded and verified
2020-02-05 03:57:14, Epoch 0, Iteration 7, loss 2.060 (3.691), acc 63.462 (60.400)
2020-02-05 03:57:14, Epoch 30, Iteration 7, loss 0.633 (0.261), acc 90.385 (92.600)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-1.6237879, -11.821387, -7.729097, 12.227432, -6.0516186, 0.8079572, 20.976753, -17.27689, 10.628138, -12.217862], Poisons' Predictions:[6, 8, 8, 8, 6]
2020-02-05 03:57:15 Epoch 59, Val iteration 0, acc 88.200 (88.200)
2020-02-05 03:57:17 Epoch 59, Val iteration 19, acc 89.200 (87.440)
* Prec: 87.44000244140625
--------
ResNet18
Using Adam for retraining
Files already downloaded and verified
2020-02-05 03:57:18, Epoch 0, Iteration 7, loss 1.135 (0.654), acc 86.538 (89.000)
2020-02-05 03:57:19, Epoch 30, Iteration 7, loss 0.087 (0.050), acc 94.231 (98.400)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-35.633392, -25.766155, -17.225037, -1.689805, -40.28736, -7.8535323, 10.229348, -24.701672, 9.686741, -48.882423], Poisons' Predictions:[6, 8, 8, 8, 8]
2020-02-05 03:57:19 Epoch 59, Val iteration 0, acc 93.800 (93.800)
2020-02-05 03:57:21 Epoch 59, Val iteration 19, acc 94.000 (92.800)
* Prec: 92.80000190734863
--------
DenseNet121
Using Adam for retraining
Files already downloaded and verified
2020-02-05 03:57:24, Epoch 0, Iteration 7, loss 0.228 (0.399), acc 98.077 (92.400)
2020-02-05 03:57:24, Epoch 30, Iteration 7, loss 0.003 (0.006), acc 100.000 (99.800)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-13.848338, -20.647055, -16.680758, -2.9105096, -5.8649163, -10.048145, 10.179584, -37.012665, 5.813298, -25.550718], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-02-05 03:57:26 Epoch 59, Val iteration 0, acc 93.600 (93.600)
2020-02-05 03:57:30 Epoch 59, Val iteration 19, acc 93.400 (92.870)
* Prec: 92.87000160217285
--------
------SUMMARY------
TIME ELAPSED (mins): 90
TARGET INDEX: 38
DPN92 0
SENet18 1
ResNet50 1
ResNeXt29_2x64d 0
GoogLeNet 0
MobileNetV2 0
ResNet18 0
DenseNet121 0
