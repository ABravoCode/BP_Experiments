Namespace(chk_path='chk-black-ourmean/', chk_subdir='poisons', device='cuda', dset_path='datasets', end2end=False, eval_poison_path='', gpu='0', lr_decay_epoch=[30, 45], mode='mean', model_resume_path='model-chks', nearest=False, net_repeat=3, num_per_class=50, original_grad=True, poison_decay_ites=[], poison_decay_ratio=0.1, poison_epsilon=0.1, poison_ites=4000, poison_label=8, poison_lr=0.04, poison_momentum=0.9, poison_num=5, poison_opt='adam', resume_poison_ite=0, retrain_bsize=64, retrain_epochs=60, retrain_lr=0.1, retrain_momentum=0.9, retrain_opt='adam', retrain_wd=0, subs_chk_name=['ckpt-%s-4800-dp0.200-droplayer0.000-seed1226.t7', 'ckpt-%s-4800-dp0.250-droplayer0.000-seed1226.t7', 'ckpt-%s-4800-dp0.300-droplayer0.000.t7'], subs_dp=[0.2, 0.25, 0.3], subset_group=0, substitute_nets=['DPN92', 'SENet18', 'ResNet50', 'ResNeXt29_2x64d', 'GoogLeNet', 'MobileNetV2'], target_index=8, target_label=6, target_net=['DPN92', 'SENet18', 'ResNet50', 'ResNeXt29_2x64d', 'GoogLeNet', 'MobileNetV2', 'ResNet18', 'DenseNet121'], test_chk_name='ckpt-%s-4800.t7', tol=1e-06, train_data_path='datasets/CIFAR10_TRAIN_Split.pth')
Path: chk-black-ourmean/mean-3Repeat/4000/8
Selected base image indices: [213, 225, 227, 247, 249]
 2020-01-31 05:08:10 Iteration 0 	 Training Loss: 1.021e+00 	 Loss in Target Net: 3.699e-01	  
 2020-01-31 05:09:23 Iteration 50 	 Training Loss: 9.299e-02 	 Loss in Target Net: 1.305e-02	  
 2020-01-31 05:10:35 Iteration 100 	 Training Loss: 8.241e-02 	 Loss in Target Net: 7.953e-03	  
 2020-01-31 05:11:47 Iteration 150 	 Training Loss: 7.603e-02 	 Loss in Target Net: 1.355e-02	  
 2020-01-31 05:12:58 Iteration 200 	 Training Loss: 7.907e-02 	 Loss in Target Net: 1.211e-02	  
 2020-01-31 05:14:06 Iteration 250 	 Training Loss: 7.137e-02 	 Loss in Target Net: 9.012e-03	  
 2020-01-31 05:15:15 Iteration 300 	 Training Loss: 7.307e-02 	 Loss in Target Net: 1.385e-02	  
 2020-01-31 05:16:23 Iteration 350 	 Training Loss: 7.071e-02 	 Loss in Target Net: 1.286e-02	  
 2020-01-31 05:17:32 Iteration 400 	 Training Loss: 7.053e-02 	 Loss in Target Net: 1.228e-02	  
 2020-01-31 05:18:41 Iteration 450 	 Training Loss: 6.673e-02 	 Loss in Target Net: 1.034e-02	  
 2020-01-31 05:19:49 Iteration 500 	 Training Loss: 7.057e-02 	 Loss in Target Net: 8.113e-03	  
 2020-01-31 05:20:58 Iteration 550 	 Training Loss: 6.937e-02 	 Loss in Target Net: 6.910e-03	  
 2020-01-31 05:22:05 Iteration 600 	 Training Loss: 7.214e-02 	 Loss in Target Net: 1.104e-02	  
 2020-01-31 05:23:13 Iteration 650 	 Training Loss: 6.595e-02 	 Loss in Target Net: 9.114e-03	  
 2020-01-31 05:24:20 Iteration 700 	 Training Loss: 6.938e-02 	 Loss in Target Net: 7.482e-03	  
 2020-01-31 05:25:24 Iteration 750 	 Training Loss: 6.971e-02 	 Loss in Target Net: 1.088e-02	  
 2020-01-31 05:26:28 Iteration 800 	 Training Loss: 6.431e-02 	 Loss in Target Net: 9.289e-03	  
 2020-01-31 05:27:33 Iteration 850 	 Training Loss: 6.746e-02 	 Loss in Target Net: 1.048e-02	  
 2020-01-31 05:28:37 Iteration 900 	 Training Loss: 6.798e-02 	 Loss in Target Net: 7.826e-03	  
 2020-01-31 05:29:41 Iteration 950 	 Training Loss: 6.828e-02 	 Loss in Target Net: 1.006e-02	  
 2020-01-31 05:30:45 Iteration 1000 	 Training Loss: 6.868e-02 	 Loss in Target Net: 1.205e-02	  
 2020-01-31 05:31:49 Iteration 1050 	 Training Loss: 6.630e-02 	 Loss in Target Net: 8.243e-03	  
 2020-01-31 05:32:54 Iteration 1100 	 Training Loss: 6.518e-02 	 Loss in Target Net: 1.100e-02	  
 2020-01-31 05:33:58 Iteration 1150 	 Training Loss: 6.903e-02 	 Loss in Target Net: 1.012e-02	  
 2020-01-31 05:35:02 Iteration 1200 	 Training Loss: 6.593e-02 	 Loss in Target Net: 1.176e-02	  
 2020-01-31 05:36:06 Iteration 1250 	 Training Loss: 6.732e-02 	 Loss in Target Net: 1.451e-02	  
 2020-01-31 05:37:10 Iteration 1300 	 Training Loss: 6.411e-02 	 Loss in Target Net: 1.378e-02	  
 2020-01-31 05:38:15 Iteration 1350 	 Training Loss: 6.704e-02 	 Loss in Target Net: 1.157e-02	  
 2020-01-31 05:39:19 Iteration 1400 	 Training Loss: 6.955e-02 	 Loss in Target Net: 6.296e-03	  
 2020-01-31 05:40:23 Iteration 1450 	 Training Loss: 6.830e-02 	 Loss in Target Net: 9.111e-03	  
 2020-01-31 05:41:27 Iteration 1500 	 Training Loss: 6.565e-02 	 Loss in Target Net: 8.510e-03	  
 2020-01-31 05:42:31 Iteration 1550 	 Training Loss: 6.709e-02 	 Loss in Target Net: 1.051e-02	  
 2020-01-31 05:43:35 Iteration 1600 	 Training Loss: 6.720e-02 	 Loss in Target Net: 8.029e-03	  
 2020-01-31 05:44:39 Iteration 1650 	 Training Loss: 6.175e-02 	 Loss in Target Net: 7.123e-03	  
 2020-01-31 05:45:43 Iteration 1700 	 Training Loss: 6.747e-02 	 Loss in Target Net: 9.379e-03	  
 2020-01-31 05:46:47 Iteration 1750 	 Training Loss: 6.957e-02 	 Loss in Target Net: 7.539e-03	  
 2020-01-31 05:47:51 Iteration 1800 	 Training Loss: 6.821e-02 	 Loss in Target Net: 7.599e-03	  
 2020-01-31 05:48:55 Iteration 1850 	 Training Loss: 6.943e-02 	 Loss in Target Net: 8.601e-03	  
 2020-01-31 05:49:59 Iteration 1900 	 Training Loss: 6.244e-02 	 Loss in Target Net: 9.120e-03	  
 2020-01-31 05:51:03 Iteration 1950 	 Training Loss: 6.498e-02 	 Loss in Target Net: 7.531e-03	  
 2020-01-31 05:52:07 Iteration 2000 	 Training Loss: 6.755e-02 	 Loss in Target Net: 6.099e-03	  
 2020-01-31 05:53:11 Iteration 2050 	 Training Loss: 6.702e-02 	 Loss in Target Net: 1.052e-02	  
 2020-01-31 05:54:16 Iteration 2100 	 Training Loss: 6.683e-02 	 Loss in Target Net: 1.185e-02	  
 2020-01-31 05:55:19 Iteration 2150 	 Training Loss: 6.397e-02 	 Loss in Target Net: 1.088e-02	  
 2020-01-31 05:56:24 Iteration 2200 	 Training Loss: 6.516e-02 	 Loss in Target Net: 9.525e-03	  
 2020-01-31 05:57:28 Iteration 2250 	 Training Loss: 6.617e-02 	 Loss in Target Net: 1.591e-02	  
 2020-01-31 05:58:32 Iteration 2300 	 Training Loss: 6.648e-02 	 Loss in Target Net: 1.095e-02	  
 2020-01-31 05:59:36 Iteration 2350 	 Training Loss: 6.278e-02 	 Loss in Target Net: 9.794e-03	  
 2020-01-31 06:00:40 Iteration 2400 	 Training Loss: 6.600e-02 	 Loss in Target Net: 9.770e-03	  
 2020-01-31 06:01:45 Iteration 2450 	 Training Loss: 6.345e-02 	 Loss in Target Net: 6.915e-03	  
 2020-01-31 06:02:49 Iteration 2500 	 Training Loss: 6.391e-02 	 Loss in Target Net: 7.783e-03	  
 2020-01-31 06:03:54 Iteration 2550 	 Training Loss: 6.316e-02 	 Loss in Target Net: 8.860e-03	  
 2020-01-31 06:04:58 Iteration 2600 	 Training Loss: 6.518e-02 	 Loss in Target Net: 7.060e-03	  
 2020-01-31 06:06:02 Iteration 2650 	 Training Loss: 6.719e-02 	 Loss in Target Net: 7.482e-03	  
 2020-01-31 06:07:07 Iteration 2700 	 Training Loss: 6.401e-02 	 Loss in Target Net: 7.355e-03	  
 2020-01-31 06:08:11 Iteration 2750 	 Training Loss: 6.035e-02 	 Loss in Target Net: 1.092e-02	  
 2020-01-31 06:09:15 Iteration 2800 	 Training Loss: 6.603e-02 	 Loss in Target Net: 7.030e-03	  
 2020-01-31 06:10:19 Iteration 2850 	 Training Loss: 7.484e-02 	 Loss in Target Net: 6.052e-03	  
 2020-01-31 06:11:24 Iteration 2900 	 Training Loss: 6.598e-02 	 Loss in Target Net: 7.943e-03	  
 2020-01-31 06:12:28 Iteration 2950 	 Training Loss: 6.537e-02 	 Loss in Target Net: 6.361e-03	  
 2020-01-31 06:13:31 Iteration 3000 	 Training Loss: 6.046e-02 	 Loss in Target Net: 8.157e-03	  
 2020-01-31 06:14:35 Iteration 3050 	 Training Loss: 6.541e-02 	 Loss in Target Net: 7.089e-03	  
 2020-01-31 06:15:39 Iteration 3100 	 Training Loss: 6.436e-02 	 Loss in Target Net: 7.366e-03	  
 2020-01-31 06:16:43 Iteration 3150 	 Training Loss: 6.454e-02 	 Loss in Target Net: 6.524e-03	  
 2020-01-31 06:17:48 Iteration 3200 	 Training Loss: 6.203e-02 	 Loss in Target Net: 1.078e-02	  
 2020-01-31 06:18:52 Iteration 3250 	 Training Loss: 6.587e-02 	 Loss in Target Net: 4.507e-03	  
 2020-01-31 06:19:56 Iteration 3300 	 Training Loss: 6.413e-02 	 Loss in Target Net: 6.866e-03	  
 2020-01-31 06:21:00 Iteration 3350 	 Training Loss: 6.421e-02 	 Loss in Target Net: 7.202e-03	  
 2020-01-31 06:22:05 Iteration 3400 	 Training Loss: 6.145e-02 	 Loss in Target Net: 7.352e-03	  
 2020-01-31 06:23:10 Iteration 3450 	 Training Loss: 6.524e-02 	 Loss in Target Net: 6.752e-03	  
 2020-01-31 06:24:14 Iteration 3500 	 Training Loss: 6.459e-02 	 Loss in Target Net: 8.001e-03	  
 2020-01-31 06:25:18 Iteration 3550 	 Training Loss: 6.416e-02 	 Loss in Target Net: 7.479e-03	  
 2020-01-31 06:26:21 Iteration 3600 	 Training Loss: 6.443e-02 	 Loss in Target Net: 6.953e-03	  
 2020-01-31 06:27:25 Iteration 3650 	 Training Loss: 6.560e-02 	 Loss in Target Net: 6.789e-03	  
 2020-01-31 06:28:28 Iteration 3700 	 Training Loss: 6.656e-02 	 Loss in Target Net: 9.548e-03	  
 2020-01-31 06:29:31 Iteration 3750 	 Training Loss: 6.112e-02 	 Loss in Target Net: 9.513e-03	  
 2020-01-31 06:30:36 Iteration 3800 	 Training Loss: 6.330e-02 	 Loss in Target Net: 8.535e-03	  
 2020-01-31 06:31:40 Iteration 3850 	 Training Loss: 6.649e-02 	 Loss in Target Net: 9.878e-03	  
 2020-01-31 06:32:44 Iteration 3900 	 Training Loss: 6.695e-02 	 Loss in Target Net: 8.463e-03	  
 2020-01-31 06:33:49 Iteration 3950 	 Training Loss: 6.607e-02 	 Loss in Target Net: 7.608e-03	  
 2020-01-31 06:34:51 Iteration 3999 	 Training Loss: 6.775e-02 	 Loss in Target Net: 6.878e-03	  
Evaluating against victims networks
DPN92
Using Adam for retraining
Files already downloaded and verified
2020-01-31 06:34:56, Epoch 0, Iteration 7, loss 0.790 (4.057), acc 92.308 (68.200)
2020-01-31 06:34:56, Epoch 30, Iteration 7, loss 0.077 (0.143), acc 98.077 (97.400)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[16.705477, -27.118864, -61.845028, 0.56500006, -29.313784, -2.0913665, 17.216803, -39.26314, 41.601192, -90.79438], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-01-31 06:35:00 Epoch 59, Val iteration 0, acc 91.000 (91.000)
2020-01-31 06:35:08 Epoch 59, Val iteration 19, acc 92.000 (92.280)
* Prec: 92.28000183105469
--------
SENet18
Using Adam for retraining
Files already downloaded and verified
2020-01-31 06:35:10, Epoch 0, Iteration 7, loss 0.527 (0.675), acc 92.308 (87.200)
2020-01-31 06:35:10, Epoch 30, Iteration 7, loss 0.005 (0.213), acc 100.000 (96.800)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[8.389872, -21.263422, -20.020983, -5.3898087, 8.014549, -4.821552, 22.985819, -36.51006, 26.296968, -23.876898], Poisons' Predictions:[8, 8, 8, 8, 6]
2020-01-31 06:35:11 Epoch 59, Val iteration 0, acc 91.800 (91.800)
2020-01-31 06:35:14 Epoch 59, Val iteration 19, acc 91.800 (90.960)
* Prec: 90.96000213623047
--------
ResNet50
Using Adam for retraining
Files already downloaded and verified
2020-01-31 06:35:16, Epoch 0, Iteration 7, loss 0.700 (0.673), acc 90.385 (86.800)
2020-01-31 06:35:16, Epoch 30, Iteration 7, loss 0.000 (0.000), acc 100.000 (100.000)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-74.51626, -31.904432, -38.949516, -22.279606, -30.348276, -44.15856, 19.361027, -13.079215, 30.087389, -33.247486], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-01-31 06:35:18 Epoch 59, Val iteration 0, acc 93.000 (93.000)
2020-01-31 06:35:22 Epoch 59, Val iteration 19, acc 93.800 (93.420)
* Prec: 93.42000160217285
--------
ResNeXt29_2x64d
Using Adam for retraining
Files already downloaded and verified
2020-01-31 06:35:24, Epoch 0, Iteration 7, loss 0.651 (2.295), acc 88.462 (74.000)
2020-01-31 06:35:25, Epoch 30, Iteration 7, loss 0.001 (0.025), acc 100.000 (99.200)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-20.129375, -8.442743, -13.648906, -3.6817937, -49.00985, -19.979317, 9.36499, -20.996408, 20.10716, -17.892738], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-01-31 06:35:26 Epoch 59, Val iteration 0, acc 93.000 (93.000)
2020-01-31 06:35:30 Epoch 59, Val iteration 19, acc 92.800 (92.820)
* Prec: 92.82000122070312
--------
GoogLeNet
Using Adam for retraining
Files already downloaded and verified
2020-01-31 06:35:33, Epoch 0, Iteration 7, loss 0.418 (0.355), acc 90.385 (91.400)
2020-01-31 06:35:34, Epoch 30, Iteration 7, loss 0.019 (0.026), acc 100.000 (99.400)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-18.87232, -8.645884, -5.7307415, 0.98627377, -7.6176295, -3.8434374, 10.401191, -8.424211, 8.383945, -18.461128], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-01-31 06:35:36 Epoch 59, Val iteration 0, acc 92.200 (92.200)
2020-01-31 06:35:41 Epoch 59, Val iteration 19, acc 92.000 (92.310)
* Prec: 92.31000213623047
--------
MobileNetV2
Using Adam for retraining
Files already downloaded and verified
2020-01-31 06:35:44, Epoch 0, Iteration 7, loss 1.211 (3.760), acc 80.769 (57.600)
2020-01-31 06:35:44, Epoch 30, Iteration 7, loss 0.237 (0.194), acc 90.385 (95.200)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[9.454251, -15.130652, -5.1793637, 12.90065, -22.328335, 1.425667, 15.810731, -22.138454, 20.39961, 1.3670135], Poisons' Predictions:[8, 6, 8, 8, 8]
2020-01-31 06:35:45 Epoch 59, Val iteration 0, acc 88.800 (88.800)
2020-01-31 06:35:47 Epoch 59, Val iteration 19, acc 88.600 (87.090)
* Prec: 87.09000129699707
--------
ResNet18
Using Adam for retraining
Files already downloaded and verified
2020-01-31 06:35:49, Epoch 0, Iteration 7, loss 0.493 (0.813), acc 92.308 (87.400)
2020-01-31 06:35:50, Epoch 30, Iteration 7, loss 0.437 (0.105), acc 96.154 (97.800)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-41.301693, -37.035553, -15.333878, -4.336229, -37.812595, -3.9303846, 7.976406, -21.670689, 8.51213, -39.116116], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-01-31 06:35:50 Epoch 59, Val iteration 0, acc 93.600 (93.600)
2020-01-31 06:35:53 Epoch 59, Val iteration 19, acc 92.800 (92.680)
* Prec: 92.68000068664551
--------
DenseNet121
Using Adam for retraining
Files already downloaded and verified
2020-01-31 06:35:56, Epoch 0, Iteration 7, loss 0.421 (0.435), acc 92.308 (92.000)
2020-01-31 06:35:56, Epoch 30, Iteration 7, loss 0.000 (0.002), acc 100.000 (100.000)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-12.199242, -30.465267, -20.002441, -5.827118, -11.216214, -6.020711, 3.2586083, -38.21208, 5.302871, -15.711413], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-01-31 06:35:58 Epoch 59, Val iteration 0, acc 93.400 (93.400)
2020-01-31 06:36:03 Epoch 59, Val iteration 19, acc 94.000 (93.280)
* Prec: 93.28000183105469
--------
------SUMMARY------
TIME ELAPSED (mins): 86
TARGET INDEX: 8
DPN92 1
SENet18 1
ResNet50 1
ResNeXt29_2x64d 1
GoogLeNet 0
MobileNetV2 1
ResNet18 1
DenseNet121 1
