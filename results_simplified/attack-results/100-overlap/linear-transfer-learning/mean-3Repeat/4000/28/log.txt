Namespace(chk_path='chk-black-ourmean/', chk_subdir='poisons', device='cuda', dset_path='datasets', end2end=False, eval_poison_path='', gpu='0', lr_decay_epoch=[30, 45], mode='mean', model_resume_path='model-chks', nearest=False, net_repeat=3, num_per_class=50, original_grad=True, poison_decay_ites=[], poison_decay_ratio=0.1, poison_epsilon=0.1, poison_ites=4000, poison_label=8, poison_lr=0.04, poison_momentum=0.9, poison_num=5, poison_opt='adam', resume_poison_ite=0, retrain_bsize=64, retrain_epochs=60, retrain_lr=0.1, retrain_momentum=0.9, retrain_opt='adam', retrain_wd=0, subs_chk_name=['ckpt-%s-4800-dp0.200-droplayer0.000-seed1226.t7', 'ckpt-%s-4800-dp0.250-droplayer0.000-seed1226.t7', 'ckpt-%s-4800-dp0.300-droplayer0.000.t7'], subs_dp=[0.2, 0.25, 0.3], subset_group=0, substitute_nets=['DPN92', 'SENet18', 'ResNet50', 'ResNeXt29_2x64d', 'GoogLeNet', 'MobileNetV2'], target_index=28, target_label=6, target_net=['DPN92', 'SENet18', 'ResNet50', 'ResNeXt29_2x64d', 'GoogLeNet', 'MobileNetV2', 'ResNet18', 'DenseNet121'], test_chk_name='ckpt-%s-4800.t7', tol=1e-06, train_data_path='datasets/CIFAR10_TRAIN_Split.pth')
Path: chk-black-ourmean/mean-3Repeat/4000/28
Selected base image indices: [213, 225, 227, 247, 249]
 2020-01-31 12:23:53 Iteration 0 	 Training Loss: 1.108e+00 	 Loss in Target Net: 3.713e-01	  
 2020-01-31 12:25:01 Iteration 50 	 Training Loss: 6.788e-02 	 Loss in Target Net: 8.061e-03	  
 2020-01-31 12:26:07 Iteration 100 	 Training Loss: 5.566e-02 	 Loss in Target Net: 8.260e-03	  
 2020-01-31 12:27:14 Iteration 150 	 Training Loss: 5.439e-02 	 Loss in Target Net: 3.740e-03	  
 2020-01-31 12:28:21 Iteration 200 	 Training Loss: 5.005e-02 	 Loss in Target Net: 3.176e-03	  
 2020-01-31 12:29:29 Iteration 250 	 Training Loss: 5.060e-02 	 Loss in Target Net: 3.804e-03	  
 2020-01-31 12:30:35 Iteration 300 	 Training Loss: 4.845e-02 	 Loss in Target Net: 3.498e-03	  
 2020-01-31 12:31:40 Iteration 350 	 Training Loss: 4.802e-02 	 Loss in Target Net: 3.859e-03	  
 2020-01-31 12:32:43 Iteration 400 	 Training Loss: 4.526e-02 	 Loss in Target Net: 6.213e-03	  
 2020-01-31 12:33:45 Iteration 450 	 Training Loss: 4.718e-02 	 Loss in Target Net: 4.453e-03	  
 2020-01-31 12:34:48 Iteration 500 	 Training Loss: 4.807e-02 	 Loss in Target Net: 5.351e-03	  
 2020-01-31 12:35:51 Iteration 550 	 Training Loss: 4.535e-02 	 Loss in Target Net: 5.414e-03	  
 2020-01-31 12:36:54 Iteration 600 	 Training Loss: 4.582e-02 	 Loss in Target Net: 4.779e-03	  
 2020-01-31 12:37:56 Iteration 650 	 Training Loss: 4.832e-02 	 Loss in Target Net: 4.203e-03	  
 2020-01-31 12:38:59 Iteration 700 	 Training Loss: 4.701e-02 	 Loss in Target Net: 3.347e-03	  
 2020-01-31 12:40:03 Iteration 750 	 Training Loss: 4.631e-02 	 Loss in Target Net: 3.310e-03	  
 2020-01-31 12:41:08 Iteration 800 	 Training Loss: 4.505e-02 	 Loss in Target Net: 3.619e-03	  
 2020-01-31 12:42:16 Iteration 850 	 Training Loss: 4.711e-02 	 Loss in Target Net: 4.502e-03	  
 2020-01-31 12:43:20 Iteration 900 	 Training Loss: 5.123e-02 	 Loss in Target Net: 5.261e-03	  
 2020-01-31 12:44:24 Iteration 950 	 Training Loss: 4.413e-02 	 Loss in Target Net: 3.870e-03	  
 2020-01-31 12:45:28 Iteration 1000 	 Training Loss: 4.794e-02 	 Loss in Target Net: 3.827e-03	  
 2020-01-31 12:46:34 Iteration 1050 	 Training Loss: 4.694e-02 	 Loss in Target Net: 3.052e-03	  
 2020-01-31 12:47:41 Iteration 1100 	 Training Loss: 4.314e-02 	 Loss in Target Net: 4.423e-03	  
 2020-01-31 12:48:49 Iteration 1150 	 Training Loss: 4.637e-02 	 Loss in Target Net: 4.796e-03	  
 2020-01-31 12:49:55 Iteration 1200 	 Training Loss: 4.467e-02 	 Loss in Target Net: 3.856e-03	  
 2020-01-31 12:51:03 Iteration 1250 	 Training Loss: 4.329e-02 	 Loss in Target Net: 4.477e-03	  
 2020-01-31 12:52:12 Iteration 1300 	 Training Loss: 4.545e-02 	 Loss in Target Net: 3.966e-03	  
 2020-01-31 12:53:22 Iteration 1350 	 Training Loss: 4.376e-02 	 Loss in Target Net: 5.288e-03	  
 2020-01-31 12:54:33 Iteration 1400 	 Training Loss: 4.536e-02 	 Loss in Target Net: 4.671e-03	  
 2020-01-31 12:55:46 Iteration 1450 	 Training Loss: 4.173e-02 	 Loss in Target Net: 3.156e-03	  
 2020-01-31 12:56:57 Iteration 1500 	 Training Loss: 4.544e-02 	 Loss in Target Net: 4.189e-03	  
 2020-01-31 12:58:10 Iteration 1550 	 Training Loss: 4.590e-02 	 Loss in Target Net: 4.902e-03	  
 2020-01-31 12:59:19 Iteration 1600 	 Training Loss: 5.154e-02 	 Loss in Target Net: 5.336e-03	  
 2020-01-31 13:00:28 Iteration 1650 	 Training Loss: 4.618e-02 	 Loss in Target Net: 5.083e-03	  
 2020-01-31 13:01:37 Iteration 1700 	 Training Loss: 4.527e-02 	 Loss in Target Net: 5.254e-03	  
 2020-01-31 13:02:44 Iteration 1750 	 Training Loss: 4.746e-02 	 Loss in Target Net: 3.499e-03	  
 2020-01-31 13:03:46 Iteration 1800 	 Training Loss: 4.665e-02 	 Loss in Target Net: 3.392e-03	  
 2020-01-31 13:04:48 Iteration 1850 	 Training Loss: 4.646e-02 	 Loss in Target Net: 3.554e-03	  
 2020-01-31 13:05:51 Iteration 1900 	 Training Loss: 4.443e-02 	 Loss in Target Net: 2.844e-03	  
 2020-01-31 13:06:54 Iteration 1950 	 Training Loss: 4.173e-02 	 Loss in Target Net: 2.900e-03	  
 2020-01-31 13:07:57 Iteration 2000 	 Training Loss: 4.596e-02 	 Loss in Target Net: 3.240e-03	  
 2020-01-31 13:08:59 Iteration 2050 	 Training Loss: 4.494e-02 	 Loss in Target Net: 5.220e-03	  
 2020-01-31 13:10:03 Iteration 2100 	 Training Loss: 4.672e-02 	 Loss in Target Net: 3.656e-03	  
 2020-01-31 13:11:06 Iteration 2150 	 Training Loss: 4.846e-02 	 Loss in Target Net: 4.478e-03	  
 2020-01-31 13:12:09 Iteration 2200 	 Training Loss: 4.336e-02 	 Loss in Target Net: 4.271e-03	  
 2020-01-31 13:13:12 Iteration 2250 	 Training Loss: 4.179e-02 	 Loss in Target Net: 3.342e-03	  
 2020-01-31 13:14:15 Iteration 2300 	 Training Loss: 4.676e-02 	 Loss in Target Net: 5.707e-03	  
 2020-01-31 13:15:17 Iteration 2350 	 Training Loss: 4.497e-02 	 Loss in Target Net: 4.701e-03	  
 2020-01-31 13:16:20 Iteration 2400 	 Training Loss: 4.764e-02 	 Loss in Target Net: 4.112e-03	  
 2020-01-31 13:17:23 Iteration 2450 	 Training Loss: 4.454e-02 	 Loss in Target Net: 3.429e-03	  
 2020-01-31 13:18:25 Iteration 2500 	 Training Loss: 4.602e-02 	 Loss in Target Net: 3.475e-03	  
 2020-01-31 13:19:28 Iteration 2550 	 Training Loss: 4.786e-02 	 Loss in Target Net: 2.978e-03	  
 2020-01-31 13:20:30 Iteration 2600 	 Training Loss: 4.332e-02 	 Loss in Target Net: 3.811e-03	  
 2020-01-31 13:21:33 Iteration 2650 	 Training Loss: 4.318e-02 	 Loss in Target Net: 4.113e-03	  
 2020-01-31 13:22:36 Iteration 2700 	 Training Loss: 4.447e-02 	 Loss in Target Net: 2.878e-03	  
 2020-01-31 13:23:39 Iteration 2750 	 Training Loss: 4.263e-02 	 Loss in Target Net: 3.590e-03	  
 2020-01-31 13:24:41 Iteration 2800 	 Training Loss: 4.593e-02 	 Loss in Target Net: 4.066e-03	  
 2020-01-31 13:25:45 Iteration 2850 	 Training Loss: 4.340e-02 	 Loss in Target Net: 3.329e-03	  
 2020-01-31 13:26:50 Iteration 2900 	 Training Loss: 4.348e-02 	 Loss in Target Net: 4.424e-03	  
 2020-01-31 13:27:54 Iteration 2950 	 Training Loss: 5.094e-02 	 Loss in Target Net: 4.733e-03	  
 2020-01-31 13:28:56 Iteration 3000 	 Training Loss: 4.141e-02 	 Loss in Target Net: 4.125e-03	  
 2020-01-31 13:29:59 Iteration 3050 	 Training Loss: 4.117e-02 	 Loss in Target Net: 3.887e-03	  
 2020-01-31 13:31:00 Iteration 3100 	 Training Loss: 4.625e-02 	 Loss in Target Net: 2.723e-03	  
 2020-01-31 13:32:02 Iteration 3150 	 Training Loss: 4.419e-02 	 Loss in Target Net: 3.251e-03	  
 2020-01-31 13:33:03 Iteration 3200 	 Training Loss: 4.630e-02 	 Loss in Target Net: 3.740e-03	  
 2020-01-31 13:34:05 Iteration 3250 	 Training Loss: 4.284e-02 	 Loss in Target Net: 4.338e-03	  
 2020-01-31 13:35:06 Iteration 3300 	 Training Loss: 4.669e-02 	 Loss in Target Net: 3.874e-03	  
 2020-01-31 13:36:11 Iteration 3350 	 Training Loss: 4.310e-02 	 Loss in Target Net: 4.970e-03	  
 2020-01-31 13:37:12 Iteration 3400 	 Training Loss: 5.004e-02 	 Loss in Target Net: 3.072e-03	  
 2020-01-31 13:38:15 Iteration 3450 	 Training Loss: 4.853e-02 	 Loss in Target Net: 4.688e-03	  
 2020-01-31 13:39:17 Iteration 3500 	 Training Loss: 4.461e-02 	 Loss in Target Net: 4.484e-03	  
 2020-01-31 13:40:20 Iteration 3550 	 Training Loss: 4.815e-02 	 Loss in Target Net: 3.954e-03	  
 2020-01-31 13:41:23 Iteration 3600 	 Training Loss: 4.524e-02 	 Loss in Target Net: 4.014e-03	  
 2020-01-31 13:42:26 Iteration 3650 	 Training Loss: 4.748e-02 	 Loss in Target Net: 5.574e-03	  
 2020-01-31 13:43:28 Iteration 3700 	 Training Loss: 4.505e-02 	 Loss in Target Net: 3.912e-03	  
 2020-01-31 13:44:30 Iteration 3750 	 Training Loss: 4.692e-02 	 Loss in Target Net: 3.921e-03	  
 2020-01-31 13:45:33 Iteration 3800 	 Training Loss: 4.228e-02 	 Loss in Target Net: 4.822e-03	  
 2020-01-31 13:46:35 Iteration 3850 	 Training Loss: 4.810e-02 	 Loss in Target Net: 5.679e-03	  
 2020-01-31 13:47:37 Iteration 3900 	 Training Loss: 4.668e-02 	 Loss in Target Net: 3.851e-03	  
 2020-01-31 13:48:41 Iteration 3950 	 Training Loss: 4.496e-02 	 Loss in Target Net: 4.470e-03	  
 2020-01-31 13:49:42 Iteration 3999 	 Training Loss: 4.355e-02 	 Loss in Target Net: 4.941e-03	  
Evaluating against victims networks
DPN92
Using Adam for retraining
Files already downloaded and verified
2020-01-31 13:49:46, Epoch 0, Iteration 7, loss 1.358 (2.952), acc 86.538 (72.400)
2020-01-31 13:49:47, Epoch 30, Iteration 7, loss 0.175 (0.242), acc 98.077 (96.600)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[6.6807895, -2.5463016, -48.250313, 3.214957, -20.354256, -4.306978, 31.861334, -48.115273, 35.377335, -112.76773], Poisons' Predictions:[8, 8, 8, 6, 8]
2020-01-31 13:49:50 Epoch 59, Val iteration 0, acc 90.800 (90.800)
2020-01-31 13:49:58 Epoch 59, Val iteration 19, acc 92.600 (91.980)
* Prec: 91.98000106811523
--------
SENet18
Using Adam for retraining
Files already downloaded and verified
2020-01-31 13:50:00, Epoch 0, Iteration 7, loss 1.456 (0.751), acc 82.692 (88.000)
2020-01-31 13:50:01, Epoch 30, Iteration 7, loss 0.079 (0.238), acc 98.077 (95.800)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[1.9198556, -3.030397, -10.697126, -3.8687096, 2.1954017, -4.3655624, 25.024387, -19.663744, 17.436941, -14.644669], Poisons' Predictions:[8, 8, 6, 6, 8]
2020-01-31 13:50:01 Epoch 59, Val iteration 0, acc 92.000 (92.000)
2020-01-31 13:50:04 Epoch 59, Val iteration 19, acc 92.600 (91.580)
* Prec: 91.58000144958496
--------
ResNet50
Using Adam for retraining
Files already downloaded and verified
2020-01-31 13:50:06, Epoch 0, Iteration 7, loss 0.978 (0.878), acc 98.077 (89.000)
2020-01-31 13:50:06, Epoch 30, Iteration 7, loss 0.011 (0.007), acc 100.000 (99.600)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-20.026615, -55.07909, -55.734886, -20.51345, -47.165993, -90.96938, 17.549202, -37.43678, 19.82002, -32.729088], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-01-31 13:50:08 Epoch 59, Val iteration 0, acc 94.000 (94.000)
2020-01-31 13:50:12 Epoch 59, Val iteration 19, acc 94.000 (93.870)
* Prec: 93.87000122070313
--------
ResNeXt29_2x64d
Using Adam for retraining
Files already downloaded and verified
2020-01-31 13:50:15, Epoch 0, Iteration 7, loss 0.450 (1.570), acc 90.385 (75.000)
2020-01-31 13:50:15, Epoch 30, Iteration 7, loss 0.014 (0.116), acc 100.000 (98.200)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-37.82733, 18.864628, -0.60413605, 13.823634, -60.206673, -26.78527, 33.532455, -9.993856, 32.21448, -24.808214], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-01-31 13:50:16 Epoch 59, Val iteration 0, acc 92.800 (92.800)
2020-01-31 13:50:20 Epoch 59, Val iteration 19, acc 93.200 (93.360)
* Prec: 93.36000213623046
--------
GoogLeNet
Using Adam for retraining
Files already downloaded and verified
2020-01-31 13:50:23, Epoch 0, Iteration 7, loss 0.564 (0.362), acc 78.846 (90.600)
2020-01-31 13:50:24, Epoch 30, Iteration 7, loss 0.057 (0.052), acc 98.077 (97.400)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-17.202538, -8.877364, -12.669989, 0.15053731, -10.13198, -5.2974753, 9.476577, -25.236109, 9.226079, -20.383078], Poisons' Predictions:[8, 6, 8, 8, 6]
2020-01-31 13:50:26 Epoch 59, Val iteration 0, acc 91.000 (91.000)
2020-01-31 13:50:31 Epoch 59, Val iteration 19, acc 91.600 (91.660)
* Prec: 91.66000061035156
--------
MobileNetV2
Using Adam for retraining
Files already downloaded and verified
2020-01-31 13:50:33, Epoch 0, Iteration 7, loss 0.947 (3.542), acc 80.769 (65.200)
2020-01-31 13:50:34, Epoch 30, Iteration 7, loss 0.189 (0.133), acc 94.231 (96.400)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-10.88564, -6.8760767, -5.1521883, 10.501312, -7.8253284, -9.560784, 20.164436, -31.053715, 24.204157, -24.876957], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-01-31 13:50:34 Epoch 59, Val iteration 0, acc 88.000 (88.000)
2020-01-31 13:50:37 Epoch 59, Val iteration 19, acc 88.200 (86.880)
* Prec: 86.88000144958497
--------
ResNet18
Using Adam for retraining
Files already downloaded and verified
2020-01-31 13:50:38, Epoch 0, Iteration 7, loss 0.633 (0.733), acc 94.231 (84.800)
2020-01-31 13:50:39, Epoch 30, Iteration 7, loss 0.038 (0.060), acc 98.077 (98.800)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-31.701315, -15.6395235, -10.182732, -0.22203968, -44.37089, -8.666897, 8.801153, -24.892859, 6.164466, -26.30001], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-01-31 13:50:39 Epoch 59, Val iteration 0, acc 94.000 (94.000)
2020-01-31 13:50:41 Epoch 59, Val iteration 19, acc 93.000 (92.770)
* Prec: 92.77000160217285
--------
DenseNet121
Using Adam for retraining
Files already downloaded and verified
2020-01-31 13:50:44, Epoch 0, Iteration 7, loss 0.175 (0.356), acc 96.154 (92.400)
2020-01-31 13:50:44, Epoch 30, Iteration 7, loss 0.001 (0.004), acc 100.000 (100.000)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-7.940382, -16.3445, -11.5660095, -2.994771, -4.209444, -5.6101093, 6.218888, -38.44768, 7.4212027, -15.398473], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-01-31 13:50:46 Epoch 59, Val iteration 0, acc 93.800 (93.800)
2020-01-31 13:50:51 Epoch 59, Val iteration 19, acc 93.000 (92.810)
* Prec: 92.81000213623047
--------
------SUMMARY------
TIME ELAPSED (mins): 85
TARGET INDEX: 28
DPN92 1
SENet18 0
ResNet50 1
ResNeXt29_2x64d 0
GoogLeNet 0
MobileNetV2 1
ResNet18 0
DenseNet121 1
