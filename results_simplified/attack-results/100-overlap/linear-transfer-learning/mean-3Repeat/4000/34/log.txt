Namespace(chk_path='chk-black-ourmean/', chk_subdir='poisons', device='cuda', dset_path='datasets', end2end=False, eval_poison_path='', gpu='2', lr_decay_epoch=[30, 45], mode='mean', model_resume_path='model-chks', nearest=False, net_repeat=3, num_per_class=50, original_grad=True, poison_decay_ites=[], poison_decay_ratio=0.1, poison_epsilon=0.1, poison_ites=4000, poison_label=8, poison_lr=0.04, poison_momentum=0.9, poison_num=5, poison_opt='adam', resume_poison_ite=0, retrain_bsize=64, retrain_epochs=60, retrain_lr=0.1, retrain_momentum=0.9, retrain_opt='adam', retrain_wd=0, subs_chk_name=['ckpt-%s-4800-dp0.200-droplayer0.000-seed1226.t7', 'ckpt-%s-4800-dp0.250-droplayer0.000-seed1226.t7', 'ckpt-%s-4800-dp0.300-droplayer0.000.t7'], subs_dp=[0.2, 0.25, 0.3], subset_group=0, substitute_nets=['DPN92', 'SENet18', 'ResNet50', 'ResNeXt29_2x64d', 'GoogLeNet', 'MobileNetV2'], target_index=34, target_label=6, target_net=['DPN92', 'SENet18', 'ResNet50', 'ResNeXt29_2x64d', 'GoogLeNet', 'MobileNetV2', 'ResNet18', 'DenseNet121'], test_chk_name='ckpt-%s-4800.t7', tol=1e-06, train_data_path='datasets/CIFAR10_TRAIN_Split.pth')
Path: chk-black-ourmean/mean-3Repeat/4000/34
Selected base image indices: [213, 225, 227, 247, 249]
 2020-01-31 13:42:01 Iteration 0 	 Training Loss: 1.154e+00 	 Loss in Target Net: 3.939e-01	  
 2020-01-31 13:43:08 Iteration 50 	 Training Loss: 8.576e-02 	 Loss in Target Net: 2.400e-02	  
 2020-01-31 13:44:14 Iteration 100 	 Training Loss: 7.145e-02 	 Loss in Target Net: 1.270e-02	  
 2020-01-31 13:45:20 Iteration 150 	 Training Loss: 6.522e-02 	 Loss in Target Net: 1.327e-02	  
 2020-01-31 13:46:26 Iteration 200 	 Training Loss: 6.530e-02 	 Loss in Target Net: 9.585e-03	  
 2020-01-31 13:47:32 Iteration 250 	 Training Loss: 6.188e-02 	 Loss in Target Net: 1.850e-02	  
 2020-01-31 13:48:39 Iteration 300 	 Training Loss: 6.786e-02 	 Loss in Target Net: 1.651e-02	  
 2020-01-31 13:49:45 Iteration 350 	 Training Loss: 6.253e-02 	 Loss in Target Net: 1.292e-02	  
 2020-01-31 13:50:51 Iteration 400 	 Training Loss: 6.402e-02 	 Loss in Target Net: 1.520e-02	  
 2020-01-31 13:51:57 Iteration 450 	 Training Loss: 6.415e-02 	 Loss in Target Net: 6.834e-03	  
 2020-01-31 13:53:02 Iteration 500 	 Training Loss: 6.693e-02 	 Loss in Target Net: 8.350e-03	  
 2020-01-31 13:54:08 Iteration 550 	 Training Loss: 6.182e-02 	 Loss in Target Net: 8.731e-03	  
 2020-01-31 13:55:14 Iteration 600 	 Training Loss: 6.177e-02 	 Loss in Target Net: 1.112e-02	  
 2020-01-31 13:56:20 Iteration 650 	 Training Loss: 5.972e-02 	 Loss in Target Net: 4.545e-03	  
 2020-01-31 13:57:25 Iteration 700 	 Training Loss: 5.906e-02 	 Loss in Target Net: 6.875e-03	  
 2020-01-31 13:58:31 Iteration 750 	 Training Loss: 6.799e-02 	 Loss in Target Net: 7.583e-03	  
 2020-01-31 13:59:37 Iteration 800 	 Training Loss: 5.749e-02 	 Loss in Target Net: 1.039e-02	  
 2020-01-31 14:00:43 Iteration 850 	 Training Loss: 6.078e-02 	 Loss in Target Net: 9.015e-03	  
 2020-01-31 14:01:49 Iteration 900 	 Training Loss: 6.260e-02 	 Loss in Target Net: 8.477e-03	  
 2020-01-31 14:02:55 Iteration 950 	 Training Loss: 5.703e-02 	 Loss in Target Net: 7.461e-03	  
 2020-01-31 14:04:00 Iteration 1000 	 Training Loss: 5.824e-02 	 Loss in Target Net: 6.672e-03	  
 2020-01-31 14:05:06 Iteration 1050 	 Training Loss: 5.633e-02 	 Loss in Target Net: 9.082e-03	  
 2020-01-31 14:06:12 Iteration 1100 	 Training Loss: 5.822e-02 	 Loss in Target Net: 5.697e-03	  
 2020-01-31 14:07:18 Iteration 1150 	 Training Loss: 5.783e-02 	 Loss in Target Net: 1.043e-02	  
 2020-01-31 14:08:23 Iteration 1200 	 Training Loss: 5.908e-02 	 Loss in Target Net: 6.281e-03	  
 2020-01-31 14:09:29 Iteration 1250 	 Training Loss: 5.798e-02 	 Loss in Target Net: 8.349e-03	  
 2020-01-31 14:10:34 Iteration 1300 	 Training Loss: 6.071e-02 	 Loss in Target Net: 9.298e-03	  
 2020-01-31 14:11:40 Iteration 1350 	 Training Loss: 5.980e-02 	 Loss in Target Net: 1.052e-02	  
 2020-01-31 14:12:46 Iteration 1400 	 Training Loss: 6.030e-02 	 Loss in Target Net: 1.289e-02	  
 2020-01-31 14:13:51 Iteration 1450 	 Training Loss: 6.184e-02 	 Loss in Target Net: 6.008e-03	  
 2020-01-31 14:14:57 Iteration 1500 	 Training Loss: 5.860e-02 	 Loss in Target Net: 9.769e-03	  
 2020-01-31 14:16:03 Iteration 1550 	 Training Loss: 6.307e-02 	 Loss in Target Net: 9.625e-03	  
 2020-01-31 14:17:08 Iteration 1600 	 Training Loss: 5.739e-02 	 Loss in Target Net: 8.797e-03	  
 2020-01-31 14:18:14 Iteration 1650 	 Training Loss: 5.623e-02 	 Loss in Target Net: 6.963e-03	  
 2020-01-31 14:19:20 Iteration 1700 	 Training Loss: 6.006e-02 	 Loss in Target Net: 8.488e-03	  
 2020-01-31 14:20:26 Iteration 1750 	 Training Loss: 5.549e-02 	 Loss in Target Net: 8.106e-03	  
 2020-01-31 14:21:31 Iteration 1800 	 Training Loss: 6.299e-02 	 Loss in Target Net: 7.073e-03	  
 2020-01-31 14:22:37 Iteration 1850 	 Training Loss: 6.021e-02 	 Loss in Target Net: 6.376e-03	  
 2020-01-31 14:23:43 Iteration 1900 	 Training Loss: 6.171e-02 	 Loss in Target Net: 1.039e-02	  
 2020-01-31 14:24:48 Iteration 1950 	 Training Loss: 6.029e-02 	 Loss in Target Net: 1.057e-02	  
 2020-01-31 14:25:54 Iteration 2000 	 Training Loss: 5.357e-02 	 Loss in Target Net: 1.092e-02	  
 2020-01-31 14:26:59 Iteration 2050 	 Training Loss: 6.065e-02 	 Loss in Target Net: 1.361e-02	  
 2020-01-31 14:28:05 Iteration 2100 	 Training Loss: 5.653e-02 	 Loss in Target Net: 9.935e-03	  
 2020-01-31 14:29:10 Iteration 2150 	 Training Loss: 5.704e-02 	 Loss in Target Net: 1.273e-02	  
 2020-01-31 14:30:16 Iteration 2200 	 Training Loss: 5.902e-02 	 Loss in Target Net: 7.583e-03	  
 2020-01-31 14:31:21 Iteration 2250 	 Training Loss: 6.013e-02 	 Loss in Target Net: 6.681e-03	  
 2020-01-31 14:32:27 Iteration 2300 	 Training Loss: 5.756e-02 	 Loss in Target Net: 7.588e-03	  
 2020-01-31 14:33:32 Iteration 2350 	 Training Loss: 5.670e-02 	 Loss in Target Net: 1.362e-02	  
 2020-01-31 14:34:38 Iteration 2400 	 Training Loss: 5.729e-02 	 Loss in Target Net: 1.569e-02	  
 2020-01-31 14:35:43 Iteration 2450 	 Training Loss: 5.536e-02 	 Loss in Target Net: 1.748e-02	  
 2020-01-31 14:36:49 Iteration 2500 	 Training Loss: 5.914e-02 	 Loss in Target Net: 1.281e-02	  
 2020-01-31 14:37:54 Iteration 2550 	 Training Loss: 5.851e-02 	 Loss in Target Net: 1.522e-02	  
 2020-01-31 14:39:00 Iteration 2600 	 Training Loss: 5.928e-02 	 Loss in Target Net: 9.856e-03	  
 2020-01-31 14:40:06 Iteration 2650 	 Training Loss: 5.719e-02 	 Loss in Target Net: 1.096e-02	  
 2020-01-31 14:41:11 Iteration 2700 	 Training Loss: 5.373e-02 	 Loss in Target Net: 1.192e-02	  
 2020-01-31 14:42:17 Iteration 2750 	 Training Loss: 5.774e-02 	 Loss in Target Net: 1.596e-02	  
 2020-01-31 14:43:22 Iteration 2800 	 Training Loss: 5.737e-02 	 Loss in Target Net: 1.486e-02	  
 2020-01-31 14:44:28 Iteration 2850 	 Training Loss: 6.029e-02 	 Loss in Target Net: 9.812e-03	  
 2020-01-31 14:45:33 Iteration 2900 	 Training Loss: 5.612e-02 	 Loss in Target Net: 1.034e-02	  
 2020-01-31 14:46:39 Iteration 2950 	 Training Loss: 5.805e-02 	 Loss in Target Net: 7.178e-03	  
 2020-01-31 14:47:44 Iteration 3000 	 Training Loss: 5.801e-02 	 Loss in Target Net: 1.097e-02	  
 2020-01-31 14:48:50 Iteration 3050 	 Training Loss: 5.670e-02 	 Loss in Target Net: 1.094e-02	  
 2020-01-31 14:49:56 Iteration 3100 	 Training Loss: 5.788e-02 	 Loss in Target Net: 1.059e-02	  
 2020-01-31 14:51:02 Iteration 3150 	 Training Loss: 5.732e-02 	 Loss in Target Net: 1.142e-02	  
 2020-01-31 14:52:08 Iteration 3200 	 Training Loss: 5.636e-02 	 Loss in Target Net: 6.649e-03	  
 2020-01-31 14:53:14 Iteration 3250 	 Training Loss: 6.353e-02 	 Loss in Target Net: 1.374e-02	  
 2020-01-31 14:54:19 Iteration 3300 	 Training Loss: 5.539e-02 	 Loss in Target Net: 1.757e-02	  
 2020-01-31 14:55:25 Iteration 3350 	 Training Loss: 5.495e-02 	 Loss in Target Net: 1.174e-02	  
 2020-01-31 14:56:31 Iteration 3400 	 Training Loss: 5.378e-02 	 Loss in Target Net: 1.137e-02	  
 2020-01-31 14:57:36 Iteration 3450 	 Training Loss: 6.131e-02 	 Loss in Target Net: 1.641e-02	  
 2020-01-31 14:58:42 Iteration 3500 	 Training Loss: 6.019e-02 	 Loss in Target Net: 1.827e-02	  
 2020-01-31 14:59:48 Iteration 3550 	 Training Loss: 5.846e-02 	 Loss in Target Net: 5.301e-03	  
 2020-01-31 15:00:53 Iteration 3600 	 Training Loss: 6.144e-02 	 Loss in Target Net: 1.203e-02	  
 2020-01-31 15:01:59 Iteration 3650 	 Training Loss: 5.696e-02 	 Loss in Target Net: 1.226e-02	  
 2020-01-31 15:03:05 Iteration 3700 	 Training Loss: 5.339e-02 	 Loss in Target Net: 1.185e-02	  
 2020-01-31 15:04:11 Iteration 3750 	 Training Loss: 5.466e-02 	 Loss in Target Net: 1.116e-02	  
 2020-01-31 15:05:16 Iteration 3800 	 Training Loss: 6.191e-02 	 Loss in Target Net: 1.083e-02	  
 2020-01-31 15:06:23 Iteration 3850 	 Training Loss: 6.015e-02 	 Loss in Target Net: 1.178e-02	  
 2020-01-31 15:07:29 Iteration 3900 	 Training Loss: 6.005e-02 	 Loss in Target Net: 9.759e-03	  
 2020-01-31 15:08:35 Iteration 3950 	 Training Loss: 5.505e-02 	 Loss in Target Net: 1.021e-02	  
 2020-01-31 15:09:40 Iteration 3999 	 Training Loss: 5.461e-02 	 Loss in Target Net: 9.756e-03	  
Evaluating against victims networks
DPN92
Using Adam for retraining
Files already downloaded and verified
2020-01-31 15:09:44, Epoch 0, Iteration 7, loss 3.735 (5.316), acc 82.692 (65.200)
2020-01-31 15:09:45, Epoch 30, Iteration 7, loss 0.034 (0.075), acc 96.154 (97.800)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-2.3670616, -37.643875, -29.717121, 1.6921936, -20.275793, -13.562008, 17.684029, -50.835392, 27.573328, -101.83303], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-01-31 15:09:49 Epoch 59, Val iteration 0, acc 91.200 (91.200)
2020-01-31 15:09:56 Epoch 59, Val iteration 19, acc 91.400 (91.620)
* Prec: 91.62000160217285
--------
SENet18
Using Adam for retraining
Files already downloaded and verified
2020-01-31 15:09:58, Epoch 0, Iteration 7, loss 1.196 (0.810), acc 90.385 (88.200)
2020-01-31 15:09:59, Epoch 30, Iteration 7, loss 0.018 (0.161), acc 100.000 (96.000)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[3.0272992, -18.860796, -8.42095, -4.050606, -1.2240441, -7.140383, 17.93664, -12.877124, 15.955425, -19.37727], Poisons' Predictions:[8, 8, 8, 8, 6]
2020-01-31 15:09:59 Epoch 59, Val iteration 0, acc 92.200 (92.200)
2020-01-31 15:10:01 Epoch 59, Val iteration 19, acc 92.800 (91.260)
* Prec: 91.26000137329102
--------
ResNet50
Using Adam for retraining
Files already downloaded and verified
2020-01-31 15:10:04, Epoch 0, Iteration 7, loss 0.121 (1.066), acc 96.154 (86.600)
2020-01-31 15:10:04, Epoch 30, Iteration 7, loss 0.000 (0.002), acc 100.000 (99.800)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-30.67706, -27.261475, -62.385536, -36.69944, -62.90897, -52.434654, 29.467733, 23.4489, 42.25744, -55.055893], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-01-31 15:10:05 Epoch 59, Val iteration 0, acc 92.000 (92.000)
2020-01-31 15:10:09 Epoch 59, Val iteration 19, acc 94.200 (92.980)
* Prec: 92.98000106811523
--------
ResNeXt29_2x64d
Using Adam for retraining
Files already downloaded and verified
2020-01-31 15:10:12, Epoch 0, Iteration 7, loss 1.592 (2.489), acc 84.615 (75.600)
2020-01-31 15:10:12, Epoch 30, Iteration 7, loss 0.001 (0.019), acc 100.000 (99.400)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-26.001469, -18.974106, 2.0241098, 17.023327, -29.077532, -20.715261, 10.771412, -12.416995, 22.241852, -18.518532], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-01-31 15:10:13 Epoch 59, Val iteration 0, acc 93.400 (93.400)
2020-01-31 15:10:18 Epoch 59, Val iteration 19, acc 92.200 (92.200)
* Prec: 92.2000015258789
--------
GoogLeNet
Using Adam for retraining
Files already downloaded and verified
2020-01-31 15:10:20, Epoch 0, Iteration 7, loss 0.338 (0.539), acc 88.462 (88.800)
2020-01-31 15:10:21, Epoch 30, Iteration 7, loss 0.052 (0.039), acc 96.154 (98.200)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-27.200808, -7.305656, -7.288829, -2.4736788, -16.302572, -3.9998426, 10.36362, 4.3499575, 11.890582, -19.273952], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-01-31 15:10:23 Epoch 59, Val iteration 0, acc 90.600 (90.600)
2020-01-31 15:10:28 Epoch 59, Val iteration 19, acc 91.000 (91.820)
* Prec: 91.8200008392334
--------
MobileNetV2
Using Adam for retraining
Files already downloaded and verified
2020-01-31 15:10:30, Epoch 0, Iteration 7, loss 3.206 (3.293), acc 75.000 (68.600)
2020-01-31 15:10:30, Epoch 30, Iteration 7, loss 0.198 (0.141), acc 94.231 (96.000)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-6.3573112, -0.27666607, 4.259048, 4.3091807, -56.75238, -2.4745643, -1.3051872, -11.277712, 27.3171, -57.507366], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-01-31 15:10:31 Epoch 59, Val iteration 0, acc 88.000 (88.000)
2020-01-31 15:10:33 Epoch 59, Val iteration 19, acc 87.000 (86.490)
* Prec: 86.49000205993653
--------
ResNet18
Using Adam for retraining
Files already downloaded and verified
2020-01-31 15:10:35, Epoch 0, Iteration 7, loss 0.489 (0.596), acc 92.308 (87.400)
2020-01-31 15:10:35, Epoch 30, Iteration 7, loss 0.008 (0.038), acc 100.000 (98.800)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-37.15662, -2.6274145, -13.737485, 2.4847355, -50.799488, -9.224023, 8.34081, -26.440687, 9.058272, -32.61088], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-01-31 15:10:36 Epoch 59, Val iteration 0, acc 93.600 (93.600)
2020-01-31 15:10:38 Epoch 59, Val iteration 19, acc 93.600 (92.820)
* Prec: 92.82000007629395
--------
DenseNet121
Using Adam for retraining
Files already downloaded and verified
2020-01-31 15:10:41, Epoch 0, Iteration 7, loss 0.314 (0.377), acc 94.231 (93.200)
2020-01-31 15:10:41, Epoch 30, Iteration 7, loss 0.000 (0.003), acc 100.000 (100.000)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-6.5327125, -13.944031, -10.615482, -1.881144, -11.36766, -4.3686523, 8.196701, -32.184242, 5.170927, -15.341298], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-01-31 15:10:43 Epoch 59, Val iteration 0, acc 94.000 (94.000)
2020-01-31 15:10:47 Epoch 59, Val iteration 19, acc 93.200 (93.060)
* Prec: 93.06000061035157
--------
------SUMMARY------
TIME ELAPSED (mins): 87
TARGET INDEX: 34
DPN92 1
SENet18 0
ResNet50 1
ResNeXt29_2x64d 1
GoogLeNet 1
MobileNetV2 1
ResNet18 1
DenseNet121 0
