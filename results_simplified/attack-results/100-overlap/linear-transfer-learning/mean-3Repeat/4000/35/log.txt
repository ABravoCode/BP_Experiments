Namespace(chk_path='chk-black-ourmean/', chk_subdir='poisons', device='cuda', dset_path='datasets', end2end=False, eval_poison_path='', gpu='3', lr_decay_epoch=[30, 45], mode='mean', model_resume_path='model-chks', nearest=False, net_repeat=3, num_per_class=50, original_grad=True, poison_decay_ites=[], poison_decay_ratio=0.1, poison_epsilon=0.1, poison_ites=4000, poison_label=8, poison_lr=0.04, poison_momentum=0.9, poison_num=5, poison_opt='adam', resume_poison_ite=0, retrain_bsize=64, retrain_epochs=60, retrain_lr=0.1, retrain_momentum=0.9, retrain_opt='adam', retrain_wd=0, subs_chk_name=['ckpt-%s-4800-dp0.200-droplayer0.000-seed1226.t7', 'ckpt-%s-4800-dp0.250-droplayer0.000-seed1226.t7', 'ckpt-%s-4800-dp0.300-droplayer0.000.t7'], subs_dp=[0.2, 0.25, 0.3], subset_group=0, substitute_nets=['DPN92', 'SENet18', 'ResNet50', 'ResNeXt29_2x64d', 'GoogLeNet', 'MobileNetV2'], target_index=35, target_label=6, target_net=['DPN92', 'SENet18', 'ResNet50', 'ResNeXt29_2x64d', 'GoogLeNet', 'MobileNetV2', 'ResNet18', 'DenseNet121'], test_chk_name='ckpt-%s-4800.t7', tol=1e-06, train_data_path='datasets/CIFAR10_TRAIN_Split.pth')
Path: chk-black-ourmean/mean-3Repeat/4000/35
Selected base image indices: [213, 225, 227, 247, 249]
 2020-01-31 13:27:23 Iteration 0 	 Training Loss: 1.111e+00 	 Loss in Target Net: 3.886e-01	  
 2020-01-31 13:28:31 Iteration 50 	 Training Loss: 7.323e-02 	 Loss in Target Net: 9.424e-03	  
 2020-01-31 13:29:38 Iteration 100 	 Training Loss: 5.407e-02 	 Loss in Target Net: 7.178e-03	  
 2020-01-31 13:30:46 Iteration 150 	 Training Loss: 5.946e-02 	 Loss in Target Net: 8.663e-03	  
 2020-01-31 13:31:53 Iteration 200 	 Training Loss: 5.327e-02 	 Loss in Target Net: 7.638e-03	  
 2020-01-31 13:33:00 Iteration 250 	 Training Loss: 5.374e-02 	 Loss in Target Net: 6.989e-03	  
 2020-01-31 13:34:07 Iteration 300 	 Training Loss: 5.121e-02 	 Loss in Target Net: 7.365e-03	  
 2020-01-31 13:35:15 Iteration 350 	 Training Loss: 5.132e-02 	 Loss in Target Net: 8.711e-03	  
 2020-01-31 13:36:22 Iteration 400 	 Training Loss: 4.994e-02 	 Loss in Target Net: 7.151e-03	  
 2020-01-31 13:37:31 Iteration 450 	 Training Loss: 4.944e-02 	 Loss in Target Net: 7.616e-03	  
 2020-01-31 13:38:38 Iteration 500 	 Training Loss: 4.890e-02 	 Loss in Target Net: 7.472e-03	  
 2020-01-31 13:39:45 Iteration 550 	 Training Loss: 5.063e-02 	 Loss in Target Net: 7.554e-03	  
 2020-01-31 13:40:54 Iteration 600 	 Training Loss: 4.874e-02 	 Loss in Target Net: 6.849e-03	  
 2020-01-31 13:42:03 Iteration 650 	 Training Loss: 5.181e-02 	 Loss in Target Net: 9.213e-03	  
 2020-01-31 13:43:04 Iteration 700 	 Training Loss: 5.245e-02 	 Loss in Target Net: 7.889e-03	  
 2020-01-31 13:44:04 Iteration 750 	 Training Loss: 4.490e-02 	 Loss in Target Net: 9.121e-03	  
 2020-01-31 13:45:05 Iteration 800 	 Training Loss: 4.834e-02 	 Loss in Target Net: 7.735e-03	  
 2020-01-31 13:46:05 Iteration 850 	 Training Loss: 4.946e-02 	 Loss in Target Net: 9.136e-03	  
 2020-01-31 13:47:05 Iteration 900 	 Training Loss: 4.834e-02 	 Loss in Target Net: 9.027e-03	  
 2020-01-31 13:48:05 Iteration 950 	 Training Loss: 4.684e-02 	 Loss in Target Net: 8.415e-03	  
 2020-01-31 13:49:05 Iteration 1000 	 Training Loss: 4.837e-02 	 Loss in Target Net: 1.013e-02	  
 2020-01-31 13:50:05 Iteration 1050 	 Training Loss: 4.511e-02 	 Loss in Target Net: 6.854e-03	  
 2020-01-31 13:51:07 Iteration 1100 	 Training Loss: 4.832e-02 	 Loss in Target Net: 9.134e-03	  
 2020-01-31 13:52:06 Iteration 1150 	 Training Loss: 5.152e-02 	 Loss in Target Net: 1.037e-02	  
 2020-01-31 13:53:07 Iteration 1200 	 Training Loss: 4.602e-02 	 Loss in Target Net: 9.553e-03	  
 2020-01-31 13:54:07 Iteration 1250 	 Training Loss: 4.963e-02 	 Loss in Target Net: 8.012e-03	  
 2020-01-31 13:55:08 Iteration 1300 	 Training Loss: 4.729e-02 	 Loss in Target Net: 9.510e-03	  
 2020-01-31 13:56:07 Iteration 1350 	 Training Loss: 4.602e-02 	 Loss in Target Net: 8.205e-03	  
 2020-01-31 13:57:08 Iteration 1400 	 Training Loss: 4.659e-02 	 Loss in Target Net: 9.942e-03	  
 2020-01-31 13:58:08 Iteration 1450 	 Training Loss: 4.582e-02 	 Loss in Target Net: 8.211e-03	  
 2020-01-31 13:59:08 Iteration 1500 	 Training Loss: 4.780e-02 	 Loss in Target Net: 7.443e-03	  
 2020-01-31 14:00:09 Iteration 1550 	 Training Loss: 4.870e-02 	 Loss in Target Net: 8.140e-03	  
 2020-01-31 14:01:09 Iteration 1600 	 Training Loss: 4.945e-02 	 Loss in Target Net: 1.021e-02	  
 2020-01-31 14:02:10 Iteration 1650 	 Training Loss: 4.680e-02 	 Loss in Target Net: 7.431e-03	  
 2020-01-31 14:03:09 Iteration 1700 	 Training Loss: 4.938e-02 	 Loss in Target Net: 8.937e-03	  
 2020-01-31 14:04:09 Iteration 1750 	 Training Loss: 5.122e-02 	 Loss in Target Net: 7.301e-03	  
 2020-01-31 14:05:09 Iteration 1800 	 Training Loss: 4.937e-02 	 Loss in Target Net: 1.092e-02	  
 2020-01-31 14:06:09 Iteration 1850 	 Training Loss: 4.527e-02 	 Loss in Target Net: 1.222e-02	  
 2020-01-31 14:07:09 Iteration 1900 	 Training Loss: 4.839e-02 	 Loss in Target Net: 8.353e-03	  
 2020-01-31 14:08:09 Iteration 1950 	 Training Loss: 4.178e-02 	 Loss in Target Net: 8.867e-03	  
 2020-01-31 14:09:10 Iteration 2000 	 Training Loss: 4.724e-02 	 Loss in Target Net: 1.093e-02	  
 2020-01-31 14:10:11 Iteration 2050 	 Training Loss: 4.483e-02 	 Loss in Target Net: 6.305e-03	  
 2020-01-31 14:11:11 Iteration 2100 	 Training Loss: 5.008e-02 	 Loss in Target Net: 8.382e-03	  
 2020-01-31 14:12:11 Iteration 2150 	 Training Loss: 4.422e-02 	 Loss in Target Net: 8.039e-03	  
 2020-01-31 14:13:11 Iteration 2200 	 Training Loss: 4.494e-02 	 Loss in Target Net: 9.253e-03	  
 2020-01-31 14:14:11 Iteration 2250 	 Training Loss: 4.991e-02 	 Loss in Target Net: 9.464e-03	  
 2020-01-31 14:15:12 Iteration 2300 	 Training Loss: 4.909e-02 	 Loss in Target Net: 1.102e-02	  
 2020-01-31 14:16:12 Iteration 2350 	 Training Loss: 4.901e-02 	 Loss in Target Net: 1.096e-02	  
 2020-01-31 14:17:13 Iteration 2400 	 Training Loss: 4.691e-02 	 Loss in Target Net: 1.143e-02	  
 2020-01-31 14:18:12 Iteration 2450 	 Training Loss: 4.889e-02 	 Loss in Target Net: 1.309e-02	  
 2020-01-31 14:19:12 Iteration 2500 	 Training Loss: 4.582e-02 	 Loss in Target Net: 9.341e-03	  
 2020-01-31 14:20:11 Iteration 2550 	 Training Loss: 4.984e-02 	 Loss in Target Net: 1.038e-02	  
 2020-01-31 14:21:12 Iteration 2600 	 Training Loss: 4.808e-02 	 Loss in Target Net: 7.878e-03	  
 2020-01-31 14:22:11 Iteration 2650 	 Training Loss: 4.536e-02 	 Loss in Target Net: 8.250e-03	  
 2020-01-31 14:23:11 Iteration 2700 	 Training Loss: 4.735e-02 	 Loss in Target Net: 8.424e-03	  
 2020-01-31 14:24:10 Iteration 2750 	 Training Loss: 4.461e-02 	 Loss in Target Net: 1.021e-02	  
 2020-01-31 14:25:10 Iteration 2800 	 Training Loss: 4.837e-02 	 Loss in Target Net: 9.611e-03	  
 2020-01-31 14:26:09 Iteration 2850 	 Training Loss: 4.588e-02 	 Loss in Target Net: 6.274e-03	  
 2020-01-31 14:27:09 Iteration 2900 	 Training Loss: 4.581e-02 	 Loss in Target Net: 6.531e-03	  
 2020-01-31 14:28:10 Iteration 2950 	 Training Loss: 4.907e-02 	 Loss in Target Net: 8.298e-03	  
 2020-01-31 14:29:10 Iteration 3000 	 Training Loss: 4.706e-02 	 Loss in Target Net: 6.643e-03	  
 2020-01-31 14:30:10 Iteration 3050 	 Training Loss: 4.648e-02 	 Loss in Target Net: 8.067e-03	  
 2020-01-31 14:31:10 Iteration 3100 	 Training Loss: 4.939e-02 	 Loss in Target Net: 9.029e-03	  
 2020-01-31 14:32:09 Iteration 3150 	 Training Loss: 4.481e-02 	 Loss in Target Net: 9.082e-03	  
 2020-01-31 14:33:08 Iteration 3200 	 Training Loss: 4.720e-02 	 Loss in Target Net: 9.435e-03	  
 2020-01-31 14:34:08 Iteration 3250 	 Training Loss: 4.421e-02 	 Loss in Target Net: 9.302e-03	  
 2020-01-31 14:35:08 Iteration 3300 	 Training Loss: 4.826e-02 	 Loss in Target Net: 1.037e-02	  
 2020-01-31 14:36:08 Iteration 3350 	 Training Loss: 4.731e-02 	 Loss in Target Net: 8.879e-03	  
 2020-01-31 14:37:08 Iteration 3400 	 Training Loss: 4.807e-02 	 Loss in Target Net: 1.047e-02	  
 2020-01-31 14:38:08 Iteration 3450 	 Training Loss: 5.140e-02 	 Loss in Target Net: 9.470e-03	  
 2020-01-31 14:39:08 Iteration 3500 	 Training Loss: 4.428e-02 	 Loss in Target Net: 9.064e-03	  
 2020-01-31 14:40:08 Iteration 3550 	 Training Loss: 4.592e-02 	 Loss in Target Net: 1.101e-02	  
 2020-01-31 14:41:07 Iteration 3600 	 Training Loss: 4.827e-02 	 Loss in Target Net: 9.055e-03	  
 2020-01-31 14:42:07 Iteration 3650 	 Training Loss: 4.694e-02 	 Loss in Target Net: 1.223e-02	  
 2020-01-31 14:43:07 Iteration 3700 	 Training Loss: 4.411e-02 	 Loss in Target Net: 1.200e-02	  
 2020-01-31 14:44:08 Iteration 3750 	 Training Loss: 4.722e-02 	 Loss in Target Net: 1.281e-02	  
 2020-01-31 14:45:07 Iteration 3800 	 Training Loss: 4.558e-02 	 Loss in Target Net: 9.107e-03	  
 2020-01-31 14:46:07 Iteration 3850 	 Training Loss: 4.750e-02 	 Loss in Target Net: 1.003e-02	  
 2020-01-31 14:47:06 Iteration 3900 	 Training Loss: 4.946e-02 	 Loss in Target Net: 9.045e-03	  
 2020-01-31 14:48:05 Iteration 3950 	 Training Loss: 4.598e-02 	 Loss in Target Net: 9.938e-03	  
 2020-01-31 14:49:03 Iteration 3999 	 Training Loss: 4.527e-02 	 Loss in Target Net: 6.616e-03	  
Evaluating against victims networks
DPN92
Using Adam for retraining
Files already downloaded and verified
2020-01-31 14:49:08, Epoch 0, Iteration 7, loss 2.675 (5.043), acc 86.538 (62.400)
2020-01-31 14:49:08, Epoch 30, Iteration 7, loss 0.109 (0.089), acc 98.077 (98.000)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[22.31023, -2.9798925, -44.112324, -2.1529272, -25.19975, -12.736263, 43.384613, -42.17653, 41.263042, -92.45963], Poisons' Predictions:[6, 6, 8, 8, 8]
2020-01-31 14:49:12 Epoch 59, Val iteration 0, acc 91.800 (91.800)
2020-01-31 14:49:19 Epoch 59, Val iteration 19, acc 92.600 (92.380)
* Prec: 92.38000144958497
--------
SENet18
Using Adam for retraining
Files already downloaded and verified
2020-01-31 14:49:21, Epoch 0, Iteration 7, loss 0.739 (0.671), acc 92.308 (89.200)
2020-01-31 14:49:21, Epoch 30, Iteration 7, loss 0.104 (0.191), acc 94.231 (95.600)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-4.086395, -12.561148, -13.108401, -1.5121008, 9.913572, -11.791072, 26.228952, -9.341495, 23.965963, -21.046501], Poisons' Predictions:[8, 6, 6, 8, 6]
2020-01-31 14:49:22 Epoch 59, Val iteration 0, acc 90.600 (90.600)
2020-01-31 14:49:24 Epoch 59, Val iteration 19, acc 93.400 (91.010)
* Prec: 91.01000213623047
--------
ResNet50
Using Adam for retraining
Files already downloaded and verified
2020-01-31 14:49:26, Epoch 0, Iteration 7, loss 1.161 (0.531), acc 90.385 (92.000)
2020-01-31 14:49:27, Epoch 30, Iteration 7, loss 0.000 (0.083), acc 100.000 (99.000)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-15.559188, -12.094955, -25.916553, 15.247451, -86.54312, -43.866528, 33.691154, -125.167755, 37.483784, -17.309322], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-01-31 14:49:28 Epoch 59, Val iteration 0, acc 93.400 (93.400)
2020-01-31 14:49:32 Epoch 59, Val iteration 19, acc 92.800 (92.780)
* Prec: 92.78000144958496
--------
ResNeXt29_2x64d
Using Adam for retraining
Files already downloaded and verified
2020-01-31 14:49:34, Epoch 0, Iteration 7, loss 1.220 (2.385), acc 78.846 (74.200)
2020-01-31 14:49:34, Epoch 30, Iteration 7, loss 0.005 (0.045), acc 100.000 (98.200)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-42.718536, -14.809282, 7.43696, 18.833187, -50.583412, -8.788398, 41.611748, -24.706734, 43.371746, -28.439285], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-01-31 14:49:36 Epoch 59, Val iteration 0, acc 93.200 (93.200)
2020-01-31 14:49:40 Epoch 59, Val iteration 19, acc 92.400 (92.800)
* Prec: 92.80000305175781
--------
GoogLeNet
Using Adam for retraining
Files already downloaded and verified
2020-01-31 14:49:42, Epoch 0, Iteration 7, loss 0.203 (0.559), acc 96.154 (86.600)
2020-01-31 14:49:43, Epoch 30, Iteration 7, loss 0.144 (0.046), acc 92.308 (97.600)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-13.410542, -8.276382, -9.326617, 0.27931178, -9.18924, -4.779528, 13.753522, -3.8346713, 10.038015, -13.069593], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-01-31 14:49:45 Epoch 59, Val iteration 0, acc 90.800 (90.800)
2020-01-31 14:49:50 Epoch 59, Val iteration 19, acc 90.200 (91.750)
* Prec: 91.75000190734863
--------
MobileNetV2
Using Adam for retraining
Files already downloaded and verified
2020-01-31 14:49:52, Epoch 0, Iteration 7, loss 1.180 (2.712), acc 73.077 (62.600)
2020-01-31 14:49:52, Epoch 30, Iteration 7, loss 0.155 (0.173), acc 94.231 (93.800)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-2.9227097, -7.966509, -5.1393485, 14.794675, -21.389503, -2.8259916, 31.193838, -34.964104, 24.587639, -22.666498], Poisons' Predictions:[8, 8, 6, 8, 8]
2020-01-31 14:49:53 Epoch 59, Val iteration 0, acc 88.600 (88.600)
2020-01-31 14:49:55 Epoch 59, Val iteration 19, acc 85.800 (86.590)
* Prec: 86.59000129699707
--------
ResNet18
Using Adam for retraining
Files already downloaded and verified
2020-01-31 14:49:57, Epoch 0, Iteration 7, loss 0.517 (0.758), acc 90.385 (88.200)
2020-01-31 14:49:57, Epoch 30, Iteration 7, loss 0.008 (0.035), acc 100.000 (99.000)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-31.295864, -16.80068, -11.749465, 0.6937292, -34.76696, -7.508984, 9.642688, -12.27328, 6.550292, -36.532444], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-01-31 14:49:57 Epoch 59, Val iteration 0, acc 93.200 (93.200)
2020-01-31 14:49:59 Epoch 59, Val iteration 19, acc 93.800 (92.640)
* Prec: 92.6400016784668
--------
DenseNet121
Using Adam for retraining
Files already downloaded and verified
2020-01-31 14:50:02, Epoch 0, Iteration 7, loss 0.078 (0.392), acc 94.231 (92.200)
2020-01-31 14:50:02, Epoch 30, Iteration 7, loss 0.001 (0.021), acc 100.000 (99.200)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-6.059442, -19.490646, -11.420048, -1.9969906, -5.579629, -5.344982, 8.79298, -31.354435, 5.8029437, -16.461735], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-01-31 14:50:04 Epoch 59, Val iteration 0, acc 94.000 (94.000)
2020-01-31 14:50:09 Epoch 59, Val iteration 19, acc 93.400 (93.170)
* Prec: 93.17000160217285
--------
------SUMMARY------
TIME ELAPSED (mins): 81
TARGET INDEX: 35
DPN92 0
SENet18 0
ResNet50 1
ResNeXt29_2x64d 1
GoogLeNet 0
MobileNetV2 0
ResNet18 0
DenseNet121 0
