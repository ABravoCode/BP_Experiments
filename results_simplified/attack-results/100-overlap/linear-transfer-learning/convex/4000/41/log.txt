Namespace(chk_path='chk-black', chk_subdir='poisons', device='cuda', dset_path='datasets', end2end=False, eval_poison_path='', gpu='7', lr_decay_epoch=[30, 45], mode='convex', model_resume_path='model-chks', nearest=False, net_repeat=1, num_per_class=50, original_grad=True, poison_decay_ites=[], poison_decay_ratio=0.1, poison_epsilon=0.1, poison_ites=4000, poison_label=8, poison_lr=0.04, poison_momentum=0.9, poison_num=5, poison_opt='adam', resume_poison_ite=0, retrain_bsize=64, retrain_epochs=60, retrain_lr=0.1, retrain_momentum=0.9, retrain_opt='adam', retrain_wd=0, subs_chk_name=['ckpt-%s-4800-dp0.200-droplayer0.000-seed1226.t7', 'ckpt-%s-4800-dp0.250-droplayer0.000-seed1226.t7', 'ckpt-%s-4800-dp0.300-droplayer0.000.t7'], subs_dp=[0.2, 0.25, 0.3], subset_group=0, substitute_nets=['DPN92', 'SENet18', 'ResNet50', 'ResNeXt29_2x64d', 'GoogLeNet', 'MobileNetV2'], target_index=41, target_label=6, target_net=['DPN92', 'SENet18', 'ResNet50', 'ResNeXt29_2x64d', 'GoogLeNet', 'MobileNetV2', 'ResNet18', 'DenseNet121'], test_chk_name='ckpt-%s-4800.t7', tol=1e-06, train_data_path='datasets/CIFAR10_TRAIN_Split.pth')
Path: chk-black/convex/4000/41
Selected base image indices: [213, 225, 227, 247, 249]
 2020-02-01 23:32:05 Iteration 0 	 Training Loss: 5.405e-01 	 Loss in Target Net: 4.740e-01	  
 2020-02-01 23:36:29 Iteration 50 	 Training Loss: 5.257e-03 	 Loss in Target Net: 1.239e-02	  
 2020-02-01 23:42:45 Iteration 100 	 Training Loss: 3.648e-03 	 Loss in Target Net: 1.217e-02	  
 2020-02-01 23:49:52 Iteration 150 	 Training Loss: 3.169e-03 	 Loss in Target Net: 1.632e-02	  
 2020-02-01 23:57:35 Iteration 200 	 Training Loss: 3.104e-03 	 Loss in Target Net: 1.339e-02	  
 2020-02-02 00:05:12 Iteration 250 	 Training Loss: 2.601e-03 	 Loss in Target Net: 1.179e-02	  
 2020-02-02 00:13:08 Iteration 300 	 Training Loss: 2.306e-03 	 Loss in Target Net: 1.295e-02	  
 2020-02-02 00:21:27 Iteration 350 	 Training Loss: 2.391e-03 	 Loss in Target Net: 1.414e-02	  
 2020-02-02 00:29:49 Iteration 400 	 Training Loss: 2.229e-03 	 Loss in Target Net: 8.316e-03	  
 2020-02-02 00:38:38 Iteration 450 	 Training Loss: 2.297e-03 	 Loss in Target Net: 9.774e-03	  
 2020-02-02 00:47:40 Iteration 500 	 Training Loss: 1.964e-03 	 Loss in Target Net: 1.115e-02	  
 2020-02-02 00:56:45 Iteration 550 	 Training Loss: 2.271e-03 	 Loss in Target Net: 1.474e-02	  
 2020-02-02 01:05:50 Iteration 600 	 Training Loss: 1.893e-03 	 Loss in Target Net: 1.124e-02	  
 2020-02-02 01:15:02 Iteration 650 	 Training Loss: 1.944e-03 	 Loss in Target Net: 8.259e-03	  
 2020-02-02 01:24:09 Iteration 700 	 Training Loss: 2.387e-03 	 Loss in Target Net: 8.491e-03	  
 2020-02-02 01:32:51 Iteration 750 	 Training Loss: 1.901e-03 	 Loss in Target Net: 1.224e-02	  
 2020-02-02 01:42:33 Iteration 800 	 Training Loss: 1.711e-03 	 Loss in Target Net: 1.006e-02	  
 2020-02-02 01:51:40 Iteration 850 	 Training Loss: 2.146e-03 	 Loss in Target Net: 8.731e-03	  
 2020-02-02 02:00:52 Iteration 900 	 Training Loss: 2.066e-03 	 Loss in Target Net: 1.021e-02	  
 2020-02-02 02:10:06 Iteration 950 	 Training Loss: 1.674e-03 	 Loss in Target Net: 7.113e-03	  
 2020-02-02 02:19:00 Iteration 1000 	 Training Loss: 1.973e-03 	 Loss in Target Net: 7.635e-03	  
 2020-02-02 02:28:07 Iteration 1050 	 Training Loss: 2.096e-03 	 Loss in Target Net: 6.959e-03	  
 2020-02-02 02:36:47 Iteration 1100 	 Training Loss: 2.207e-03 	 Loss in Target Net: 1.110e-02	  
 2020-02-02 02:46:01 Iteration 1150 	 Training Loss: 1.792e-03 	 Loss in Target Net: 7.326e-03	  
 2020-02-02 02:55:04 Iteration 1200 	 Training Loss: 1.919e-03 	 Loss in Target Net: 9.614e-03	  
 2020-02-02 03:04:24 Iteration 1250 	 Training Loss: 1.753e-03 	 Loss in Target Net: 8.168e-03	  
 2020-02-02 03:13:51 Iteration 1300 	 Training Loss: 1.991e-03 	 Loss in Target Net: 6.881e-03	  
 2020-02-02 03:22:50 Iteration 1350 	 Training Loss: 2.016e-03 	 Loss in Target Net: 7.403e-03	  
 2020-02-02 03:31:52 Iteration 1400 	 Training Loss: 1.982e-03 	 Loss in Target Net: 7.705e-03	  
 2020-02-02 03:40:57 Iteration 1450 	 Training Loss: 1.745e-03 	 Loss in Target Net: 5.481e-03	  
 2020-02-02 03:50:06 Iteration 1500 	 Training Loss: 1.825e-03 	 Loss in Target Net: 6.718e-03	  
 2020-02-02 03:58:51 Iteration 1550 	 Training Loss: 1.893e-03 	 Loss in Target Net: 5.323e-03	  
 2020-02-02 04:08:03 Iteration 1600 	 Training Loss: 1.989e-03 	 Loss in Target Net: 8.715e-03	  
 2020-02-02 04:16:42 Iteration 1650 	 Training Loss: 1.858e-03 	 Loss in Target Net: 1.454e-02	  
 2020-02-02 04:25:26 Iteration 1700 	 Training Loss: 1.702e-03 	 Loss in Target Net: 9.166e-03	  
 2020-02-02 04:34:35 Iteration 1750 	 Training Loss: 1.544e-03 	 Loss in Target Net: 1.356e-02	  
 2020-02-02 04:43:18 Iteration 1800 	 Training Loss: 2.123e-03 	 Loss in Target Net: 8.376e-03	  
 2020-02-02 04:52:16 Iteration 1850 	 Training Loss: 1.517e-03 	 Loss in Target Net: 9.307e-03	  
 2020-02-02 05:01:10 Iteration 1900 	 Training Loss: 1.498e-03 	 Loss in Target Net: 7.388e-03	  
 2020-02-02 05:10:23 Iteration 1950 	 Training Loss: 1.990e-03 	 Loss in Target Net: 1.305e-02	  
 2020-02-02 05:19:54 Iteration 2000 	 Training Loss: 1.866e-03 	 Loss in Target Net: 8.597e-03	  
 2020-02-02 05:29:33 Iteration 2050 	 Training Loss: 1.981e-03 	 Loss in Target Net: 5.559e-03	  
 2020-02-02 05:38:38 Iteration 2100 	 Training Loss: 1.679e-03 	 Loss in Target Net: 5.763e-03	  
 2020-02-02 05:48:08 Iteration 2150 	 Training Loss: 1.519e-03 	 Loss in Target Net: 6.771e-03	  
 2020-02-02 05:57:02 Iteration 2200 	 Training Loss: 1.549e-03 	 Loss in Target Net: 5.936e-03	  
 2020-02-02 06:06:11 Iteration 2250 	 Training Loss: 1.911e-03 	 Loss in Target Net: 2.460e-03	  
 2020-02-02 06:15:44 Iteration 2300 	 Training Loss: 1.551e-03 	 Loss in Target Net: 6.668e-03	  
 2020-02-02 06:24:55 Iteration 2350 	 Training Loss: 1.752e-03 	 Loss in Target Net: 6.740e-03	  
 2020-02-02 06:33:38 Iteration 2400 	 Training Loss: 1.664e-03 	 Loss in Target Net: 7.271e-03	  
 2020-02-02 06:43:00 Iteration 2450 	 Training Loss: 1.776e-03 	 Loss in Target Net: 9.647e-03	  
 2020-02-02 06:51:29 Iteration 2500 	 Training Loss: 1.697e-03 	 Loss in Target Net: 7.158e-03	  
 2020-02-02 07:00:22 Iteration 2550 	 Training Loss: 1.690e-03 	 Loss in Target Net: 7.179e-03	  
 2020-02-02 07:09:18 Iteration 2600 	 Training Loss: 1.684e-03 	 Loss in Target Net: 6.041e-03	  
 2020-02-02 07:17:56 Iteration 2650 	 Training Loss: 1.895e-03 	 Loss in Target Net: 7.072e-03	  
 2020-02-02 07:27:09 Iteration 2700 	 Training Loss: 1.483e-03 	 Loss in Target Net: 6.269e-03	  
 2020-02-02 07:36:36 Iteration 2750 	 Training Loss: 1.799e-03 	 Loss in Target Net: 5.645e-03	  
 2020-02-02 07:45:47 Iteration 2800 	 Training Loss: 1.863e-03 	 Loss in Target Net: 7.485e-03	  
 2020-02-02 07:54:46 Iteration 2850 	 Training Loss: 2.133e-03 	 Loss in Target Net: 1.419e-02	  
 2020-02-02 08:03:39 Iteration 2900 	 Training Loss: 1.962e-03 	 Loss in Target Net: 6.839e-03	  
 2020-02-02 08:12:21 Iteration 2950 	 Training Loss: 1.920e-03 	 Loss in Target Net: 1.078e-02	  
 2020-02-02 08:21:17 Iteration 3000 	 Training Loss: 1.945e-03 	 Loss in Target Net: 8.504e-03	  
 2020-02-02 08:29:56 Iteration 3050 	 Training Loss: 1.720e-03 	 Loss in Target Net: 7.955e-03	  
 2020-02-02 08:38:09 Iteration 3100 	 Training Loss: 1.965e-03 	 Loss in Target Net: 8.667e-03	  
 2020-02-02 08:46:54 Iteration 3150 	 Training Loss: 1.754e-03 	 Loss in Target Net: 1.069e-02	  
 2020-02-02 08:55:46 Iteration 3200 	 Training Loss: 1.703e-03 	 Loss in Target Net: 7.370e-03	  
 2020-02-02 09:04:27 Iteration 3250 	 Training Loss: 2.138e-03 	 Loss in Target Net: 6.831e-03	  
 2020-02-02 09:13:51 Iteration 3300 	 Training Loss: 1.790e-03 	 Loss in Target Net: 8.079e-03	  
 2020-02-02 09:23:13 Iteration 3350 	 Training Loss: 1.931e-03 	 Loss in Target Net: 6.168e-03	  
 2020-02-02 09:31:50 Iteration 3400 	 Training Loss: 1.863e-03 	 Loss in Target Net: 1.120e-02	  
 2020-02-02 09:40:01 Iteration 3450 	 Training Loss: 1.802e-03 	 Loss in Target Net: 8.550e-03	  
 2020-02-02 09:48:58 Iteration 3500 	 Training Loss: 1.872e-03 	 Loss in Target Net: 6.158e-03	  
 2020-02-02 09:57:39 Iteration 3550 	 Training Loss: 2.446e-03 	 Loss in Target Net: 7.338e-03	  
 2020-02-02 10:06:43 Iteration 3600 	 Training Loss: 1.731e-03 	 Loss in Target Net: 6.249e-03	  
 2020-02-02 10:15:45 Iteration 3650 	 Training Loss: 1.628e-03 	 Loss in Target Net: 6.548e-03	  
 2020-02-02 10:24:23 Iteration 3700 	 Training Loss: 2.036e-03 	 Loss in Target Net: 9.250e-03	  
 2020-02-02 10:33:24 Iteration 3750 	 Training Loss: 2.023e-03 	 Loss in Target Net: 8.709e-03	  
 2020-02-02 10:41:55 Iteration 3800 	 Training Loss: 1.724e-03 	 Loss in Target Net: 8.472e-03	  
 2020-02-02 10:49:44 Iteration 3850 	 Training Loss: 1.928e-03 	 Loss in Target Net: 1.080e-02	  
 2020-02-02 10:58:15 Iteration 3900 	 Training Loss: 1.816e-03 	 Loss in Target Net: 8.815e-03	  
 2020-02-02 11:06:35 Iteration 3950 	 Training Loss: 1.851e-03 	 Loss in Target Net: 6.857e-03	  
 2020-02-02 11:14:57 Iteration 3999 	 Training Loss: 1.728e-03 	 Loss in Target Net: 6.751e-03	  
Evaluating against victims networks
DPN92
Using Adam for retraining
Files already downloaded and verified
2020-02-02 11:15:15, Epoch 0, Iteration 7, loss 1.123 (3.598), acc 86.538 (71.200)
2020-02-02 11:15:15, Epoch 30, Iteration 7, loss 0.145 (0.271), acc 96.154 (97.000)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-30.355875, -36.9068, -64.34743, 14.848592, -39.738594, 14.219998, 48.70145, -49.074913, 51.75319, -100.743866], Poisons' Predictions:[8, 8, 8, 6, 6]
2020-02-02 11:15:46 Epoch 59, Val iteration 0, acc 90.200 (90.200)
2020-02-02 11:16:34 Epoch 59, Val iteration 19, acc 91.600 (91.990)
* Prec: 91.99000205993653
--------
SENet18
Using Adam for retraining
Files already downloaded and verified
2020-02-02 11:16:39, Epoch 0, Iteration 7, loss 0.190 (0.836), acc 96.154 (88.800)
2020-02-02 11:16:39, Epoch 30, Iteration 7, loss 0.123 (0.156), acc 98.077 (94.200)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-7.159698, -28.995869, -12.157913, -0.93335783, 7.888496, -0.81461877, 16.909142, -28.484936, 18.176437, -16.006754], Poisons' Predictions:[6, 8, 8, 8, 6]
2020-02-02 11:16:43 Epoch 59, Val iteration 0, acc 91.000 (91.000)
2020-02-02 11:16:50 Epoch 59, Val iteration 19, acc 93.000 (91.090)
* Prec: 91.09000205993652
--------
ResNet50
Using Adam for retraining
Files already downloaded and verified
2020-02-02 11:16:57, Epoch 0, Iteration 7, loss 0.081 (0.637), acc 96.154 (88.800)
2020-02-02 11:16:58, Epoch 30, Iteration 7, loss 0.000 (0.035), acc 100.000 (99.400)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-44.012268, -1.2167013, -56.571774, -39.405533, -36.756645, -66.62562, 30.029253, -33.02865, 26.837637, -28.920832], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-02-02 11:17:05 Epoch 59, Val iteration 0, acc 92.200 (92.200)
2020-02-02 11:17:26 Epoch 59, Val iteration 19, acc 93.000 (92.750)
* Prec: 92.75000114440918
--------
ResNeXt29_2x64d
Using Adam for retraining
Files already downloaded and verified
2020-02-02 11:17:32, Epoch 0, Iteration 7, loss 1.408 (2.218), acc 78.846 (72.600)
2020-02-02 11:17:32, Epoch 30, Iteration 7, loss 0.031 (0.116), acc 98.077 (97.200)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-26.258078, -22.908228, -21.647913, 17.239626, -71.80959, -24.867796, 35.98711, -40.916786, 30.37494, -22.708256], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-02-02 11:17:39 Epoch 59, Val iteration 0, acc 92.600 (92.600)
2020-02-02 11:18:01 Epoch 59, Val iteration 19, acc 93.200 (92.240)
* Prec: 92.2400016784668
--------
GoogLeNet
Using Adam for retraining
Files already downloaded and verified
2020-02-02 11:18:09, Epoch 0, Iteration 7, loss 0.403 (0.494), acc 94.231 (88.400)
2020-02-02 11:18:10, Epoch 30, Iteration 7, loss 0.001 (0.050), acc 100.000 (98.200)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-23.764757, -7.8168945, 0.3976854, 3.2842376, -10.908989, 1.9670649, 7.2677054, -13.106759, 5.2838, -17.278143], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-02-02 11:18:25 Epoch 59, Val iteration 0, acc 91.200 (91.200)
2020-02-02 11:18:50 Epoch 59, Val iteration 19, acc 91.600 (91.900)
* Prec: 91.9000015258789
--------
MobileNetV2
Using Adam for retraining
Files already downloaded and verified
2020-02-02 11:18:55, Epoch 0, Iteration 7, loss 1.348 (3.959), acc 82.692 (60.800)
2020-02-02 11:18:55, Epoch 30, Iteration 7, loss 0.298 (0.328), acc 94.231 (92.400)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-0.8256185, -8.117603, -7.8255157, 10.823191, -36.728798, -1.1367999, 22.814856, -29.70924, 25.031439, -25.636852], Poisons' Predictions:[8, 8, 8, 6, 6]
2020-02-02 11:18:59 Epoch 59, Val iteration 0, acc 87.800 (87.800)
2020-02-02 11:19:06 Epoch 59, Val iteration 19, acc 86.600 (86.640)
* Prec: 86.6400016784668
--------
ResNet18
Using Adam for retraining
Files already downloaded and verified
2020-02-02 11:19:09, Epoch 0, Iteration 7, loss 0.572 (0.705), acc 94.231 (83.600)
2020-02-02 11:19:10, Epoch 30, Iteration 7, loss 0.002 (0.009), acc 100.000 (99.800)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-42.741116, -12.639318, -14.69078, -1.1249706, -42.455143, -7.3213835, 6.7023864, -36.685818, 7.521351, -35.284306], Poisons' Predictions:[8, 8, 8, 6, 8]
2020-02-02 11:19:10 Epoch 59, Val iteration 0, acc 94.000 (94.000)
2020-02-02 11:19:17 Epoch 59, Val iteration 19, acc 93.800 (92.910)
* Prec: 92.91000213623047
--------
DenseNet121
Using Adam for retraining
Files already downloaded and verified
2020-02-02 11:19:24, Epoch 0, Iteration 7, loss 0.500 (0.487), acc 94.231 (93.200)
2020-02-02 11:19:25, Epoch 30, Iteration 7, loss 0.004 (0.003), acc 100.000 (100.000)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-8.495578, -9.119497, -11.892511, -0.33379918, -20.237598, -5.878949, 8.25117, -36.5681, 5.7934327, -13.337933], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-02-02 11:19:36 Epoch 59, Val iteration 0, acc 94.200 (94.200)
2020-02-02 11:19:58 Epoch 59, Val iteration 19, acc 93.600 (93.320)
* Prec: 93.32000122070312
--------
------SUMMARY------
TIME ELAPSED (mins): 703
TARGET INDEX: 41
DPN92 1
SENet18 1
ResNet50 0
ResNeXt29_2x64d 0
GoogLeNet 0
MobileNetV2 1
ResNet18 1
DenseNet121 0
