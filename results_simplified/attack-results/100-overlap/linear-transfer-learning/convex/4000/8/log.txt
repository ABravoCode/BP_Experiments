Namespace(chk_path='chk-black', chk_subdir='poisons', device='cuda', dset_path='datasets', end2end=False, eval_poison_path='', gpu='0', lr_decay_epoch=[30, 45], mode='convex', model_resume_path='model-chks', nearest=False, net_repeat=1, num_per_class=50, original_grad=True, poison_decay_ites=[], poison_decay_ratio=0.1, poison_epsilon=0.1, poison_ites=4000, poison_label=8, poison_lr=0.04, poison_momentum=0.9, poison_num=5, poison_opt='adam', resume_poison_ite=0, retrain_bsize=64, retrain_epochs=60, retrain_lr=0.1, retrain_momentum=0.9, retrain_opt='adam', retrain_wd=0, subs_chk_name=['ckpt-%s-4800-dp0.200-droplayer0.000-seed1226.t7', 'ckpt-%s-4800-dp0.250-droplayer0.000-seed1226.t7', 'ckpt-%s-4800-dp0.300-droplayer0.000.t7'], subs_dp=[0.2, 0.25, 0.3], subset_group=0, substitute_nets=['DPN92', 'SENet18', 'ResNet50', 'ResNeXt29_2x64d', 'GoogLeNet', 'MobileNetV2'], target_index=8, target_label=6, target_net=['DPN92', 'SENet18', 'ResNet50', 'ResNeXt29_2x64d', 'GoogLeNet', 'MobileNetV2', 'ResNet18', 'DenseNet121'], test_chk_name='ckpt-%s-4800.t7', tol=1e-06, train_data_path='datasets/CIFAR10_TRAIN_Split.pth')
Path: chk-black/convex/4000/8
Selected base image indices: [213, 225, 227, 247, 249]
 2020-01-26 16:04:33 Iteration 0 	 Training Loss: 4.417e-01 	 Loss in Target Net: 4.106e-01	  
 2020-01-26 16:08:45 Iteration 50 	 Training Loss: 7.719e-03 	 Loss in Target Net: 1.707e-02	  
 2020-01-26 16:14:48 Iteration 100 	 Training Loss: 5.705e-03 	 Loss in Target Net: 1.202e-02	  
 2020-01-26 16:21:32 Iteration 150 	 Training Loss: 4.887e-03 	 Loss in Target Net: 8.355e-03	  
 2020-01-26 16:29:00 Iteration 200 	 Training Loss: 4.040e-03 	 Loss in Target Net: 1.037e-02	  
 2020-01-26 16:36:19 Iteration 250 	 Training Loss: 3.485e-03 	 Loss in Target Net: 9.377e-03	  
 2020-01-26 16:44:04 Iteration 300 	 Training Loss: 3.182e-03 	 Loss in Target Net: 5.627e-03	  
 2020-01-26 16:51:33 Iteration 350 	 Training Loss: 3.332e-03 	 Loss in Target Net: 5.790e-03	  
 2020-01-26 16:59:38 Iteration 400 	 Training Loss: 2.624e-03 	 Loss in Target Net: 8.296e-03	  
 2020-01-26 17:06:56 Iteration 450 	 Training Loss: 3.435e-03 	 Loss in Target Net: 7.703e-03	  
 2020-01-26 17:14:53 Iteration 500 	 Training Loss: 3.017e-03 	 Loss in Target Net: 7.239e-03	  
 2020-01-26 17:23:30 Iteration 550 	 Training Loss: 2.917e-03 	 Loss in Target Net: 8.209e-03	  
 2020-01-26 17:31:35 Iteration 600 	 Training Loss: 3.036e-03 	 Loss in Target Net: 7.740e-03	  
 2020-01-26 17:39:39 Iteration 650 	 Training Loss: 2.881e-03 	 Loss in Target Net: 7.148e-03	  
 2020-01-26 17:47:25 Iteration 700 	 Training Loss: 2.874e-03 	 Loss in Target Net: 1.030e-02	  
 2020-01-26 17:56:07 Iteration 750 	 Training Loss: 2.896e-03 	 Loss in Target Net: 6.917e-03	  
 2020-01-26 18:05:00 Iteration 800 	 Training Loss: 3.069e-03 	 Loss in Target Net: 9.258e-03	  
 2020-01-26 18:13:05 Iteration 850 	 Training Loss: 3.110e-03 	 Loss in Target Net: 6.993e-03	  
 2020-01-26 18:21:24 Iteration 900 	 Training Loss: 2.936e-03 	 Loss in Target Net: 9.369e-03	  
 2020-01-26 18:30:02 Iteration 950 	 Training Loss: 2.480e-03 	 Loss in Target Net: 8.842e-03	  
 2020-01-26 18:38:50 Iteration 1000 	 Training Loss: 3.114e-03 	 Loss in Target Net: 1.047e-02	  
 2020-01-26 18:46:48 Iteration 1050 	 Training Loss: 2.607e-03 	 Loss in Target Net: 8.685e-03	  
 2020-01-26 18:55:18 Iteration 1100 	 Training Loss: 2.546e-03 	 Loss in Target Net: 1.027e-02	  
 2020-01-26 19:04:05 Iteration 1150 	 Training Loss: 2.645e-03 	 Loss in Target Net: 7.955e-03	  
 2020-01-26 19:13:02 Iteration 1200 	 Training Loss: 2.627e-03 	 Loss in Target Net: 9.159e-03	  
 2020-01-26 19:21:36 Iteration 1250 	 Training Loss: 2.673e-03 	 Loss in Target Net: 1.045e-02	  
 2020-01-26 19:30:30 Iteration 1300 	 Training Loss: 2.886e-03 	 Loss in Target Net: 1.064e-02	  
 2020-01-26 19:38:53 Iteration 1350 	 Training Loss: 2.605e-03 	 Loss in Target Net: 1.112e-02	  
 2020-01-26 19:47:23 Iteration 1400 	 Training Loss: 2.800e-03 	 Loss in Target Net: 1.231e-02	  
 2020-01-26 19:56:03 Iteration 1450 	 Training Loss: 2.780e-03 	 Loss in Target Net: 8.582e-03	  
 2020-01-26 20:04:39 Iteration 1500 	 Training Loss: 2.966e-03 	 Loss in Target Net: 1.201e-02	  
 2020-01-26 20:13:55 Iteration 1550 	 Training Loss: 2.589e-03 	 Loss in Target Net: 1.129e-02	  
 2020-01-26 20:22:34 Iteration 1600 	 Training Loss: 2.397e-03 	 Loss in Target Net: 1.182e-02	  
 2020-01-26 20:32:01 Iteration 1650 	 Training Loss: 2.921e-03 	 Loss in Target Net: 1.222e-02	  
 2020-01-26 20:40:51 Iteration 1700 	 Training Loss: 3.153e-03 	 Loss in Target Net: 1.043e-02	  
 2020-01-26 20:49:56 Iteration 1750 	 Training Loss: 2.592e-03 	 Loss in Target Net: 9.832e-03	  
 2020-01-26 20:58:13 Iteration 1800 	 Training Loss: 2.999e-03 	 Loss in Target Net: 9.540e-03	  
 2020-01-26 21:06:37 Iteration 1850 	 Training Loss: 2.918e-03 	 Loss in Target Net: 1.013e-02	  
 2020-01-26 21:15:33 Iteration 1900 	 Training Loss: 2.686e-03 	 Loss in Target Net: 9.553e-03	  
 2020-01-26 21:24:14 Iteration 1950 	 Training Loss: 2.791e-03 	 Loss in Target Net: 1.083e-02	  
 2020-01-26 21:33:12 Iteration 2000 	 Training Loss: 3.039e-03 	 Loss in Target Net: 1.104e-02	  
 2020-01-26 21:41:50 Iteration 2050 	 Training Loss: 2.838e-03 	 Loss in Target Net: 8.375e-03	  
 2020-01-26 21:50:30 Iteration 2100 	 Training Loss: 2.809e-03 	 Loss in Target Net: 9.635e-03	  
 2020-01-26 21:58:58 Iteration 2150 	 Training Loss: 2.723e-03 	 Loss in Target Net: 9.136e-03	  
 2020-01-26 22:07:46 Iteration 2200 	 Training Loss: 2.849e-03 	 Loss in Target Net: 1.082e-02	  
 2020-01-26 22:16:49 Iteration 2250 	 Training Loss: 2.601e-03 	 Loss in Target Net: 8.977e-03	  
 2020-01-26 22:26:39 Iteration 2300 	 Training Loss: 2.760e-03 	 Loss in Target Net: 9.315e-03	  
 2020-01-26 22:36:25 Iteration 2350 	 Training Loss: 2.559e-03 	 Loss in Target Net: 1.537e-02	  
 2020-01-26 22:45:49 Iteration 2400 	 Training Loss: 2.770e-03 	 Loss in Target Net: 1.016e-02	  
 2020-01-26 22:54:54 Iteration 2450 	 Training Loss: 3.040e-03 	 Loss in Target Net: 9.976e-03	  
 2020-01-26 23:03:50 Iteration 2500 	 Training Loss: 3.002e-03 	 Loss in Target Net: 1.054e-02	  
 2020-01-26 23:13:21 Iteration 2550 	 Training Loss: 3.070e-03 	 Loss in Target Net: 8.788e-03	  
 2020-01-26 23:22:22 Iteration 2600 	 Training Loss: 3.060e-03 	 Loss in Target Net: 1.368e-02	  
 2020-01-26 23:31:25 Iteration 2650 	 Training Loss: 3.026e-03 	 Loss in Target Net: 8.447e-03	  
 2020-01-26 23:39:12 Iteration 2700 	 Training Loss: 3.053e-03 	 Loss in Target Net: 1.388e-02	  
 2020-01-26 23:48:12 Iteration 2750 	 Training Loss: 3.083e-03 	 Loss in Target Net: 9.833e-03	  
 2020-01-26 23:58:00 Iteration 2800 	 Training Loss: 2.726e-03 	 Loss in Target Net: 9.848e-03	  
 2020-01-27 00:07:21 Iteration 2850 	 Training Loss: 2.550e-03 	 Loss in Target Net: 1.095e-02	  
 2020-01-27 00:15:57 Iteration 2900 	 Training Loss: 2.640e-03 	 Loss in Target Net: 1.477e-02	  
 2020-01-27 00:24:57 Iteration 2950 	 Training Loss: 2.845e-03 	 Loss in Target Net: 1.166e-02	  
 2020-01-27 00:33:17 Iteration 3000 	 Training Loss: 2.960e-03 	 Loss in Target Net: 1.030e-02	  
 2020-01-27 00:42:07 Iteration 3050 	 Training Loss: 2.798e-03 	 Loss in Target Net: 1.066e-02	  
 2020-01-27 00:50:41 Iteration 3100 	 Training Loss: 2.792e-03 	 Loss in Target Net: 1.359e-02	  
 2020-01-27 00:59:23 Iteration 3150 	 Training Loss: 2.574e-03 	 Loss in Target Net: 1.196e-02	  
 2020-01-27 01:08:17 Iteration 3200 	 Training Loss: 3.187e-03 	 Loss in Target Net: 1.372e-02	  
 2020-01-27 01:17:03 Iteration 3250 	 Training Loss: 2.993e-03 	 Loss in Target Net: 1.266e-02	  
 2020-01-27 01:25:59 Iteration 3300 	 Training Loss: 2.587e-03 	 Loss in Target Net: 1.284e-02	  
 2020-01-27 01:34:11 Iteration 3350 	 Training Loss: 2.776e-03 	 Loss in Target Net: 8.461e-03	  
 2020-01-27 01:42:18 Iteration 3400 	 Training Loss: 3.134e-03 	 Loss in Target Net: 1.484e-02	  
 2020-01-27 01:50:42 Iteration 3450 	 Training Loss: 2.748e-03 	 Loss in Target Net: 1.154e-02	  
 2020-01-27 01:59:40 Iteration 3500 	 Training Loss: 2.918e-03 	 Loss in Target Net: 1.550e-02	  
 2020-01-27 02:08:38 Iteration 3550 	 Training Loss: 2.613e-03 	 Loss in Target Net: 1.532e-02	  
 2020-01-27 02:19:17 Iteration 3600 	 Training Loss: 2.910e-03 	 Loss in Target Net: 1.011e-02	  
 2020-01-27 02:30:20 Iteration 3650 	 Training Loss: 2.930e-03 	 Loss in Target Net: 9.009e-03	  
 2020-01-27 02:41:27 Iteration 3700 	 Training Loss: 2.845e-03 	 Loss in Target Net: 8.361e-03	  
 2020-01-27 02:51:54 Iteration 3750 	 Training Loss: 2.681e-03 	 Loss in Target Net: 9.054e-03	  
 2020-01-27 03:03:57 Iteration 3800 	 Training Loss: 2.785e-03 	 Loss in Target Net: 1.119e-02	  
 2020-01-27 03:14:50 Iteration 3850 	 Training Loss: 3.136e-03 	 Loss in Target Net: 1.005e-02	  
 2020-01-27 03:24:49 Iteration 3900 	 Training Loss: 2.780e-03 	 Loss in Target Net: 1.406e-02	  
 2020-01-27 03:34:46 Iteration 3950 	 Training Loss: 2.682e-03 	 Loss in Target Net: 1.300e-02	  
 2020-01-27 03:44:54 Iteration 3999 	 Training Loss: 2.863e-03 	 Loss in Target Net: 1.349e-02	  
Evaluating against victims networks
DPN92
Using Adam for retraining
Files already downloaded and verified
2020-01-27 03:45:04, Epoch 0, Iteration 7, loss 2.136 (3.976), acc 90.385 (68.600)
2020-01-27 03:45:04, Epoch 30, Iteration 7, loss 0.587 (0.237), acc 94.231 (96.400)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-7.3405123, -14.513803, -49.77103, 0.847606, -31.858133, -3.5411751, 20.220499, -27.881128, 39.06674, -73.935585], Poisons' Predictions:[8, 8, 8, 8, 6]
2020-01-27 03:45:09 Epoch 59, Val iteration 0, acc 91.600 (91.600)
2020-01-27 03:45:20 Epoch 59, Val iteration 19, acc 92.800 (92.230)
* Prec: 92.23000221252441
--------
SENet18
Using Adam for retraining
Files already downloaded and verified
2020-01-27 03:45:27, Epoch 0, Iteration 7, loss 0.318 (0.590), acc 88.462 (89.000)
2020-01-27 03:45:28, Epoch 30, Iteration 7, loss 0.083 (0.166), acc 96.154 (97.200)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[8.145742, -24.84436, -14.820037, 0.24304003, 10.151068, -0.109325886, 24.513197, -27.453136, 23.446646, -21.54684], Poisons' Predictions:[8, 8, 5, 8, 8]
2020-01-27 03:45:29 Epoch 59, Val iteration 0, acc 92.000 (92.000)
2020-01-27 03:45:35 Epoch 59, Val iteration 19, acc 93.000 (91.120)
* Prec: 91.1200008392334
--------
ResNet50
Using Adam for retraining
Files already downloaded and verified
2020-01-27 03:45:42, Epoch 0, Iteration 7, loss 0.636 (0.542), acc 96.154 (91.800)
2020-01-27 03:45:43, Epoch 30, Iteration 7, loss 0.000 (0.000), acc 100.000 (100.000)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-54.049274, -57.06712, -52.583664, -28.353048, -37.890324, -4.4930606, 25.031553, -40.84539, 28.383108, -32.545216], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-01-27 03:45:44 Epoch 59, Val iteration 0, acc 91.800 (91.800)
2020-01-27 03:45:50 Epoch 59, Val iteration 19, acc 93.600 (92.580)
* Prec: 92.58000144958496
--------
ResNeXt29_2x64d
Using Adam for retraining
Files already downloaded and verified
2020-01-27 03:45:54, Epoch 0, Iteration 7, loss 0.860 (1.695), acc 75.000 (76.000)
2020-01-27 03:45:54, Epoch 30, Iteration 7, loss 0.019 (0.034), acc 100.000 (98.800)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-13.043489, -20.964352, -4.751689, 4.029557, -50.99829, -15.203954, 25.877707, -13.700451, 29.775488, -38.586548], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-01-27 03:45:56 Epoch 59, Val iteration 0, acc 92.800 (92.800)
2020-01-27 03:46:02 Epoch 59, Val iteration 19, acc 92.800 (92.440)
* Prec: 92.4400016784668
--------
GoogLeNet
Using Adam for retraining
Files already downloaded and verified
2020-01-27 03:46:07, Epoch 0, Iteration 7, loss 0.548 (0.442), acc 88.462 (88.600)
2020-01-27 03:46:07, Epoch 30, Iteration 7, loss 0.046 (0.039), acc 98.077 (98.400)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-16.342888, -7.9886994, -7.3772116, 2.598503, -8.051696, -3.3635647, 9.117991, -12.164656, 10.6334505, -16.773973], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-01-27 03:46:10 Epoch 59, Val iteration 0, acc 92.000 (92.000)
2020-01-27 03:46:17 Epoch 59, Val iteration 19, acc 90.800 (91.990)
* Prec: 91.99000091552735
--------
MobileNetV2
Using Adam for retraining
Files already downloaded and verified
2020-01-27 03:46:21, Epoch 0, Iteration 7, loss 1.042 (2.979), acc 82.692 (60.600)
2020-01-27 03:46:21, Epoch 30, Iteration 7, loss 0.140 (0.287), acc 90.385 (91.600)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[0.29096693, -22.980135, -11.982473, 6.52546, -34.29754, -2.778422, 11.766381, -24.859215, 13.84984, -5.444857], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-01-27 03:46:23 Epoch 59, Val iteration 0, acc 87.600 (87.600)
2020-01-27 03:46:28 Epoch 59, Val iteration 19, acc 87.600 (86.850)
* Prec: 86.85000114440918
--------
ResNet18
Using Adam for retraining
Files already downloaded and verified
2020-01-27 03:46:34, Epoch 0, Iteration 7, loss 0.627 (0.703), acc 90.385 (86.800)
2020-01-27 03:46:34, Epoch 30, Iteration 7, loss 0.031 (0.032), acc 98.077 (98.800)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-26.183113, -25.843504, -18.965393, -1.9497583, -48.40991, -10.648784, 9.32965, -32.349487, 10.962589, -37.37934], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-01-27 03:46:35 Epoch 59, Val iteration 0, acc 93.200 (93.200)
2020-01-27 03:46:39 Epoch 59, Val iteration 19, acc 93.000 (92.510)
* Prec: 92.51000175476074
--------
DenseNet121
Using Adam for retraining
Files already downloaded and verified
2020-01-27 03:46:44, Epoch 0, Iteration 7, loss 0.173 (0.449), acc 94.231 (90.400)
2020-01-27 03:46:45, Epoch 30, Iteration 7, loss 0.003 (0.008), acc 100.000 (99.800)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-8.929379, -11.8132305, -10.65434, -2.6780224, -12.203312, -5.385143, 7.3278427, -32.14471, 6.9816895, -15.792278], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-01-27 03:46:48 Epoch 59, Val iteration 0, acc 93.800 (93.800)
2020-01-27 03:46:54 Epoch 59, Val iteration 19, acc 93.400 (93.150)
* Prec: 93.15000228881836
--------
------SUMMARY------
TIME ELAPSED (mins): 700
TARGET INDEX: 8
DPN92 1
SENet18 0
ResNet50 1
ResNeXt29_2x64d 1
GoogLeNet 1
MobileNetV2 1
ResNet18 1
DenseNet121 0
