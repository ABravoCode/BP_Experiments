Namespace(chk_path='chk-black-tmpfs', chk_subdir='poisons', device='cuda', dset_path='datasets', end2end=False, eval_poison_path='', gpu='6', lr_decay_epoch=[30, 45], mode='convex', model_resume_path='model-chks', nearest=False, net_repeat=1, num_per_class=50, original_grad=True, poison_decay_ites=[], poison_decay_ratio=0.1, poison_epsilon=0.1, poison_ites=4000, poison_label=8, poison_lr=0.04, poison_momentum=0.9, poison_num=5, poison_opt='adam', resume_poison_ite=0, retrain_bsize=64, retrain_epochs=60, retrain_lr=0.1, retrain_momentum=0.9, retrain_opt='adam', retrain_wd=0, subs_chk_name=['ckpt-%s-4800-dp0.200-droplayer0.000-seed1226.t7', 'ckpt-%s-4800-dp0.250-droplayer0.000-seed1226.t7', 'ckpt-%s-4800-dp0.300-droplayer0.000.t7'], subs_dp=[0.2, 0.25, 0.3], subset_group=0, substitute_nets=['DPN92', 'SENet18', 'ResNet50', 'ResNeXt29_2x64d', 'GoogLeNet', 'MobileNetV2'], target_index=18, target_label=6, target_net=['DPN92', 'SENet18', 'ResNet50', 'ResNeXt29_2x64d', 'GoogLeNet', 'MobileNetV2', 'ResNet18', 'DenseNet121'], test_chk_name='ckpt-%s-4800.t7', tol=1e-06, train_data_path='datasets/CIFAR10_TRAIN_Split.pth')
Path: chk-black-tmpfs/convex/4000/18
Selected base image indices: [213, 225, 227, 247, 249]
 2020-01-27 13:38:10 Iteration 0 	 Training Loss: 4.882e-01 	 Loss in Target Net: 5.082e-01	  
 2020-01-27 13:43:10 Iteration 50 	 Training Loss: 5.576e-03 	 Loss in Target Net: 1.673e-02	  
 2020-01-27 13:50:04 Iteration 100 	 Training Loss: 3.687e-03 	 Loss in Target Net: 1.589e-02	  
 2020-01-27 13:57:37 Iteration 150 	 Training Loss: 3.231e-03 	 Loss in Target Net: 1.748e-02	  
 2020-01-27 14:05:47 Iteration 200 	 Training Loss: 2.956e-03 	 Loss in Target Net: 1.706e-02	  
 2020-01-27 14:14:52 Iteration 250 	 Training Loss: 2.825e-03 	 Loss in Target Net: 2.009e-02	  
 2020-01-27 14:23:43 Iteration 300 	 Training Loss: 2.560e-03 	 Loss in Target Net: 1.793e-02	  
 2020-01-27 14:32:57 Iteration 350 	 Training Loss: 2.386e-03 	 Loss in Target Net: 1.725e-02	  
 2020-01-27 14:42:22 Iteration 400 	 Training Loss: 2.556e-03 	 Loss in Target Net: 1.651e-02	  
 2020-01-27 14:51:36 Iteration 450 	 Training Loss: 2.713e-03 	 Loss in Target Net: 1.718e-02	  
 2020-01-27 15:01:15 Iteration 500 	 Training Loss: 2.384e-03 	 Loss in Target Net: 1.776e-02	  
 2020-01-27 15:10:41 Iteration 550 	 Training Loss: 2.930e-03 	 Loss in Target Net: 1.546e-02	  
 2020-01-27 15:19:41 Iteration 600 	 Training Loss: 2.074e-03 	 Loss in Target Net: 1.841e-02	  
 2020-01-27 15:28:52 Iteration 650 	 Training Loss: 2.159e-03 	 Loss in Target Net: 1.805e-02	  
 2020-01-27 15:38:16 Iteration 700 	 Training Loss: 2.723e-03 	 Loss in Target Net: 1.413e-02	  
 2020-01-27 15:47:40 Iteration 750 	 Training Loss: 2.281e-03 	 Loss in Target Net: 1.399e-02	  
 2020-01-27 15:56:39 Iteration 800 	 Training Loss: 2.390e-03 	 Loss in Target Net: 1.690e-02	  
 2020-01-27 16:05:54 Iteration 850 	 Training Loss: 2.213e-03 	 Loss in Target Net: 1.425e-02	  
 2020-01-27 16:14:54 Iteration 900 	 Training Loss: 2.151e-03 	 Loss in Target Net: 1.428e-02	  
 2020-01-27 16:24:18 Iteration 950 	 Training Loss: 1.990e-03 	 Loss in Target Net: 1.312e-02	  
 2020-01-27 16:33:19 Iteration 1000 	 Training Loss: 2.213e-03 	 Loss in Target Net: 1.472e-02	  
 2020-01-27 16:42:36 Iteration 1050 	 Training Loss: 2.353e-03 	 Loss in Target Net: 1.498e-02	  
 2020-01-27 16:51:47 Iteration 1100 	 Training Loss: 2.180e-03 	 Loss in Target Net: 1.570e-02	  
 2020-01-27 17:00:59 Iteration 1150 	 Training Loss: 2.309e-03 	 Loss in Target Net: 1.626e-02	  
 2020-01-27 17:10:05 Iteration 1200 	 Training Loss: 2.507e-03 	 Loss in Target Net: 1.683e-02	  
 2020-01-27 17:19:19 Iteration 1250 	 Training Loss: 1.747e-03 	 Loss in Target Net: 1.647e-02	  
 2020-01-27 17:28:45 Iteration 1300 	 Training Loss: 2.521e-03 	 Loss in Target Net: 1.739e-02	  
 2020-01-27 17:38:25 Iteration 1350 	 Training Loss: 2.334e-03 	 Loss in Target Net: 1.934e-02	  
 2020-01-27 17:47:22 Iteration 1400 	 Training Loss: 2.375e-03 	 Loss in Target Net: 1.647e-02	  
 2020-01-27 17:56:34 Iteration 1450 	 Training Loss: 1.792e-03 	 Loss in Target Net: 1.882e-02	  
 2020-01-27 18:06:01 Iteration 1500 	 Training Loss: 2.023e-03 	 Loss in Target Net: 1.728e-02	  
 2020-01-27 18:15:25 Iteration 1550 	 Training Loss: 2.001e-03 	 Loss in Target Net: 1.743e-02	  
 2020-01-27 18:25:11 Iteration 1600 	 Training Loss: 2.381e-03 	 Loss in Target Net: 1.935e-02	  
 2020-01-27 18:34:59 Iteration 1650 	 Training Loss: 2.381e-03 	 Loss in Target Net: 1.524e-02	  
 2020-01-27 18:44:04 Iteration 1700 	 Training Loss: 1.910e-03 	 Loss in Target Net: 1.977e-02	  
 2020-01-27 18:53:15 Iteration 1750 	 Training Loss: 2.047e-03 	 Loss in Target Net: 1.894e-02	  
 2020-01-27 19:02:47 Iteration 1800 	 Training Loss: 1.872e-03 	 Loss in Target Net: 2.109e-02	  
 2020-01-27 19:12:11 Iteration 1850 	 Training Loss: 2.339e-03 	 Loss in Target Net: 1.680e-02	  
 2020-01-27 19:21:04 Iteration 1900 	 Training Loss: 2.252e-03 	 Loss in Target Net: 1.995e-02	  
 2020-01-27 19:30:10 Iteration 1950 	 Training Loss: 2.022e-03 	 Loss in Target Net: 2.161e-02	  
 2020-01-27 19:39:40 Iteration 2000 	 Training Loss: 2.366e-03 	 Loss in Target Net: 1.984e-02	  
 2020-01-27 19:49:09 Iteration 2050 	 Training Loss: 2.054e-03 	 Loss in Target Net: 1.950e-02	  
 2020-01-27 19:58:25 Iteration 2100 	 Training Loss: 2.158e-03 	 Loss in Target Net: 1.794e-02	  
 2020-01-27 20:07:58 Iteration 2150 	 Training Loss: 2.058e-03 	 Loss in Target Net: 2.167e-02	  
 2020-01-27 20:17:36 Iteration 2200 	 Training Loss: 1.897e-03 	 Loss in Target Net: 2.730e-02	  
 2020-01-27 20:26:37 Iteration 2250 	 Training Loss: 1.860e-03 	 Loss in Target Net: 1.991e-02	  
 2020-01-27 20:36:05 Iteration 2300 	 Training Loss: 2.252e-03 	 Loss in Target Net: 3.041e-02	  
 2020-01-27 20:45:12 Iteration 2350 	 Training Loss: 2.121e-03 	 Loss in Target Net: 2.143e-02	  
 2020-01-27 20:54:06 Iteration 2400 	 Training Loss: 1.825e-03 	 Loss in Target Net: 2.166e-02	  
 2020-01-27 21:03:11 Iteration 2450 	 Training Loss: 2.140e-03 	 Loss in Target Net: 2.252e-02	  
 2020-01-27 21:11:08 Iteration 2500 	 Training Loss: 2.098e-03 	 Loss in Target Net: 1.873e-02	  
 2020-01-27 21:20:50 Iteration 2550 	 Training Loss: 1.872e-03 	 Loss in Target Net: 1.798e-02	  
 2020-01-27 21:30:19 Iteration 2600 	 Training Loss: 1.989e-03 	 Loss in Target Net: 2.229e-02	  
 2020-01-27 21:39:26 Iteration 2650 	 Training Loss: 1.931e-03 	 Loss in Target Net: 2.373e-02	  
 2020-01-27 21:48:13 Iteration 2700 	 Training Loss: 1.772e-03 	 Loss in Target Net: 1.752e-02	  
 2020-01-27 21:57:12 Iteration 2750 	 Training Loss: 2.214e-03 	 Loss in Target Net: 1.606e-02	  
 2020-01-27 22:06:08 Iteration 2800 	 Training Loss: 1.949e-03 	 Loss in Target Net: 1.854e-02	  
 2020-01-27 22:15:18 Iteration 2850 	 Training Loss: 2.013e-03 	 Loss in Target Net: 1.614e-02	  
 2020-01-27 22:25:00 Iteration 2900 	 Training Loss: 2.356e-03 	 Loss in Target Net: 2.409e-02	  
 2020-01-27 22:33:57 Iteration 2950 	 Training Loss: 1.927e-03 	 Loss in Target Net: 1.780e-02	  
 2020-01-27 22:43:33 Iteration 3000 	 Training Loss: 1.949e-03 	 Loss in Target Net: 1.609e-02	  
 2020-01-27 22:53:04 Iteration 3050 	 Training Loss: 2.072e-03 	 Loss in Target Net: 1.236e-02	  
 2020-01-27 23:02:57 Iteration 3100 	 Training Loss: 1.835e-03 	 Loss in Target Net: 1.975e-02	  
 2020-01-27 23:12:15 Iteration 3150 	 Training Loss: 2.109e-03 	 Loss in Target Net: 1.615e-02	  
 2020-01-27 23:22:05 Iteration 3200 	 Training Loss: 1.979e-03 	 Loss in Target Net: 1.323e-02	  
 2020-01-27 23:31:38 Iteration 3250 	 Training Loss: 1.946e-03 	 Loss in Target Net: 1.909e-02	  
 2020-01-27 23:41:39 Iteration 3300 	 Training Loss: 2.102e-03 	 Loss in Target Net: 1.633e-02	  
 2020-01-27 23:51:10 Iteration 3350 	 Training Loss: 1.999e-03 	 Loss in Target Net: 1.953e-02	  
 2020-01-28 00:00:41 Iteration 3400 	 Training Loss: 1.802e-03 	 Loss in Target Net: 1.962e-02	  
 2020-01-28 00:09:29 Iteration 3450 	 Training Loss: 1.775e-03 	 Loss in Target Net: 2.049e-02	  
 2020-01-28 00:18:14 Iteration 3500 	 Training Loss: 1.917e-03 	 Loss in Target Net: 1.964e-02	  
 2020-01-28 00:27:32 Iteration 3550 	 Training Loss: 2.019e-03 	 Loss in Target Net: 1.876e-02	  
 2020-01-28 00:36:48 Iteration 3600 	 Training Loss: 1.880e-03 	 Loss in Target Net: 2.124e-02	  
 2020-01-28 00:45:37 Iteration 3650 	 Training Loss: 2.050e-03 	 Loss in Target Net: 2.131e-02	  
 2020-01-28 00:55:20 Iteration 3700 	 Training Loss: 2.334e-03 	 Loss in Target Net: 1.795e-02	  
 2020-01-28 01:04:57 Iteration 3750 	 Training Loss: 2.190e-03 	 Loss in Target Net: 1.969e-02	  
 2020-01-28 01:14:26 Iteration 3800 	 Training Loss: 1.996e-03 	 Loss in Target Net: 1.634e-02	  
 2020-01-28 01:23:43 Iteration 3850 	 Training Loss: 1.861e-03 	 Loss in Target Net: 1.698e-02	  
 2020-01-28 01:33:00 Iteration 3900 	 Training Loss: 2.154e-03 	 Loss in Target Net: 1.767e-02	  
 2020-01-28 01:42:09 Iteration 3950 	 Training Loss: 2.101e-03 	 Loss in Target Net: 1.517e-02	  
 2020-01-28 01:52:09 Iteration 3999 	 Training Loss: 2.208e-03 	 Loss in Target Net: 1.678e-02	  
Evaluating against victims networks
DPN92
Using Adam for retraining
Files already downloaded and verified
2020-01-28 01:52:14, Epoch 0, Iteration 7, loss 1.234 (4.549), acc 88.462 (63.600)
2020-01-28 01:52:15, Epoch 30, Iteration 7, loss 0.353 (0.149), acc 96.154 (96.800)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[22.15611, 2.3984256, -57.29374, 2.8029377, -49.271667, -6.311755, 14.267, -24.633947, 32.681133, -96.20314], Poisons' Predictions:[8, 8, 8, 6, 8]
2020-01-28 01:52:20 Epoch 59, Val iteration 0, acc 90.000 (90.000)
2020-01-28 01:52:28 Epoch 59, Val iteration 19, acc 90.600 (91.200)
* Prec: 91.20000076293945
--------
SENet18
Using Adam for retraining
Files already downloaded and verified
2020-01-28 01:52:31, Epoch 0, Iteration 7, loss 0.747 (0.868), acc 94.231 (85.400)
2020-01-28 01:52:31, Epoch 30, Iteration 7, loss 0.057 (0.251), acc 96.154 (94.800)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-5.0748167, -3.51404, -7.052291, -4.991972, 2.776286, -16.796432, 13.009702, -6.8110485, 9.509255, -12.146883], Poisons' Predictions:[8, 8, 8, 6, 8]
2020-01-28 01:52:32 Epoch 59, Val iteration 0, acc 91.200 (91.200)
2020-01-28 01:52:35 Epoch 59, Val iteration 19, acc 92.400 (91.130)
* Prec: 91.13000183105468
--------
ResNet50
Using Adam for retraining
Files already downloaded and verified
2020-01-28 01:52:38, Epoch 0, Iteration 7, loss 0.206 (1.689), acc 98.077 (83.600)
2020-01-28 01:52:38, Epoch 30, Iteration 7, loss 0.123 (0.013), acc 98.077 (99.800)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-48.638103, -3.5864184, -58.236244, -48.69059, -55.74099, -56.201927, 18.535107, -33.820045, 32.280857, -34.286503], Poisons' Predictions:[8, 8, 8, 6, 8]
2020-01-28 01:52:40 Epoch 59, Val iteration 0, acc 93.800 (93.800)
2020-01-28 01:52:44 Epoch 59, Val iteration 19, acc 94.200 (94.050)
* Prec: 94.05000152587891
--------
ResNeXt29_2x64d
Using Adam for retraining
Files already downloaded and verified
2020-01-28 01:52:47, Epoch 0, Iteration 7, loss 0.764 (2.492), acc 88.462 (74.800)
2020-01-28 01:52:48, Epoch 30, Iteration 7, loss 0.296 (0.219), acc 98.077 (95.400)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-19.781427, -3.788753, -4.8234196, 0.7224914, -61.905567, -34.08342, -1.062754, -23.35006, 9.28082, -27.221315], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-01-28 01:52:49 Epoch 59, Val iteration 0, acc 91.000 (91.000)
2020-01-28 01:52:54 Epoch 59, Val iteration 19, acc 92.400 (92.380)
* Prec: 92.38000183105468
--------
GoogLeNet
Using Adam for retraining
Files already downloaded and verified
2020-01-28 01:52:57, Epoch 0, Iteration 7, loss 0.545 (0.489), acc 86.538 (88.400)
2020-01-28 01:52:58, Epoch 30, Iteration 7, loss 0.129 (0.069), acc 94.231 (97.600)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-9.616843, -2.2867427, -5.1546106, 1.5409594, -16.039394, -3.8270392, 5.9123263, -10.324888, 9.284355, -16.219578], Poisons' Predictions:[8, 8, 8, 6, 8]
2020-01-28 01:53:00 Epoch 59, Val iteration 0, acc 90.400 (90.400)
2020-01-28 01:53:05 Epoch 59, Val iteration 19, acc 92.200 (92.140)
* Prec: 92.1400016784668
--------
MobileNetV2
Using Adam for retraining
Files already downloaded and verified
2020-01-28 01:53:08, Epoch 0, Iteration 7, loss 1.865 (3.549), acc 82.692 (63.600)
2020-01-28 01:53:08, Epoch 30, Iteration 7, loss 0.901 (0.364), acc 88.462 (91.800)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[0.19923094, -35.276577, 2.3756745, 9.939775, -31.009253, -10.014251, 17.953884, -15.882858, 16.100355, -47.685493], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-01-28 01:53:09 Epoch 59, Val iteration 0, acc 88.200 (88.200)
2020-01-28 01:53:12 Epoch 59, Val iteration 19, acc 88.600 (87.220)
* Prec: 87.22000122070312
--------
ResNet18
Using Adam for retraining
Files already downloaded and verified
2020-01-28 01:53:15, Epoch 0, Iteration 7, loss 0.465 (0.638), acc 88.462 (90.600)
2020-01-28 01:53:15, Epoch 30, Iteration 7, loss 0.003 (0.008), acc 100.000 (99.800)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-42.234814, -3.0835016, -26.337206, -0.8134292, -34.367954, -9.268802, 9.090794, -11.531568, 7.825571, -39.104927], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-01-28 01:53:16 Epoch 59, Val iteration 0, acc 92.400 (92.400)
2020-01-28 01:53:18 Epoch 59, Val iteration 19, acc 93.800 (92.530)
* Prec: 92.53000144958496
--------
DenseNet121
Using Adam for retraining
Files already downloaded and verified
2020-01-28 01:53:22, Epoch 0, Iteration 7, loss 0.240 (0.375), acc 94.231 (92.200)
2020-01-28 01:53:22, Epoch 30, Iteration 7, loss 0.004 (0.004), acc 100.000 (100.000)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-3.859791, -23.699186, -12.480082, -1.8113588, -12.325257, -3.8420825, 6.055622, -36.288967, 4.902968, -17.363192], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-01-28 01:53:25 Epoch 59, Val iteration 0, acc 93.600 (93.600)
2020-01-28 01:53:29 Epoch 59, Val iteration 19, acc 93.600 (92.790)
* Prec: 92.79000091552734
--------
------SUMMARY------
TIME ELAPSED (mins): 734
TARGET INDEX: 18
DPN92 1
SENet18 0
ResNet50 1
ResNeXt29_2x64d 1
GoogLeNet 1
MobileNetV2 0
ResNet18 0
DenseNet121 0
