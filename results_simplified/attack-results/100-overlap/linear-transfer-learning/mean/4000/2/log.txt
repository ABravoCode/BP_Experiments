Namespace(chk_path='chk-black-ourmean/', chk_subdir='poisons', device='cuda', dset_path='datasets', end2end=False, eval_poison_path='', gpu='2', lr_decay_epoch=[30, 45], mode='mean', model_resume_path='model-chks', nearest=False, net_repeat=1, num_per_class=50, original_grad=True, poison_decay_ites=[], poison_decay_ratio=0.1, poison_epsilon=0.1, poison_ites=4000, poison_label=8, poison_lr=0.04, poison_momentum=0.9, poison_num=5, poison_opt='adam', resume_poison_ite=0, retrain_bsize=64, retrain_epochs=60, retrain_lr=0.1, retrain_momentum=0.9, retrain_opt='adam', retrain_wd=0, subs_chk_name=['ckpt-%s-4800-dp0.200-droplayer0.000-seed1226.t7', 'ckpt-%s-4800-dp0.250-droplayer0.000-seed1226.t7', 'ckpt-%s-4800-dp0.300-droplayer0.000.t7'], subs_dp=[0.2, 0.25, 0.3], subset_group=0, substitute_nets=['DPN92', 'SENet18', 'ResNet50', 'ResNeXt29_2x64d', 'GoogLeNet', 'MobileNetV2'], target_index=2, target_label=6, target_net=['DPN92', 'SENet18', 'ResNet50', 'ResNeXt29_2x64d', 'GoogLeNet', 'MobileNetV2', 'ResNet18', 'DenseNet121'], test_chk_name='ckpt-%s-4800.t7', tol=1e-06, train_data_path='datasets/CIFAR10_TRAIN_Split.pth')
Path: chk-black-ourmean/mean/4000/2
Selected base image indices: [213, 225, 227, 247, 249]
 2020-01-31 17:11:24 Iteration 0 	 Training Loss: 1.104e+00 	 Loss in Target Net: 4.230e-01	  
 2020-01-31 17:11:46 Iteration 50 	 Training Loss: 9.240e-02 	 Loss in Target Net: 9.178e-03	  
 2020-01-31 17:12:09 Iteration 100 	 Training Loss: 8.604e-02 	 Loss in Target Net: 1.045e-02	  
 2020-01-31 17:12:31 Iteration 150 	 Training Loss: 8.177e-02 	 Loss in Target Net: 7.776e-03	  
 2020-01-31 17:12:53 Iteration 200 	 Training Loss: 7.904e-02 	 Loss in Target Net: 6.451e-03	  
 2020-01-31 17:13:16 Iteration 250 	 Training Loss: 7.844e-02 	 Loss in Target Net: 7.890e-03	  
 2020-01-31 17:13:38 Iteration 300 	 Training Loss: 8.801e-02 	 Loss in Target Net: 8.106e-03	  
 2020-01-31 17:14:01 Iteration 350 	 Training Loss: 8.189e-02 	 Loss in Target Net: 6.156e-03	  
 2020-01-31 17:14:25 Iteration 400 	 Training Loss: 8.534e-02 	 Loss in Target Net: 5.227e-03	  
 2020-01-31 17:14:48 Iteration 450 	 Training Loss: 7.864e-02 	 Loss in Target Net: 6.838e-03	  
 2020-01-31 17:15:10 Iteration 500 	 Training Loss: 8.385e-02 	 Loss in Target Net: 5.221e-03	  
 2020-01-31 17:15:33 Iteration 550 	 Training Loss: 8.232e-02 	 Loss in Target Net: 6.653e-03	  
 2020-01-31 17:15:55 Iteration 600 	 Training Loss: 8.240e-02 	 Loss in Target Net: 7.957e-03	  
 2020-01-31 17:16:17 Iteration 650 	 Training Loss: 7.487e-02 	 Loss in Target Net: 8.617e-03	  
 2020-01-31 17:16:40 Iteration 700 	 Training Loss: 7.007e-02 	 Loss in Target Net: 1.364e-02	  
 2020-01-31 17:17:03 Iteration 750 	 Training Loss: 7.914e-02 	 Loss in Target Net: 1.095e-02	  
 2020-01-31 17:17:25 Iteration 800 	 Training Loss: 7.675e-02 	 Loss in Target Net: 8.790e-03	  
 2020-01-31 17:17:47 Iteration 850 	 Training Loss: 8.038e-02 	 Loss in Target Net: 8.803e-03	  
 2020-01-31 17:18:10 Iteration 900 	 Training Loss: 7.548e-02 	 Loss in Target Net: 6.400e-03	  
 2020-01-31 17:18:32 Iteration 950 	 Training Loss: 7.372e-02 	 Loss in Target Net: 1.194e-02	  
 2020-01-31 17:18:55 Iteration 1000 	 Training Loss: 7.459e-02 	 Loss in Target Net: 6.178e-03	  
 2020-01-31 17:19:17 Iteration 1050 	 Training Loss: 7.242e-02 	 Loss in Target Net: 6.803e-03	  
 2020-01-31 17:19:41 Iteration 1100 	 Training Loss: 7.841e-02 	 Loss in Target Net: 5.829e-03	  
 2020-01-31 17:20:03 Iteration 1150 	 Training Loss: 7.990e-02 	 Loss in Target Net: 9.151e-03	  
 2020-01-31 17:20:26 Iteration 1200 	 Training Loss: 7.699e-02 	 Loss in Target Net: 8.534e-03	  
 2020-01-31 17:20:48 Iteration 1250 	 Training Loss: 7.707e-02 	 Loss in Target Net: 8.906e-03	  
 2020-01-31 17:21:11 Iteration 1300 	 Training Loss: 8.186e-02 	 Loss in Target Net: 7.797e-03	  
 2020-01-31 17:21:33 Iteration 1350 	 Training Loss: 7.527e-02 	 Loss in Target Net: 7.604e-03	  
 2020-01-31 17:21:56 Iteration 1400 	 Training Loss: 7.451e-02 	 Loss in Target Net: 8.850e-03	  
 2020-01-31 17:22:19 Iteration 1450 	 Training Loss: 8.216e-02 	 Loss in Target Net: 1.168e-02	  
 2020-01-31 17:22:41 Iteration 1500 	 Training Loss: 7.509e-02 	 Loss in Target Net: 1.008e-02	  
 2020-01-31 17:23:04 Iteration 1550 	 Training Loss: 7.714e-02 	 Loss in Target Net: 8.351e-03	  
 2020-01-31 17:23:26 Iteration 1600 	 Training Loss: 7.142e-02 	 Loss in Target Net: 7.249e-03	  
 2020-01-31 17:23:48 Iteration 1650 	 Training Loss: 7.729e-02 	 Loss in Target Net: 7.976e-03	  
 2020-01-31 17:24:10 Iteration 1700 	 Training Loss: 7.626e-02 	 Loss in Target Net: 5.410e-03	  
 2020-01-31 17:24:33 Iteration 1750 	 Training Loss: 7.767e-02 	 Loss in Target Net: 6.259e-03	  
 2020-01-31 17:24:55 Iteration 1800 	 Training Loss: 8.030e-02 	 Loss in Target Net: 1.034e-02	  
 2020-01-31 17:25:17 Iteration 1850 	 Training Loss: 6.681e-02 	 Loss in Target Net: 9.878e-03	  
 2020-01-31 17:25:40 Iteration 1900 	 Training Loss: 7.486e-02 	 Loss in Target Net: 9.954e-03	  
 2020-01-31 17:26:02 Iteration 1950 	 Training Loss: 7.445e-02 	 Loss in Target Net: 6.671e-03	  
 2020-01-31 17:26:24 Iteration 2000 	 Training Loss: 7.437e-02 	 Loss in Target Net: 1.030e-02	  
 2020-01-31 17:26:46 Iteration 2050 	 Training Loss: 7.380e-02 	 Loss in Target Net: 9.474e-03	  
 2020-01-31 17:27:08 Iteration 2100 	 Training Loss: 7.242e-02 	 Loss in Target Net: 8.278e-03	  
 2020-01-31 17:27:31 Iteration 2150 	 Training Loss: 7.736e-02 	 Loss in Target Net: 7.381e-03	  
 2020-01-31 17:27:53 Iteration 2200 	 Training Loss: 7.015e-02 	 Loss in Target Net: 8.336e-03	  
 2020-01-31 17:28:15 Iteration 2250 	 Training Loss: 7.547e-02 	 Loss in Target Net: 5.902e-03	  
 2020-01-31 17:28:37 Iteration 2300 	 Training Loss: 8.676e-02 	 Loss in Target Net: 6.732e-03	  
 2020-01-31 17:28:59 Iteration 2350 	 Training Loss: 7.474e-02 	 Loss in Target Net: 8.414e-03	  
 2020-01-31 17:29:22 Iteration 2400 	 Training Loss: 7.698e-02 	 Loss in Target Net: 1.205e-02	  
 2020-01-31 17:29:45 Iteration 2450 	 Training Loss: 7.348e-02 	 Loss in Target Net: 1.144e-02	  
 2020-01-31 17:30:07 Iteration 2500 	 Training Loss: 7.319e-02 	 Loss in Target Net: 8.188e-03	  
 2020-01-31 17:30:30 Iteration 2550 	 Training Loss: 8.254e-02 	 Loss in Target Net: 1.778e-02	  
 2020-01-31 17:30:52 Iteration 2600 	 Training Loss: 7.335e-02 	 Loss in Target Net: 1.448e-02	  
 2020-01-31 17:31:15 Iteration 2650 	 Training Loss: 7.973e-02 	 Loss in Target Net: 7.653e-03	  
 2020-01-31 17:31:38 Iteration 2700 	 Training Loss: 7.459e-02 	 Loss in Target Net: 8.785e-03	  
 2020-01-31 17:32:00 Iteration 2750 	 Training Loss: 7.372e-02 	 Loss in Target Net: 7.305e-03	  
 2020-01-31 17:32:23 Iteration 2800 	 Training Loss: 6.987e-02 	 Loss in Target Net: 6.688e-03	  
 2020-01-31 17:32:46 Iteration 2850 	 Training Loss: 7.454e-02 	 Loss in Target Net: 1.088e-02	  
 2020-01-31 17:33:08 Iteration 2900 	 Training Loss: 7.562e-02 	 Loss in Target Net: 8.488e-03	  
 2020-01-31 17:33:30 Iteration 2950 	 Training Loss: 7.561e-02 	 Loss in Target Net: 9.431e-03	  
 2020-01-31 17:33:53 Iteration 3000 	 Training Loss: 8.223e-02 	 Loss in Target Net: 1.101e-02	  
 2020-01-31 17:34:15 Iteration 3050 	 Training Loss: 7.692e-02 	 Loss in Target Net: 7.231e-03	  
 2020-01-31 17:34:38 Iteration 3100 	 Training Loss: 7.518e-02 	 Loss in Target Net: 8.771e-03	  
 2020-01-31 17:35:00 Iteration 3150 	 Training Loss: 7.235e-02 	 Loss in Target Net: 1.261e-02	  
 2020-01-31 17:35:22 Iteration 3200 	 Training Loss: 7.788e-02 	 Loss in Target Net: 8.145e-03	  
 2020-01-31 17:35:46 Iteration 3250 	 Training Loss: 7.716e-02 	 Loss in Target Net: 7.381e-03	  
 2020-01-31 17:36:08 Iteration 3300 	 Training Loss: 7.652e-02 	 Loss in Target Net: 8.339e-03	  
 2020-01-31 17:36:31 Iteration 3350 	 Training Loss: 7.835e-02 	 Loss in Target Net: 7.092e-03	  
 2020-01-31 17:36:54 Iteration 3400 	 Training Loss: 7.628e-02 	 Loss in Target Net: 8.701e-03	  
 2020-01-31 17:37:16 Iteration 3450 	 Training Loss: 7.129e-02 	 Loss in Target Net: 8.296e-03	  
 2020-01-31 17:37:39 Iteration 3500 	 Training Loss: 7.449e-02 	 Loss in Target Net: 6.021e-03	  
 2020-01-31 17:38:01 Iteration 3550 	 Training Loss: 7.551e-02 	 Loss in Target Net: 4.554e-03	  
 2020-01-31 17:38:23 Iteration 3600 	 Training Loss: 7.648e-02 	 Loss in Target Net: 9.299e-03	  
 2020-01-31 17:38:46 Iteration 3650 	 Training Loss: 7.066e-02 	 Loss in Target Net: 8.453e-03	  
 2020-01-31 17:39:08 Iteration 3700 	 Training Loss: 7.582e-02 	 Loss in Target Net: 1.316e-02	  
 2020-01-31 17:39:31 Iteration 3750 	 Training Loss: 7.704e-02 	 Loss in Target Net: 1.128e-02	  
 2020-01-31 17:39:53 Iteration 3800 	 Training Loss: 7.379e-02 	 Loss in Target Net: 5.877e-03	  
 2020-01-31 17:40:15 Iteration 3850 	 Training Loss: 7.564e-02 	 Loss in Target Net: 7.606e-03	  
 2020-01-31 17:40:38 Iteration 3900 	 Training Loss: 7.317e-02 	 Loss in Target Net: 8.149e-03	  
 2020-01-31 17:41:00 Iteration 3950 	 Training Loss: 7.760e-02 	 Loss in Target Net: 5.392e-03	  
 2020-01-31 17:41:22 Iteration 3999 	 Training Loss: 7.398e-02 	 Loss in Target Net: 5.353e-03	  
Evaluating against victims networks
DPN92
Using Adam for retraining
Files already downloaded and verified
2020-01-31 17:41:26, Epoch 0, Iteration 7, loss 1.950 (4.367), acc 88.462 (65.000)
2020-01-31 17:41:26, Epoch 30, Iteration 7, loss 0.387 (0.213), acc 94.231 (96.000)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[38.592724, 9.063739, -21.974857, 22.932188, -6.846222, 15.399769, 50.117035, -50.930023, 45.619255, -77.94589], Poisons' Predictions:[8, 8, 8, 6, 6]
2020-01-31 17:41:30 Epoch 59, Val iteration 0, acc 90.200 (90.200)
2020-01-31 17:41:38 Epoch 59, Val iteration 19, acc 92.600 (91.860)
* Prec: 91.86000213623046
--------
SENet18
Using Adam for retraining
Files already downloaded and verified
2020-01-31 17:41:40, Epoch 0, Iteration 7, loss 0.677 (0.646), acc 90.385 (88.400)
2020-01-31 17:41:40, Epoch 30, Iteration 7, loss 0.263 (0.260), acc 94.231 (95.600)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[2.3395412, -1.6410697, -2.803746, -2.636074, 1.4307746, -10.535016, 21.207388, -15.590498, 16.747263, -11.365155], Poisons' Predictions:[8, 6, 6, 8, 6]
2020-01-31 17:41:41 Epoch 59, Val iteration 0, acc 92.000 (92.000)
2020-01-31 17:41:43 Epoch 59, Val iteration 19, acc 92.800 (91.330)
* Prec: 91.33000144958496
--------
ResNet50
Using Adam for retraining
Files already downloaded and verified
2020-01-31 17:41:45, Epoch 0, Iteration 7, loss 0.000 (1.049), acc 100.000 (87.000)
2020-01-31 17:41:45, Epoch 30, Iteration 7, loss 0.072 (0.019), acc 98.077 (99.600)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-30.144352, -18.544514, -59.352276, -37.8145, -47.761284, -29.23841, 21.051205, -94.66296, 13.735939, -44.02083], Poisons' Predictions:[8, 8, 8, 6, 6]
2020-01-31 17:41:47 Epoch 59, Val iteration 0, acc 91.400 (91.400)
2020-01-31 17:41:51 Epoch 59, Val iteration 19, acc 92.600 (91.880)
* Prec: 91.88000030517578
--------
ResNeXt29_2x64d
Using Adam for retraining
Files already downloaded and verified
2020-01-31 17:41:53, Epoch 0, Iteration 7, loss 0.567 (2.230), acc 90.385 (70.200)
2020-01-31 17:41:53, Epoch 30, Iteration 7, loss 0.045 (0.086), acc 98.077 (97.400)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-19.881458, -11.728312, -0.3059676, 2.2721138, -65.111046, -21.75241, 22.492073, -14.355262, 24.587753, -15.139097], Poisons' Predictions:[8, 8, 6, 8, 8]
2020-01-31 17:41:55 Epoch 59, Val iteration 0, acc 93.000 (93.000)
2020-01-31 17:41:59 Epoch 59, Val iteration 19, acc 92.600 (92.880)
* Prec: 92.8800006866455
--------
GoogLeNet
Using Adam for retraining
Files already downloaded and verified
2020-01-31 17:42:01, Epoch 0, Iteration 7, loss 0.289 (0.376), acc 94.231 (90.600)
2020-01-31 17:42:02, Epoch 30, Iteration 7, loss 0.086 (0.055), acc 96.154 (98.400)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-18.68445, -17.553432, -4.783514, -2.482345, -6.8569384, -1.6085731, -0.9537451, -8.12099, 7.610975, -12.457383], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-01-31 17:42:04 Epoch 59, Val iteration 0, acc 91.800 (91.800)
2020-01-31 17:42:09 Epoch 59, Val iteration 19, acc 92.000 (92.370)
* Prec: 92.3700023651123
--------
MobileNetV2
Using Adam for retraining
Files already downloaded and verified
2020-01-31 17:42:11, Epoch 0, Iteration 7, loss 1.724 (2.667), acc 80.769 (69.600)
2020-01-31 17:42:11, Epoch 30, Iteration 7, loss 0.273 (0.533), acc 92.308 (89.600)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-5.0710573, -18.270926, 4.4129214, 8.042304, -18.64729, -11.518337, 16.878654, -39.30454, 11.903157, -27.490608], Poisons' Predictions:[8, 8, 8, 6, 8]
2020-01-31 17:42:12 Epoch 59, Val iteration 0, acc 88.800 (88.800)
2020-01-31 17:42:14 Epoch 59, Val iteration 19, acc 89.000 (87.180)
* Prec: 87.18000144958496
--------
ResNet18
Using Adam for retraining
Files already downloaded and verified
2020-01-31 17:42:16, Epoch 0, Iteration 7, loss 0.112 (0.621), acc 92.308 (86.000)
2020-01-31 17:42:16, Epoch 30, Iteration 7, loss 0.012 (0.017), acc 100.000 (99.400)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-45.408817, -24.166622, -11.601466, 5.7699895, -36.002293, -11.801348, 15.323441, -13.602728, 13.640121, -31.797855], Poisons' Predictions:[8, 6, 8, 6, 8]
2020-01-31 17:42:16 Epoch 59, Val iteration 0, acc 93.400 (93.400)
2020-01-31 17:42:18 Epoch 59, Val iteration 19, acc 93.800 (92.680)
* Prec: 92.68000106811523
--------
DenseNet121
Using Adam for retraining
Files already downloaded and verified
2020-01-31 17:42:21, Epoch 0, Iteration 7, loss 0.571 (0.359), acc 94.231 (93.200)
2020-01-31 17:42:21, Epoch 30, Iteration 7, loss 0.004 (0.005), acc 100.000 (100.000)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-14.239947, -15.120184, -20.58574, -4.7334805, -17.943935, -8.631443, 6.5526304, -42.611805, 3.7673373, -19.736464], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-01-31 17:42:23 Epoch 59, Val iteration 0, acc 94.400 (94.400)
2020-01-31 17:42:28 Epoch 59, Val iteration 19, acc 93.000 (93.040)
* Prec: 93.0400016784668
--------
------SUMMARY------
TIME ELAPSED (mins): 30
TARGET INDEX: 2
DPN92 0
SENet18 0
ResNet50 0
ResNeXt29_2x64d 1
GoogLeNet 1
MobileNetV2 0
ResNet18 0
DenseNet121 0
