Namespace(chk_path='chk-black-ourmean/', chk_subdir='poisons', device='cuda', dset_path='datasets', end2end=False, eval_poison_path='', gpu='2', lr_decay_epoch=[30, 45], mode='mean', model_resume_path='model-chks', nearest=False, net_repeat=1, num_per_class=50, original_grad=True, poison_decay_ites=[], poison_decay_ratio=0.1, poison_epsilon=0.1, poison_ites=4000, poison_label=8, poison_lr=0.04, poison_momentum=0.9, poison_num=5, poison_opt='adam', resume_poison_ite=0, retrain_bsize=64, retrain_epochs=60, retrain_lr=0.1, retrain_momentum=0.9, retrain_opt='adam', retrain_wd=0, subs_chk_name=['ckpt-%s-4800-dp0.200-droplayer0.000-seed1226.t7', 'ckpt-%s-4800-dp0.250-droplayer0.000-seed1226.t7', 'ckpt-%s-4800-dp0.300-droplayer0.000.t7'], subs_dp=[0.2, 0.25, 0.3], subset_group=0, substitute_nets=['DPN92', 'SENet18', 'ResNet50', 'ResNeXt29_2x64d', 'GoogLeNet', 'MobileNetV2'], target_index=6, target_label=6, target_net=['DPN92', 'SENet18', 'ResNet50', 'ResNeXt29_2x64d', 'GoogLeNet', 'MobileNetV2', 'ResNet18', 'DenseNet121'], test_chk_name='ckpt-%s-4800.t7', tol=1e-06, train_data_path='datasets/CIFAR10_TRAIN_Split.pth')
Path: chk-black-ourmean/mean/4000/6
Selected base image indices: [213, 225, 227, 247, 249]
 2020-01-31 17:42:45 Iteration 0 	 Training Loss: 1.059e+00 	 Loss in Target Net: 4.056e-01	  
 2020-01-31 17:43:06 Iteration 50 	 Training Loss: 8.811e-02 	 Loss in Target Net: 1.334e-02	  
 2020-01-31 17:43:29 Iteration 100 	 Training Loss: 7.818e-02 	 Loss in Target Net: 1.007e-02	  
 2020-01-31 17:43:53 Iteration 150 	 Training Loss: 6.865e-02 	 Loss in Target Net: 9.556e-03	  
 2020-01-31 17:44:16 Iteration 200 	 Training Loss: 7.356e-02 	 Loss in Target Net: 9.667e-03	  
 2020-01-31 17:44:39 Iteration 250 	 Training Loss: 6.940e-02 	 Loss in Target Net: 9.723e-03	  
 2020-01-31 17:45:01 Iteration 300 	 Training Loss: 7.621e-02 	 Loss in Target Net: 1.076e-02	  
 2020-01-31 17:45:23 Iteration 350 	 Training Loss: 7.283e-02 	 Loss in Target Net: 1.022e-02	  
 2020-01-31 17:45:46 Iteration 400 	 Training Loss: 7.163e-02 	 Loss in Target Net: 7.095e-03	  
 2020-01-31 17:46:08 Iteration 450 	 Training Loss: 6.896e-02 	 Loss in Target Net: 1.049e-02	  
 2020-01-31 17:46:30 Iteration 500 	 Training Loss: 7.263e-02 	 Loss in Target Net: 8.850e-03	  
 2020-01-31 17:46:52 Iteration 550 	 Training Loss: 7.252e-02 	 Loss in Target Net: 1.028e-02	  
 2020-01-31 17:47:12 Iteration 600 	 Training Loss: 7.153e-02 	 Loss in Target Net: 9.164e-03	  
 2020-01-31 17:47:33 Iteration 650 	 Training Loss: 6.408e-02 	 Loss in Target Net: 1.070e-02	  
 2020-01-31 17:47:54 Iteration 700 	 Training Loss: 6.293e-02 	 Loss in Target Net: 1.018e-02	  
 2020-01-31 17:48:15 Iteration 750 	 Training Loss: 7.132e-02 	 Loss in Target Net: 8.798e-03	  
 2020-01-31 17:48:37 Iteration 800 	 Training Loss: 6.939e-02 	 Loss in Target Net: 9.488e-03	  
 2020-01-31 17:48:59 Iteration 850 	 Training Loss: 6.842e-02 	 Loss in Target Net: 9.307e-03	  
 2020-01-31 17:49:19 Iteration 900 	 Training Loss: 6.818e-02 	 Loss in Target Net: 1.103e-02	  
 2020-01-31 17:49:41 Iteration 950 	 Training Loss: 6.986e-02 	 Loss in Target Net: 8.343e-03	  
 2020-01-31 17:50:04 Iteration 1000 	 Training Loss: 6.722e-02 	 Loss in Target Net: 8.952e-03	  
 2020-01-31 17:50:25 Iteration 1050 	 Training Loss: 6.960e-02 	 Loss in Target Net: 1.002e-02	  
 2020-01-31 17:50:46 Iteration 1100 	 Training Loss: 6.741e-02 	 Loss in Target Net: 8.433e-03	  
 2020-01-31 17:51:08 Iteration 1150 	 Training Loss: 6.533e-02 	 Loss in Target Net: 8.446e-03	  
 2020-01-31 17:51:30 Iteration 1200 	 Training Loss: 7.163e-02 	 Loss in Target Net: 8.291e-03	  
 2020-01-31 17:51:51 Iteration 1250 	 Training Loss: 7.451e-02 	 Loss in Target Net: 7.355e-03	  
 2020-01-31 17:52:11 Iteration 1300 	 Training Loss: 6.197e-02 	 Loss in Target Net: 7.299e-03	  
 2020-01-31 17:52:32 Iteration 1350 	 Training Loss: 7.133e-02 	 Loss in Target Net: 1.032e-02	  
 2020-01-31 17:52:52 Iteration 1400 	 Training Loss: 7.015e-02 	 Loss in Target Net: 5.300e-03	  
 2020-01-31 17:53:12 Iteration 1450 	 Training Loss: 6.633e-02 	 Loss in Target Net: 3.099e-03	  
 2020-01-31 17:53:34 Iteration 1500 	 Training Loss: 7.035e-02 	 Loss in Target Net: 7.882e-03	  
 2020-01-31 17:53:55 Iteration 1550 	 Training Loss: 6.625e-02 	 Loss in Target Net: 6.220e-03	  
 2020-01-31 17:54:16 Iteration 1600 	 Training Loss: 6.538e-02 	 Loss in Target Net: 5.605e-03	  
 2020-01-31 17:54:36 Iteration 1650 	 Training Loss: 7.946e-02 	 Loss in Target Net: 4.449e-03	  
 2020-01-31 17:54:57 Iteration 1700 	 Training Loss: 6.719e-02 	 Loss in Target Net: 7.447e-03	  
 2020-01-31 17:55:18 Iteration 1750 	 Training Loss: 6.773e-02 	 Loss in Target Net: 6.423e-03	  
 2020-01-31 17:55:39 Iteration 1800 	 Training Loss: 6.617e-02 	 Loss in Target Net: 5.390e-03	  
 2020-01-31 17:55:59 Iteration 1850 	 Training Loss: 6.559e-02 	 Loss in Target Net: 6.915e-03	  
 2020-01-31 17:56:20 Iteration 1900 	 Training Loss: 7.238e-02 	 Loss in Target Net: 8.155e-03	  
 2020-01-31 17:56:40 Iteration 1950 	 Training Loss: 6.684e-02 	 Loss in Target Net: 6.858e-03	  
 2020-01-31 17:57:01 Iteration 2000 	 Training Loss: 7.366e-02 	 Loss in Target Net: 8.524e-03	  
 2020-01-31 17:57:22 Iteration 2050 	 Training Loss: 7.131e-02 	 Loss in Target Net: 5.183e-03	  
 2020-01-31 17:57:43 Iteration 2100 	 Training Loss: 6.934e-02 	 Loss in Target Net: 5.497e-03	  
 2020-01-31 17:58:05 Iteration 2150 	 Training Loss: 6.765e-02 	 Loss in Target Net: 3.934e-03	  
 2020-01-31 17:58:26 Iteration 2200 	 Training Loss: 6.578e-02 	 Loss in Target Net: 6.892e-03	  
 2020-01-31 17:58:47 Iteration 2250 	 Training Loss: 6.884e-02 	 Loss in Target Net: 4.563e-03	  
 2020-01-31 17:59:08 Iteration 2300 	 Training Loss: 6.452e-02 	 Loss in Target Net: 6.022e-03	  
 2020-01-31 17:59:30 Iteration 2350 	 Training Loss: 6.737e-02 	 Loss in Target Net: 5.982e-03	  
 2020-01-31 17:59:51 Iteration 2400 	 Training Loss: 6.343e-02 	 Loss in Target Net: 6.662e-03	  
 2020-01-31 18:00:12 Iteration 2450 	 Training Loss: 6.640e-02 	 Loss in Target Net: 3.969e-03	  
 2020-01-31 18:00:33 Iteration 2500 	 Training Loss: 6.317e-02 	 Loss in Target Net: 4.119e-03	  
 2020-01-31 18:00:53 Iteration 2550 	 Training Loss: 6.816e-02 	 Loss in Target Net: 3.970e-03	  
 2020-01-31 18:01:14 Iteration 2600 	 Training Loss: 6.414e-02 	 Loss in Target Net: 6.211e-03	  
 2020-01-31 18:01:35 Iteration 2650 	 Training Loss: 6.382e-02 	 Loss in Target Net: 6.493e-03	  
 2020-01-31 18:01:56 Iteration 2700 	 Training Loss: 6.536e-02 	 Loss in Target Net: 5.376e-03	  
 2020-01-31 18:02:17 Iteration 2750 	 Training Loss: 7.507e-02 	 Loss in Target Net: 5.472e-03	  
 2020-01-31 18:02:38 Iteration 2800 	 Training Loss: 6.329e-02 	 Loss in Target Net: 3.165e-03	  
 2020-01-31 18:02:58 Iteration 2850 	 Training Loss: 6.407e-02 	 Loss in Target Net: 5.295e-03	  
 2020-01-31 18:03:19 Iteration 2900 	 Training Loss: 7.406e-02 	 Loss in Target Net: 4.792e-03	  
 2020-01-31 18:03:40 Iteration 2950 	 Training Loss: 6.671e-02 	 Loss in Target Net: 7.486e-03	  
 2020-01-31 18:04:01 Iteration 3000 	 Training Loss: 6.188e-02 	 Loss in Target Net: 6.193e-03	  
 2020-01-31 18:04:22 Iteration 3050 	 Training Loss: 7.266e-02 	 Loss in Target Net: 5.051e-03	  
 2020-01-31 18:04:43 Iteration 3100 	 Training Loss: 6.331e-02 	 Loss in Target Net: 4.674e-03	  
 2020-01-31 18:05:04 Iteration 3150 	 Training Loss: 6.791e-02 	 Loss in Target Net: 4.787e-03	  
 2020-01-31 18:05:25 Iteration 3200 	 Training Loss: 6.890e-02 	 Loss in Target Net: 4.612e-03	  
 2020-01-31 18:05:46 Iteration 3250 	 Training Loss: 7.183e-02 	 Loss in Target Net: 5.530e-03	  
 2020-01-31 18:06:08 Iteration 3300 	 Training Loss: 6.684e-02 	 Loss in Target Net: 6.559e-03	  
 2020-01-31 18:06:28 Iteration 3350 	 Training Loss: 7.195e-02 	 Loss in Target Net: 6.742e-03	  
 2020-01-31 18:06:50 Iteration 3400 	 Training Loss: 7.112e-02 	 Loss in Target Net: 5.410e-03	  
 2020-01-31 18:07:12 Iteration 3450 	 Training Loss: 6.795e-02 	 Loss in Target Net: 4.879e-03	  
 2020-01-31 18:07:32 Iteration 3500 	 Training Loss: 6.581e-02 	 Loss in Target Net: 4.251e-03	  
 2020-01-31 18:07:53 Iteration 3550 	 Training Loss: 6.573e-02 	 Loss in Target Net: 5.142e-03	  
 2020-01-31 18:08:14 Iteration 3600 	 Training Loss: 6.697e-02 	 Loss in Target Net: 6.867e-03	  
 2020-01-31 18:08:35 Iteration 3650 	 Training Loss: 7.046e-02 	 Loss in Target Net: 4.793e-03	  
 2020-01-31 18:08:56 Iteration 3700 	 Training Loss: 6.869e-02 	 Loss in Target Net: 4.032e-03	  
 2020-01-31 18:09:17 Iteration 3750 	 Training Loss: 6.502e-02 	 Loss in Target Net: 6.555e-03	  
 2020-01-31 18:09:38 Iteration 3800 	 Training Loss: 6.693e-02 	 Loss in Target Net: 5.620e-03	  
 2020-01-31 18:10:01 Iteration 3850 	 Training Loss: 6.503e-02 	 Loss in Target Net: 3.738e-03	  
 2020-01-31 18:10:22 Iteration 3900 	 Training Loss: 6.829e-02 	 Loss in Target Net: 4.123e-03	  
 2020-01-31 18:10:44 Iteration 3950 	 Training Loss: 7.312e-02 	 Loss in Target Net: 3.781e-03	  
 2020-01-31 18:11:05 Iteration 3999 	 Training Loss: 6.170e-02 	 Loss in Target Net: 3.588e-03	  
Evaluating against victims networks
DPN92
Using Adam for retraining
Files already downloaded and verified
2020-01-31 18:11:09, Epoch 0, Iteration 7, loss 0.524 (3.070), acc 94.231 (74.400)
2020-01-31 18:11:09, Epoch 30, Iteration 7, loss 0.387 (0.105), acc 96.154 (97.800)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-15.566457, -3.4697611, -63.774376, -7.8794847, -37.55152, -15.013702, 12.808393, -62.383675, 28.955967, -91.354416], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-01-31 18:11:14 Epoch 59, Val iteration 0, acc 90.400 (90.400)
2020-01-31 18:11:21 Epoch 59, Val iteration 19, acc 92.400 (92.410)
* Prec: 92.41000137329101
--------
SENet18
Using Adam for retraining
Files already downloaded and verified
2020-01-31 18:11:24, Epoch 0, Iteration 7, loss 0.161 (0.902), acc 94.231 (90.200)
2020-01-31 18:11:24, Epoch 30, Iteration 7, loss 0.339 (0.127), acc 96.154 (96.800)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-3.3746552, -13.248632, -7.1123466, -4.414649, 10.841471, -8.171974, 18.894327, -13.842698, 24.230913, -8.637887], Poisons' Predictions:[8, 8, 6, 8, 8]
2020-01-31 18:11:25 Epoch 59, Val iteration 0, acc 91.600 (91.600)
2020-01-31 18:11:27 Epoch 59, Val iteration 19, acc 92.400 (91.380)
* Prec: 91.38000144958497
--------
ResNet50
Using Adam for retraining
Files already downloaded and verified
2020-01-31 18:11:29, Epoch 0, Iteration 7, loss 0.008 (0.414), acc 100.000 (92.800)
2020-01-31 18:11:29, Epoch 30, Iteration 7, loss 0.000 (0.000), acc 100.000 (100.000)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-77.04619, -15.820089, -19.278347, -4.2545314, -41.61223, -6.6552334, 9.448893, -25.026606, 32.84475, -40.573704], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-01-31 18:11:30 Epoch 59, Val iteration 0, acc 92.400 (92.400)
2020-01-31 18:11:34 Epoch 59, Val iteration 19, acc 92.600 (93.020)
* Prec: 93.02000160217285
--------
ResNeXt29_2x64d
Using Adam for retraining
Files already downloaded and verified
2020-01-31 18:11:37, Epoch 0, Iteration 7, loss 0.596 (2.653), acc 88.462 (69.600)
2020-01-31 18:11:37, Epoch 30, Iteration 7, loss 0.122 (0.050), acc 98.077 (98.800)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-21.267967, 9.662866, -18.613674, 6.3411317, -62.339256, -32.43233, 21.279114, -39.94048, 22.87748, -14.621545], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-01-31 18:11:38 Epoch 59, Val iteration 0, acc 93.600 (93.600)
2020-01-31 18:11:42 Epoch 59, Val iteration 19, acc 93.000 (92.810)
* Prec: 92.81000213623047
--------
GoogLeNet
Using Adam for retraining
Files already downloaded and verified
2020-01-31 18:11:45, Epoch 0, Iteration 7, loss 0.090 (0.398), acc 100.000 (91.600)
2020-01-31 18:11:45, Epoch 30, Iteration 7, loss 0.048 (0.037), acc 96.154 (97.800)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-26.373363, -13.210057, -8.297762, -1.7892953, -10.764399, -6.9790716, 6.246864, -11.568774, 8.021535, -25.303629], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-01-31 18:11:48 Epoch 59, Val iteration 0, acc 90.200 (90.200)
2020-01-31 18:11:52 Epoch 59, Val iteration 19, acc 90.200 (91.490)
* Prec: 91.49000205993653
--------
MobileNetV2
Using Adam for retraining
Files already downloaded and verified
2020-01-31 18:11:55, Epoch 0, Iteration 7, loss 0.975 (2.864), acc 84.615 (66.200)
2020-01-31 18:11:55, Epoch 30, Iteration 7, loss 0.477 (0.393), acc 88.462 (92.000)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[4.559383, 3.4167259, -2.5239103, 18.883118, -15.076527, -0.23645854, 31.688477, -30.792301, 33.6868, -32.564358], Poisons' Predictions:[8, 8, 6, 8, 6]
2020-01-31 18:11:56 Epoch 59, Val iteration 0, acc 88.800 (88.800)
2020-01-31 18:11:58 Epoch 59, Val iteration 19, acc 88.200 (87.140)
* Prec: 87.14000129699707
--------
ResNet18
Using Adam for retraining
Files already downloaded and verified
2020-01-31 18:12:00, Epoch 0, Iteration 7, loss 0.626 (0.719), acc 92.308 (85.800)
2020-01-31 18:12:00, Epoch 30, Iteration 7, loss 0.157 (0.045), acc 92.308 (98.400)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-28.112144, -5.950345, -11.837439, 1.8840563, -43.824753, -10.865148, 1.5741833, -30.335321, 7.2977514, -31.469028], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-01-31 18:12:00 Epoch 59, Val iteration 0, acc 93.200 (93.200)
2020-01-31 18:12:02 Epoch 59, Val iteration 19, acc 94.000 (92.630)
* Prec: 92.63000183105468
--------
DenseNet121
Using Adam for retraining
Files already downloaded and verified
2020-01-31 18:12:05, Epoch 0, Iteration 7, loss 0.255 (0.445), acc 92.308 (92.000)
2020-01-31 18:12:05, Epoch 30, Iteration 7, loss 0.007 (0.004), acc 100.000 (100.000)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-11.108739, -19.3294, -11.542237, -4.214205, -10.953102, -5.507483, 7.2528396, -31.704403, 6.1440387, -13.695089], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-01-31 18:12:07 Epoch 59, Val iteration 0, acc 94.200 (94.200)
2020-01-31 18:12:11 Epoch 59, Val iteration 19, acc 92.400 (93.000)
* Prec: 93.0000015258789
--------
------SUMMARY------
TIME ELAPSED (mins): 28
TARGET INDEX: 6
DPN92 1
SENet18 1
ResNet50 1
ResNeXt29_2x64d 1
GoogLeNet 1
MobileNetV2 1
ResNet18 1
DenseNet121 0
