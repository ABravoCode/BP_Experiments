Namespace(chk_path='chk-black-ourmean/', chk_subdir='poisons', device='cuda', dset_path='datasets', end2end=False, eval_poison_path='', gpu='10', lr_decay_epoch=[30, 45], mode='mean', model_resume_path='model-chks', nearest=False, net_repeat=1, num_per_class=50, original_grad=True, poison_decay_ites=[], poison_decay_ratio=0.1, poison_epsilon=0.1, poison_ites=4000, poison_label=8, poison_lr=0.04, poison_momentum=0.9, poison_num=5, poison_opt='adam', resume_poison_ite=0, retrain_bsize=64, retrain_epochs=60, retrain_lr=0.1, retrain_momentum=0.9, retrain_opt='adam', retrain_wd=0, subs_chk_name=['ckpt-%s-4800-dp0.200-droplayer0.000-seed1226.t7', 'ckpt-%s-4800-dp0.250-droplayer0.000-seed1226.t7', 'ckpt-%s-4800-dp0.300-droplayer0.000.t7'], subs_dp=[0.2, 0.25, 0.3], subset_group=0, substitute_nets=['DPN92', 'SENet18', 'ResNet50', 'ResNeXt29_2x64d', 'GoogLeNet', 'MobileNetV2'], target_index=42, target_label=6, target_net=['DPN92', 'SENet18', 'ResNet50', 'ResNeXt29_2x64d', 'GoogLeNet', 'MobileNetV2', 'ResNet18', 'DenseNet121'], test_chk_name='ckpt-%s-4800.t7', tol=1e-06, train_data_path='datasets/CIFAR10_TRAIN_Split.pth')
Path: chk-black-ourmean/mean/4000/42
Selected base image indices: [213, 225, 227, 247, 249]
 2020-02-04 21:22:18 Iteration 0 	 Training Loss: 1.115e+00 	 Loss in Target Net: 4.673e-01	  
 2020-02-04 21:23:36 Iteration 50 	 Training Loss: 9.496e-02 	 Loss in Target Net: 8.052e-03	  
 2020-02-04 21:24:54 Iteration 100 	 Training Loss: 8.049e-02 	 Loss in Target Net: 9.600e-03	  
 2020-02-04 21:26:12 Iteration 150 	 Training Loss: 7.743e-02 	 Loss in Target Net: 8.047e-03	  
 2020-02-04 21:27:32 Iteration 200 	 Training Loss: 7.847e-02 	 Loss in Target Net: 9.467e-03	  
 2020-02-04 21:28:53 Iteration 250 	 Training Loss: 7.827e-02 	 Loss in Target Net: 1.092e-02	  
 2020-02-04 21:30:12 Iteration 300 	 Training Loss: 6.954e-02 	 Loss in Target Net: 9.207e-03	  
 2020-02-04 21:31:30 Iteration 350 	 Training Loss: 7.520e-02 	 Loss in Target Net: 8.926e-03	  
 2020-02-04 21:32:50 Iteration 400 	 Training Loss: 7.091e-02 	 Loss in Target Net: 8.402e-03	  
 2020-02-04 21:34:08 Iteration 450 	 Training Loss: 7.144e-02 	 Loss in Target Net: 7.512e-03	  
 2020-02-04 21:35:28 Iteration 500 	 Training Loss: 6.747e-02 	 Loss in Target Net: 9.116e-03	  
 2020-02-04 21:36:46 Iteration 550 	 Training Loss: 6.928e-02 	 Loss in Target Net: 9.127e-03	  
 2020-02-04 21:38:05 Iteration 600 	 Training Loss: 7.368e-02 	 Loss in Target Net: 9.045e-03	  
 2020-02-04 21:39:24 Iteration 650 	 Training Loss: 7.125e-02 	 Loss in Target Net: 5.077e-03	  
 2020-02-04 21:40:50 Iteration 700 	 Training Loss: 7.609e-02 	 Loss in Target Net: 5.777e-03	  
 2020-02-04 21:42:27 Iteration 750 	 Training Loss: 7.292e-02 	 Loss in Target Net: 6.603e-03	  
 2020-02-04 21:44:05 Iteration 800 	 Training Loss: 7.265e-02 	 Loss in Target Net: 8.384e-03	  
 2020-02-04 21:45:43 Iteration 850 	 Training Loss: 6.768e-02 	 Loss in Target Net: 6.996e-03	  
 2020-02-04 21:47:20 Iteration 900 	 Training Loss: 7.912e-02 	 Loss in Target Net: 6.050e-03	  
 2020-02-04 21:48:58 Iteration 950 	 Training Loss: 6.702e-02 	 Loss in Target Net: 6.375e-03	  
 2020-02-04 21:50:29 Iteration 1000 	 Training Loss: 6.739e-02 	 Loss in Target Net: 7.735e-03	  
 2020-02-04 21:51:59 Iteration 1050 	 Training Loss: 6.400e-02 	 Loss in Target Net: 7.756e-03	  
 2020-02-04 21:53:30 Iteration 1100 	 Training Loss: 7.187e-02 	 Loss in Target Net: 8.918e-03	  
 2020-02-04 21:55:01 Iteration 1150 	 Training Loss: 7.002e-02 	 Loss in Target Net: 6.392e-03	  
 2020-02-04 21:56:32 Iteration 1200 	 Training Loss: 6.834e-02 	 Loss in Target Net: 1.254e-02	  
 2020-02-04 21:58:05 Iteration 1250 	 Training Loss: 7.172e-02 	 Loss in Target Net: 1.134e-02	  
 2020-02-04 21:59:33 Iteration 1300 	 Training Loss: 7.550e-02 	 Loss in Target Net: 9.421e-03	  
 2020-02-04 22:01:01 Iteration 1350 	 Training Loss: 6.516e-02 	 Loss in Target Net: 8.303e-03	  
 2020-02-04 22:02:27 Iteration 1400 	 Training Loss: 6.903e-02 	 Loss in Target Net: 9.900e-03	  
 2020-02-04 22:03:55 Iteration 1450 	 Training Loss: 6.786e-02 	 Loss in Target Net: 7.016e-03	  
 2020-02-04 22:05:24 Iteration 1500 	 Training Loss: 6.667e-02 	 Loss in Target Net: 1.010e-02	  
 2020-02-04 22:06:53 Iteration 1550 	 Training Loss: 6.861e-02 	 Loss in Target Net: 7.929e-03	  
 2020-02-04 22:08:19 Iteration 1600 	 Training Loss: 6.633e-02 	 Loss in Target Net: 7.949e-03	  
 2020-02-04 22:09:48 Iteration 1650 	 Training Loss: 7.247e-02 	 Loss in Target Net: 9.475e-03	  
 2020-02-04 22:11:11 Iteration 1700 	 Training Loss: 7.031e-02 	 Loss in Target Net: 6.284e-03	  
 2020-02-04 22:12:37 Iteration 1750 	 Training Loss: 7.032e-02 	 Loss in Target Net: 7.848e-03	  
 2020-02-04 22:14:01 Iteration 1800 	 Training Loss: 6.934e-02 	 Loss in Target Net: 6.358e-03	  
 2020-02-04 22:15:29 Iteration 1850 	 Training Loss: 6.886e-02 	 Loss in Target Net: 7.497e-03	  
 2020-02-04 22:17:01 Iteration 1900 	 Training Loss: 6.800e-02 	 Loss in Target Net: 8.021e-03	  
 2020-02-04 22:18:36 Iteration 1950 	 Training Loss: 7.363e-02 	 Loss in Target Net: 7.928e-03	  
 2020-02-04 22:20:13 Iteration 2000 	 Training Loss: 7.461e-02 	 Loss in Target Net: 6.737e-03	  
 2020-02-04 22:21:50 Iteration 2050 	 Training Loss: 6.806e-02 	 Loss in Target Net: 8.185e-03	  
 2020-02-04 22:23:28 Iteration 2100 	 Training Loss: 6.632e-02 	 Loss in Target Net: 7.109e-03	  
 2020-02-04 22:25:03 Iteration 2150 	 Training Loss: 7.017e-02 	 Loss in Target Net: 9.427e-03	  
 2020-02-04 22:26:37 Iteration 2200 	 Training Loss: 7.103e-02 	 Loss in Target Net: 6.090e-03	  
 2020-02-04 22:28:09 Iteration 2250 	 Training Loss: 7.074e-02 	 Loss in Target Net: 5.996e-03	  
 2020-02-04 22:29:42 Iteration 2300 	 Training Loss: 6.869e-02 	 Loss in Target Net: 1.047e-02	  
 2020-02-04 22:31:17 Iteration 2350 	 Training Loss: 7.287e-02 	 Loss in Target Net: 1.146e-02	  
 2020-02-04 22:32:50 Iteration 2400 	 Training Loss: 7.135e-02 	 Loss in Target Net: 8.446e-03	  
 2020-02-04 22:34:25 Iteration 2450 	 Training Loss: 7.041e-02 	 Loss in Target Net: 5.600e-03	  
 2020-02-04 22:36:00 Iteration 2500 	 Training Loss: 6.850e-02 	 Loss in Target Net: 7.273e-03	  
 2020-02-04 22:37:34 Iteration 2550 	 Training Loss: 6.825e-02 	 Loss in Target Net: 9.122e-03	  
 2020-02-04 22:39:08 Iteration 2600 	 Training Loss: 6.878e-02 	 Loss in Target Net: 8.833e-03	  
 2020-02-04 22:40:42 Iteration 2650 	 Training Loss: 6.952e-02 	 Loss in Target Net: 8.134e-03	  
 2020-02-04 22:42:11 Iteration 2700 	 Training Loss: 6.874e-02 	 Loss in Target Net: 5.793e-03	  
 2020-02-04 22:43:43 Iteration 2750 	 Training Loss: 7.205e-02 	 Loss in Target Net: 4.348e-03	  
 2020-02-04 22:45:11 Iteration 2800 	 Training Loss: 6.944e-02 	 Loss in Target Net: 8.167e-03	  
 2020-02-04 22:46:35 Iteration 2850 	 Training Loss: 6.673e-02 	 Loss in Target Net: 6.507e-03	  
 2020-02-04 22:48:01 Iteration 2900 	 Training Loss: 6.606e-02 	 Loss in Target Net: 6.690e-03	  
 2020-02-04 22:49:32 Iteration 2950 	 Training Loss: 6.774e-02 	 Loss in Target Net: 7.015e-03	  
 2020-02-04 22:51:05 Iteration 3000 	 Training Loss: 7.318e-02 	 Loss in Target Net: 8.026e-03	  
 2020-02-04 22:52:37 Iteration 3050 	 Training Loss: 7.368e-02 	 Loss in Target Net: 7.710e-03	  
 2020-02-04 22:54:10 Iteration 3100 	 Training Loss: 7.637e-02 	 Loss in Target Net: 8.718e-03	  
 2020-02-04 22:55:47 Iteration 3150 	 Training Loss: 6.810e-02 	 Loss in Target Net: 1.162e-02	  
 2020-02-04 22:57:24 Iteration 3200 	 Training Loss: 7.217e-02 	 Loss in Target Net: 6.503e-03	  
 2020-02-04 22:58:59 Iteration 3250 	 Training Loss: 7.529e-02 	 Loss in Target Net: 7.511e-03	  
 2020-02-04 23:00:32 Iteration 3300 	 Training Loss: 7.659e-02 	 Loss in Target Net: 5.819e-03	  
 2020-02-04 23:02:06 Iteration 3350 	 Training Loss: 6.540e-02 	 Loss in Target Net: 5.976e-03	  
 2020-02-04 23:03:40 Iteration 3400 	 Training Loss: 6.978e-02 	 Loss in Target Net: 8.375e-03	  
 2020-02-04 23:05:12 Iteration 3450 	 Training Loss: 6.463e-02 	 Loss in Target Net: 8.894e-03	  
 2020-02-04 23:06:43 Iteration 3500 	 Training Loss: 6.965e-02 	 Loss in Target Net: 7.763e-03	  
 2020-02-04 23:08:12 Iteration 3550 	 Training Loss: 6.951e-02 	 Loss in Target Net: 9.625e-03	  
 2020-02-04 23:09:43 Iteration 3600 	 Training Loss: 7.470e-02 	 Loss in Target Net: 7.131e-03	  
 2020-02-04 23:11:13 Iteration 3650 	 Training Loss: 7.338e-02 	 Loss in Target Net: 6.754e-03	  
 2020-02-04 23:12:39 Iteration 3700 	 Training Loss: 7.011e-02 	 Loss in Target Net: 6.627e-03	  
 2020-02-04 23:14:02 Iteration 3750 	 Training Loss: 7.339e-02 	 Loss in Target Net: 6.010e-03	  
 2020-02-04 23:15:25 Iteration 3800 	 Training Loss: 6.638e-02 	 Loss in Target Net: 7.442e-03	  
 2020-02-04 23:16:47 Iteration 3850 	 Training Loss: 6.880e-02 	 Loss in Target Net: 4.757e-03	  
 2020-02-04 23:18:08 Iteration 3900 	 Training Loss: 6.566e-02 	 Loss in Target Net: 8.955e-03	  
 2020-02-04 23:19:26 Iteration 3950 	 Training Loss: 7.048e-02 	 Loss in Target Net: 6.727e-03	  
 2020-02-04 23:20:43 Iteration 3999 	 Training Loss: 7.020e-02 	 Loss in Target Net: 5.712e-03	  
Evaluating against victims networks
DPN92
Using Adam for retraining
Files already downloaded and verified
2020-02-04 23:21:04, Epoch 0, Iteration 7, loss 1.079 (4.971), acc 84.615 (62.800)
2020-02-04 23:21:04, Epoch 30, Iteration 7, loss 0.133 (0.116), acc 98.077 (96.400)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[19.51406, -16.91381, -49.090424, 2.6831965, -24.519444, -7.4737053, 32.677906, -39.6215, 31.72906, -72.34801], Poisons' Predictions:[8, 8, 6, 8, 8]
2020-02-04 23:21:38 Epoch 59, Val iteration 0, acc 91.000 (91.000)
2020-02-04 23:22:26 Epoch 59, Val iteration 19, acc 92.000 (92.190)
* Prec: 92.1900016784668
--------
SENet18
Using Adam for retraining
Files already downloaded and verified
2020-02-04 23:22:31, Epoch 0, Iteration 7, loss 1.294 (0.804), acc 88.462 (85.200)
2020-02-04 23:22:32, Epoch 30, Iteration 7, loss 0.021 (0.199), acc 98.077 (94.800)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[1.3134378, 3.5888453, -7.111573, -7.4007096, -5.4352355, -12.896159, 24.67191, -10.496454, 22.193798, -16.295156], Poisons' Predictions:[6, 6, 6, 8, 6]
2020-02-04 23:22:36 Epoch 59, Val iteration 0, acc 91.400 (91.400)
2020-02-04 23:22:45 Epoch 59, Val iteration 19, acc 92.600 (91.100)
* Prec: 91.10000076293946
--------
ResNet50
Using Adam for retraining
Files already downloaded and verified
2020-02-04 23:22:52, Epoch 0, Iteration 7, loss 0.000 (1.221), acc 100.000 (83.200)
2020-02-04 23:22:52, Epoch 30, Iteration 7, loss 0.000 (0.120), acc 100.000 (99.000)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-31.481293, -39.490772, -36.75363, -48.18938, -19.111897, -53.73562, 19.696453, -36.158245, 24.796457, -33.15817], Poisons' Predictions:[8, 8, 8, 8, 6]
2020-02-04 23:23:00 Epoch 59, Val iteration 0, acc 91.600 (91.600)
2020-02-04 23:23:22 Epoch 59, Val iteration 19, acc 92.400 (92.300)
* Prec: 92.30000190734863
--------
ResNeXt29_2x64d
Using Adam for retraining
Files already downloaded and verified
2020-02-04 23:23:29, Epoch 0, Iteration 7, loss 0.484 (2.590), acc 94.231 (69.600)
2020-02-04 23:23:30, Epoch 30, Iteration 7, loss 0.022 (0.068), acc 98.077 (97.800)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-37.92073, -17.60394, -13.258503, 11.053249, -61.529194, -22.760818, 27.397123, -33.47982, 26.397018, -29.05255], Poisons' Predictions:[8, 8, 6, 8, 8]
2020-02-04 23:23:37 Epoch 59, Val iteration 0, acc 92.600 (92.600)
2020-02-04 23:23:58 Epoch 59, Val iteration 19, acc 92.800 (92.500)
* Prec: 92.50000190734863
--------
GoogLeNet
Using Adam for retraining
Files already downloaded and verified
2020-02-04 23:24:07, Epoch 0, Iteration 7, loss 0.495 (0.496), acc 90.385 (89.600)
2020-02-04 23:24:08, Epoch 30, Iteration 7, loss 0.178 (0.097), acc 94.231 (96.600)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-25.819323, -6.417992, -19.053488, -0.42072248, -8.322805, -5.121664, 10.838119, -14.003453, 7.337009, -18.113684], Poisons' Predictions:[8, 8, 6, 8, 8]
2020-02-04 23:24:24 Epoch 59, Val iteration 0, acc 91.400 (91.400)
2020-02-04 23:24:56 Epoch 59, Val iteration 19, acc 91.400 (91.750)
* Prec: 91.75000228881837
--------
MobileNetV2
Using Adam for retraining
Files already downloaded and verified
2020-02-04 23:25:01, Epoch 0, Iteration 7, loss 0.951 (2.693), acc 84.615 (68.000)
2020-02-04 23:25:01, Epoch 30, Iteration 7, loss 0.005 (0.142), acc 100.000 (96.000)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-3.8427014, -18.500776, -4.184408, 15.187323, -16.903759, -2.1252933, 26.397943, -30.282602, 20.549255, -6.4471054], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-02-04 23:25:05 Epoch 59, Val iteration 0, acc 88.000 (88.000)
2020-02-04 23:25:13 Epoch 59, Val iteration 19, acc 89.000 (86.890)
* Prec: 86.89000091552734
--------
ResNet18
Using Adam for retraining
Files already downloaded and verified
2020-02-04 23:25:16, Epoch 0, Iteration 7, loss 0.441 (0.790), acc 94.231 (85.400)
2020-02-04 23:25:16, Epoch 30, Iteration 7, loss 0.041 (0.030), acc 96.154 (98.600)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-25.486286, -13.320967, -17.987967, 1.2957379, -41.142246, -10.426809, 10.442381, -14.809189, 8.767753, -35.960743], Poisons' Predictions:[8, 6, 8, 8, 8]
2020-02-04 23:25:17 Epoch 59, Val iteration 0, acc 93.600 (93.600)
2020-02-04 23:25:24 Epoch 59, Val iteration 19, acc 93.400 (92.910)
* Prec: 92.91000137329101
--------
DenseNet121
Using Adam for retraining
Files already downloaded and verified
2020-02-04 23:25:32, Epoch 0, Iteration 7, loss 0.154 (0.416), acc 96.154 (91.000)
2020-02-04 23:25:33, Epoch 30, Iteration 7, loss 0.009 (0.009), acc 100.000 (99.800)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-11.018138, -20.414469, -15.569078, -5.321678, -9.721191, -4.6456246, 5.4578524, -31.852264, 4.3198905, -12.82981], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-02-04 23:25:44 Epoch 59, Val iteration 0, acc 93.400 (93.400)
2020-02-04 23:26:08 Epoch 59, Val iteration 19, acc 92.600 (93.070)
* Prec: 93.07000198364258
--------
------SUMMARY------
TIME ELAPSED (mins): 119
TARGET INDEX: 42
DPN92 0
SENet18 0
ResNet50 1
ResNeXt29_2x64d 0
GoogLeNet 0
MobileNetV2 0
ResNet18 0
DenseNet121 0
