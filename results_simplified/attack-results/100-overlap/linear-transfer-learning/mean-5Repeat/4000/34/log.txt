Namespace(chk_path='chk-black-ourmean/', chk_subdir='poisons', device='cuda', dset_path='datasets', end2end=False, eval_poison_path='', gpu='2', lr_decay_epoch=[30, 45], mode='mean', model_resume_path='model-chks', nearest=False, net_repeat=5, num_per_class=50, original_grad=True, poison_decay_ites=[], poison_decay_ratio=0.1, poison_epsilon=0.1, poison_ites=4000, poison_label=8, poison_lr=0.04, poison_momentum=0.9, poison_num=5, poison_opt='adam', resume_poison_ite=0, retrain_bsize=64, retrain_epochs=60, retrain_lr=0.1, retrain_momentum=0.9, retrain_opt='adam', retrain_wd=0, subs_chk_name=['ckpt-%s-4800-dp0.200-droplayer0.000-seed1226.t7', 'ckpt-%s-4800-dp0.250-droplayer0.000-seed1226.t7', 'ckpt-%s-4800-dp0.300-droplayer0.000.t7'], subs_dp=[0.2, 0.25, 0.3], subset_group=0, substitute_nets=['DPN92', 'SENet18', 'ResNet50', 'ResNeXt29_2x64d', 'GoogLeNet', 'MobileNetV2'], target_index=34, target_label=6, target_net=['DPN92', 'SENet18', 'ResNet50', 'ResNeXt29_2x64d', 'GoogLeNet', 'MobileNetV2', 'ResNet18', 'DenseNet121'], test_chk_name='ckpt-%s-4800.t7', tol=1e-06, train_data_path='datasets/CIFAR10_TRAIN_Split.pth')
Path: chk-black-ourmean/mean-5Repeat/4000/34
Selected base image indices: [213, 225, 227, 247, 249]
 2020-02-01 19:29:07 Iteration 0 	 Training Loss: 1.147e+00 	 Loss in Target Net: 4.021e-01	  
 2020-02-01 19:30:57 Iteration 50 	 Training Loss: 8.252e-02 	 Loss in Target Net: 1.902e-02	  
 2020-02-01 19:32:48 Iteration 100 	 Training Loss: 6.900e-02 	 Loss in Target Net: 1.506e-02	  
 2020-02-01 19:34:39 Iteration 150 	 Training Loss: 6.217e-02 	 Loss in Target Net: 9.893e-03	  
 2020-02-01 19:36:28 Iteration 200 	 Training Loss: 6.266e-02 	 Loss in Target Net: 7.485e-03	  
 2020-02-01 19:38:16 Iteration 250 	 Training Loss: 6.184e-02 	 Loss in Target Net: 1.045e-02	  
 2020-02-01 19:40:04 Iteration 300 	 Training Loss: 5.875e-02 	 Loss in Target Net: 1.051e-02	  
 2020-02-01 19:41:47 Iteration 350 	 Training Loss: 5.389e-02 	 Loss in Target Net: 8.157e-03	  
 2020-02-01 19:43:28 Iteration 400 	 Training Loss: 5.833e-02 	 Loss in Target Net: 8.848e-03	  
 2020-02-01 19:45:08 Iteration 450 	 Training Loss: 5.475e-02 	 Loss in Target Net: 1.195e-02	  
 2020-02-01 19:46:49 Iteration 500 	 Training Loss: 5.775e-02 	 Loss in Target Net: 9.788e-03	  
 2020-02-01 19:48:31 Iteration 550 	 Training Loss: 5.744e-02 	 Loss in Target Net: 9.595e-03	  
 2020-02-01 19:50:12 Iteration 600 	 Training Loss: 5.303e-02 	 Loss in Target Net: 1.157e-02	  
 2020-02-01 19:51:53 Iteration 650 	 Training Loss: 5.410e-02 	 Loss in Target Net: 1.304e-02	  
 2020-02-01 19:53:35 Iteration 700 	 Training Loss: 5.375e-02 	 Loss in Target Net: 1.377e-02	  
 2020-02-01 19:55:16 Iteration 750 	 Training Loss: 5.607e-02 	 Loss in Target Net: 1.081e-02	  
 2020-02-01 19:56:57 Iteration 800 	 Training Loss: 5.324e-02 	 Loss in Target Net: 9.366e-03	  
 2020-02-01 19:58:37 Iteration 850 	 Training Loss: 5.121e-02 	 Loss in Target Net: 1.049e-02	  
 2020-02-01 20:00:19 Iteration 900 	 Training Loss: 5.059e-02 	 Loss in Target Net: 1.273e-02	  
 2020-02-01 20:01:59 Iteration 950 	 Training Loss: 5.432e-02 	 Loss in Target Net: 1.030e-02	  
 2020-02-01 20:03:41 Iteration 1000 	 Training Loss: 5.403e-02 	 Loss in Target Net: 1.053e-02	  
 2020-02-01 20:05:22 Iteration 1050 	 Training Loss: 5.398e-02 	 Loss in Target Net: 1.184e-02	  
 2020-02-01 20:07:03 Iteration 1100 	 Training Loss: 5.666e-02 	 Loss in Target Net: 8.035e-03	  
 2020-02-01 20:08:44 Iteration 1150 	 Training Loss: 5.197e-02 	 Loss in Target Net: 7.923e-03	  
 2020-02-01 20:10:25 Iteration 1200 	 Training Loss: 5.228e-02 	 Loss in Target Net: 7.789e-03	  
 2020-02-01 20:12:07 Iteration 1250 	 Training Loss: 5.360e-02 	 Loss in Target Net: 4.821e-03	  
 2020-02-01 20:13:47 Iteration 1300 	 Training Loss: 5.516e-02 	 Loss in Target Net: 9.267e-03	  
 2020-02-01 20:15:27 Iteration 1350 	 Training Loss: 5.151e-02 	 Loss in Target Net: 6.472e-03	  
 2020-02-01 20:17:08 Iteration 1400 	 Training Loss: 5.251e-02 	 Loss in Target Net: 1.017e-02	  
 2020-02-01 20:18:50 Iteration 1450 	 Training Loss: 5.405e-02 	 Loss in Target Net: 6.434e-03	  
 2020-02-01 20:20:32 Iteration 1500 	 Training Loss: 5.580e-02 	 Loss in Target Net: 1.032e-02	  
 2020-02-01 20:22:13 Iteration 1550 	 Training Loss: 5.152e-02 	 Loss in Target Net: 1.196e-02	  
 2020-02-01 20:23:53 Iteration 1600 	 Training Loss: 5.308e-02 	 Loss in Target Net: 6.051e-03	  
 2020-02-01 20:25:33 Iteration 1650 	 Training Loss: 5.195e-02 	 Loss in Target Net: 5.467e-03	  
 2020-02-01 20:27:13 Iteration 1700 	 Training Loss: 5.323e-02 	 Loss in Target Net: 6.822e-03	  
 2020-02-01 20:28:53 Iteration 1750 	 Training Loss: 5.368e-02 	 Loss in Target Net: 7.817e-03	  
 2020-02-01 20:30:34 Iteration 1800 	 Training Loss: 5.085e-02 	 Loss in Target Net: 7.607e-03	  
 2020-02-01 20:32:14 Iteration 1850 	 Training Loss: 5.392e-02 	 Loss in Target Net: 7.807e-03	  
 2020-02-01 20:33:54 Iteration 1900 	 Training Loss: 5.562e-02 	 Loss in Target Net: 5.848e-03	  
 2020-02-01 20:35:36 Iteration 1950 	 Training Loss: 5.579e-02 	 Loss in Target Net: 8.079e-03	  
 2020-02-01 20:37:16 Iteration 2000 	 Training Loss: 5.184e-02 	 Loss in Target Net: 9.958e-03	  
 2020-02-01 20:38:57 Iteration 2050 	 Training Loss: 5.151e-02 	 Loss in Target Net: 8.103e-03	  
 2020-02-01 20:40:37 Iteration 2100 	 Training Loss: 4.988e-02 	 Loss in Target Net: 9.975e-03	  
 2020-02-01 20:42:18 Iteration 2150 	 Training Loss: 5.090e-02 	 Loss in Target Net: 1.029e-02	  
 2020-02-01 20:43:59 Iteration 2200 	 Training Loss: 5.077e-02 	 Loss in Target Net: 8.911e-03	  
 2020-02-01 20:45:40 Iteration 2250 	 Training Loss: 5.200e-02 	 Loss in Target Net: 7.468e-03	  
 2020-02-01 20:47:22 Iteration 2300 	 Training Loss: 5.099e-02 	 Loss in Target Net: 7.248e-03	  
 2020-02-01 20:49:03 Iteration 2350 	 Training Loss: 4.973e-02 	 Loss in Target Net: 7.631e-03	  
 2020-02-01 20:50:44 Iteration 2400 	 Training Loss: 5.048e-02 	 Loss in Target Net: 6.609e-03	  
 2020-02-01 20:52:24 Iteration 2450 	 Training Loss: 5.198e-02 	 Loss in Target Net: 8.781e-03	  
 2020-02-01 20:54:05 Iteration 2500 	 Training Loss: 5.613e-02 	 Loss in Target Net: 5.591e-03	  
 2020-02-01 20:55:46 Iteration 2550 	 Training Loss: 5.289e-02 	 Loss in Target Net: 7.215e-03	  
 2020-02-01 20:57:28 Iteration 2600 	 Training Loss: 5.128e-02 	 Loss in Target Net: 8.668e-03	  
 2020-02-01 20:59:08 Iteration 2650 	 Training Loss: 5.220e-02 	 Loss in Target Net: 6.963e-03	  
 2020-02-01 21:00:49 Iteration 2700 	 Training Loss: 5.120e-02 	 Loss in Target Net: 7.547e-03	  
 2020-02-01 21:02:29 Iteration 2750 	 Training Loss: 5.434e-02 	 Loss in Target Net: 4.889e-03	  
 2020-02-01 21:04:10 Iteration 2800 	 Training Loss: 5.184e-02 	 Loss in Target Net: 5.758e-03	  
 2020-02-01 21:05:50 Iteration 2850 	 Training Loss: 4.950e-02 	 Loss in Target Net: 8.632e-03	  
 2020-02-01 21:07:30 Iteration 2900 	 Training Loss: 5.326e-02 	 Loss in Target Net: 8.292e-03	  
 2020-02-01 21:09:12 Iteration 2950 	 Training Loss: 5.430e-02 	 Loss in Target Net: 8.304e-03	  
 2020-02-01 21:10:52 Iteration 3000 	 Training Loss: 4.982e-02 	 Loss in Target Net: 5.116e-03	  
 2020-02-01 21:12:33 Iteration 3050 	 Training Loss: 4.985e-02 	 Loss in Target Net: 9.392e-03	  
 2020-02-01 21:14:13 Iteration 3100 	 Training Loss: 5.144e-02 	 Loss in Target Net: 6.438e-03	  
 2020-02-01 21:15:53 Iteration 3150 	 Training Loss: 5.390e-02 	 Loss in Target Net: 5.128e-03	  
 2020-02-01 21:17:35 Iteration 3200 	 Training Loss: 5.372e-02 	 Loss in Target Net: 5.275e-03	  
 2020-02-01 21:19:16 Iteration 3250 	 Training Loss: 5.519e-02 	 Loss in Target Net: 7.746e-03	  
 2020-02-01 21:20:56 Iteration 3300 	 Training Loss: 5.215e-02 	 Loss in Target Net: 7.400e-03	  
 2020-02-01 21:22:38 Iteration 3350 	 Training Loss: 5.261e-02 	 Loss in Target Net: 7.362e-03	  
 2020-02-01 21:24:18 Iteration 3400 	 Training Loss: 5.022e-02 	 Loss in Target Net: 7.408e-03	  
 2020-02-01 21:25:58 Iteration 3450 	 Training Loss: 4.942e-02 	 Loss in Target Net: 7.058e-03	  
 2020-02-01 21:27:39 Iteration 3500 	 Training Loss: 5.522e-02 	 Loss in Target Net: 7.329e-03	  
 2020-02-01 21:29:18 Iteration 3550 	 Training Loss: 5.136e-02 	 Loss in Target Net: 6.218e-03	  
 2020-02-01 21:30:58 Iteration 3600 	 Training Loss: 5.269e-02 	 Loss in Target Net: 6.557e-03	  
 2020-02-01 21:32:38 Iteration 3650 	 Training Loss: 4.972e-02 	 Loss in Target Net: 6.857e-03	  
 2020-02-01 21:34:18 Iteration 3700 	 Training Loss: 5.058e-02 	 Loss in Target Net: 7.071e-03	  
 2020-02-01 21:35:58 Iteration 3750 	 Training Loss: 4.980e-02 	 Loss in Target Net: 4.730e-03	  
 2020-02-01 21:37:38 Iteration 3800 	 Training Loss: 5.453e-02 	 Loss in Target Net: 5.705e-03	  
 2020-02-01 21:39:18 Iteration 3850 	 Training Loss: 5.235e-02 	 Loss in Target Net: 6.609e-03	  
 2020-02-01 21:40:58 Iteration 3900 	 Training Loss: 5.566e-02 	 Loss in Target Net: 6.887e-03	  
 2020-02-01 21:42:38 Iteration 3950 	 Training Loss: 5.239e-02 	 Loss in Target Net: 7.852e-03	  
 2020-02-01 21:44:16 Iteration 3999 	 Training Loss: 5.168e-02 	 Loss in Target Net: 7.200e-03	  
Evaluating against victims networks
DPN92
Using Adam for retraining
Files already downloaded and verified
2020-02-01 21:44:22, Epoch 0, Iteration 7, loss 1.458 (3.249), acc 86.538 (72.200)
2020-02-01 21:44:22, Epoch 30, Iteration 7, loss 0.356 (0.119), acc 96.154 (97.800)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[2.6214213, 0.5966672, -29.997705, 4.3897715, -37.306137, -10.984963, 15.076968, -56.358307, 21.854893, -75.147545], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-02-01 21:44:27 Epoch 59, Val iteration 0, acc 91.000 (91.000)
2020-02-01 21:44:34 Epoch 59, Val iteration 19, acc 90.800 (91.970)
* Prec: 91.97000122070312
--------
SENet18
Using Adam for retraining
Files already downloaded and verified
2020-02-01 21:44:36, Epoch 0, Iteration 7, loss 0.677 (0.857), acc 94.231 (87.800)
2020-02-01 21:44:37, Epoch 30, Iteration 7, loss 0.085 (0.173), acc 96.154 (96.200)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[0.72764003, -16.034637, -11.395336, -1.1176766, 1.0866523, -4.252814, 19.362085, -32.1887, 15.169196, -9.933668], Poisons' Predictions:[8, 8, 8, 8, 6]
2020-02-01 21:44:37 Epoch 59, Val iteration 0, acc 92.800 (92.800)
2020-02-01 21:44:39 Epoch 59, Val iteration 19, acc 93.200 (91.960)
* Prec: 91.96000137329102
--------
ResNet50
Using Adam for retraining
Files already downloaded and verified
2020-02-01 21:44:42, Epoch 0, Iteration 7, loss 0.000 (0.509), acc 100.000 (93.200)
2020-02-01 21:44:42, Epoch 30, Iteration 7, loss 0.000 (0.000), acc 100.000 (100.000)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-61.89709, -15.109732, -49.03539, -29.27838, -59.02477, -40.047565, 14.320765, -59.423973, 26.184254, -44.369743], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-02-01 21:44:43 Epoch 59, Val iteration 0, acc 93.200 (93.200)
2020-02-01 21:44:47 Epoch 59, Val iteration 19, acc 93.400 (93.380)
* Prec: 93.38000183105468
--------
ResNeXt29_2x64d
Using Adam for retraining
Files already downloaded and verified
2020-02-01 21:44:49, Epoch 0, Iteration 7, loss 0.363 (1.703), acc 88.462 (74.800)
2020-02-01 21:44:50, Epoch 30, Iteration 7, loss 0.004 (0.055), acc 100.000 (98.200)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-20.835897, -3.493783, -6.7160673, 9.0217085, -48.3323, -20.232803, 2.7283258, -16.02766, 13.442687, -14.139138], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-02-01 21:44:51 Epoch 59, Val iteration 0, acc 92.400 (92.400)
2020-02-01 21:44:55 Epoch 59, Val iteration 19, acc 93.000 (92.800)
* Prec: 92.80000190734863
--------
GoogLeNet
Using Adam for retraining
Files already downloaded and verified
2020-02-01 21:44:58, Epoch 0, Iteration 7, loss 0.909 (0.590), acc 82.692 (84.800)
2020-02-01 21:44:58, Epoch 30, Iteration 7, loss 0.011 (0.041), acc 100.000 (98.600)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-22.418737, -6.3466544, -5.8249354, -3.3179696, -14.868032, -3.2167277, 16.433907, -8.063182, 12.230114, -22.560518], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-02-01 21:45:00 Epoch 59, Val iteration 0, acc 91.000 (91.000)
2020-02-01 21:45:05 Epoch 59, Val iteration 19, acc 91.800 (92.140)
* Prec: 92.14000053405762
--------
MobileNetV2
Using Adam for retraining
Files already downloaded and verified
2020-02-01 21:45:07, Epoch 0, Iteration 7, loss 1.390 (3.791), acc 78.846 (59.200)
2020-02-01 21:45:08, Epoch 30, Iteration 7, loss 0.066 (0.242), acc 96.154 (94.200)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[2.3738015, 3.53963, 3.9270902, 7.3783665, -39.33099, -0.3395961, 1.8904763, -12.823338, 23.146038, -32.357746], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-02-01 21:45:08 Epoch 59, Val iteration 0, acc 87.600 (87.600)
2020-02-01 21:45:11 Epoch 59, Val iteration 19, acc 87.600 (87.180)
* Prec: 87.18000144958496
--------
ResNet18
Using Adam for retraining
Files already downloaded and verified
2020-02-01 21:45:13, Epoch 0, Iteration 7, loss 0.372 (0.578), acc 94.231 (88.800)
2020-02-01 21:45:13, Epoch 30, Iteration 7, loss 0.030 (0.026), acc 98.077 (99.000)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-51.650112, -4.0147123, -36.117393, -3.8561454, -55.995842, -14.182871, 3.8672032, -22.014742, 5.3356314, -30.848703], Poisons' Predictions:[6, 8, 8, 8, 8]
2020-02-01 21:45:14 Epoch 59, Val iteration 0, acc 93.400 (93.400)
2020-02-01 21:45:16 Epoch 59, Val iteration 19, acc 93.600 (92.550)
* Prec: 92.55000190734863
--------
DenseNet121
Using Adam for retraining
Files already downloaded and verified
2020-02-01 21:45:19, Epoch 0, Iteration 7, loss 0.566 (0.389), acc 88.462 (93.200)
2020-02-01 21:45:19, Epoch 30, Iteration 7, loss 0.001 (0.011), acc 100.000 (99.600)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-7.952514, -8.100166, -11.601165, -3.4186654, -15.038837, -7.0043726, 3.8831503, -32.128223, 4.183571, -15.838584], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-02-01 21:45:21 Epoch 59, Val iteration 0, acc 93.000 (93.000)
2020-02-01 21:45:25 Epoch 59, Val iteration 19, acc 92.800 (92.670)
* Prec: 92.67000160217285
--------
------SUMMARY------
TIME ELAPSED (mins): 135
TARGET INDEX: 34
DPN92 1
SENet18 0
ResNet50 1
ResNeXt29_2x64d 1
GoogLeNet 0
MobileNetV2 1
ResNet18 1
DenseNet121 1
