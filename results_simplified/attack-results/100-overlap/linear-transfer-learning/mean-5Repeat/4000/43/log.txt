Namespace(chk_path='chk-black-ourmean/', chk_subdir='poisons', device='cuda', dset_path='datasets', end2end=False, eval_poison_path='', gpu='3', lr_decay_epoch=[30, 45], mode='mean', model_resume_path='model-chks', nearest=False, net_repeat=5, num_per_class=50, original_grad=True, poison_decay_ites=[], poison_decay_ratio=0.1, poison_epsilon=0.1, poison_ites=4000, poison_label=8, poison_lr=0.04, poison_momentum=0.9, poison_num=5, poison_opt='adam', resume_poison_ite=0, retrain_bsize=64, retrain_epochs=60, retrain_lr=0.1, retrain_momentum=0.9, retrain_opt='adam', retrain_wd=0, subs_chk_name=['ckpt-%s-4800-dp0.200-droplayer0.000-seed1226.t7', 'ckpt-%s-4800-dp0.250-droplayer0.000-seed1226.t7', 'ckpt-%s-4800-dp0.300-droplayer0.000.t7'], subs_dp=[0.2, 0.25, 0.3], subset_group=0, substitute_nets=['DPN92', 'SENet18', 'ResNet50', 'ResNeXt29_2x64d', 'GoogLeNet', 'MobileNetV2'], target_index=43, target_label=6, target_net=['DPN92', 'SENet18', 'ResNet50', 'ResNeXt29_2x64d', 'GoogLeNet', 'MobileNetV2', 'ResNet18', 'DenseNet121'], test_chk_name='ckpt-%s-4800.t7', tol=1e-06, train_data_path='datasets/CIFAR10_TRAIN_Split.pth')
Path: chk-black-ourmean/mean-5Repeat/4000/43
Selected base image indices: [213, 225, 227, 247, 249]
 2020-02-02 01:17:52 Iteration 0 	 Training Loss: 1.085e+00 	 Loss in Target Net: 3.538e-01	  
 2020-02-02 01:19:44 Iteration 50 	 Training Loss: 6.257e-02 	 Loss in Target Net: 4.393e-03	  
 2020-02-02 01:21:36 Iteration 100 	 Training Loss: 5.223e-02 	 Loss in Target Net: 4.169e-03	  
 2020-02-02 01:23:28 Iteration 150 	 Training Loss: 4.587e-02 	 Loss in Target Net: 3.637e-03	  
 2020-02-02 01:25:21 Iteration 200 	 Training Loss: 4.453e-02 	 Loss in Target Net: 3.214e-03	  
 2020-02-02 01:27:13 Iteration 250 	 Training Loss: 4.322e-02 	 Loss in Target Net: 3.549e-03	  
 2020-02-02 01:29:05 Iteration 300 	 Training Loss: 4.317e-02 	 Loss in Target Net: 4.045e-03	  
 2020-02-02 01:30:57 Iteration 350 	 Training Loss: 4.317e-02 	 Loss in Target Net: 3.931e-03	  
 2020-02-02 01:32:50 Iteration 400 	 Training Loss: 4.413e-02 	 Loss in Target Net: 5.645e-03	  
 2020-02-02 01:34:42 Iteration 450 	 Training Loss: 4.196e-02 	 Loss in Target Net: 5.169e-03	  
 2020-02-02 01:36:34 Iteration 500 	 Training Loss: 4.098e-02 	 Loss in Target Net: 5.486e-03	  
 2020-02-02 01:38:25 Iteration 550 	 Training Loss: 4.180e-02 	 Loss in Target Net: 5.637e-03	  
 2020-02-02 01:40:16 Iteration 600 	 Training Loss: 4.198e-02 	 Loss in Target Net: 5.857e-03	  
 2020-02-02 01:42:06 Iteration 650 	 Training Loss: 4.091e-02 	 Loss in Target Net: 4.274e-03	  
 2020-02-02 01:43:58 Iteration 700 	 Training Loss: 3.817e-02 	 Loss in Target Net: 4.436e-03	  
 2020-02-02 01:45:48 Iteration 750 	 Training Loss: 4.075e-02 	 Loss in Target Net: 4.736e-03	  
 2020-02-02 01:47:39 Iteration 800 	 Training Loss: 3.882e-02 	 Loss in Target Net: 3.665e-03	  
 2020-02-02 01:49:30 Iteration 850 	 Training Loss: 3.975e-02 	 Loss in Target Net: 3.018e-03	  
 2020-02-02 01:51:21 Iteration 900 	 Training Loss: 4.007e-02 	 Loss in Target Net: 3.651e-03	  
 2020-02-02 01:53:12 Iteration 950 	 Training Loss: 3.988e-02 	 Loss in Target Net: 4.266e-03	  
 2020-02-02 01:55:03 Iteration 1000 	 Training Loss: 3.903e-02 	 Loss in Target Net: 4.728e-03	  
 2020-02-02 01:56:54 Iteration 1050 	 Training Loss: 4.204e-02 	 Loss in Target Net: 3.216e-03	  
 2020-02-02 01:58:44 Iteration 1100 	 Training Loss: 4.340e-02 	 Loss in Target Net: 2.548e-03	  
 2020-02-02 02:00:36 Iteration 1150 	 Training Loss: 3.856e-02 	 Loss in Target Net: 3.519e-03	  
 2020-02-02 02:02:27 Iteration 1200 	 Training Loss: 3.809e-02 	 Loss in Target Net: 3.767e-03	  
 2020-02-02 02:04:18 Iteration 1250 	 Training Loss: 4.112e-02 	 Loss in Target Net: 3.025e-03	  
 2020-02-02 02:06:10 Iteration 1300 	 Training Loss: 3.975e-02 	 Loss in Target Net: 3.401e-03	  
 2020-02-02 02:08:02 Iteration 1350 	 Training Loss: 4.268e-02 	 Loss in Target Net: 3.345e-03	  
 2020-02-02 02:09:53 Iteration 1400 	 Training Loss: 4.216e-02 	 Loss in Target Net: 4.474e-03	  
 2020-02-02 02:11:45 Iteration 1450 	 Training Loss: 4.167e-02 	 Loss in Target Net: 3.377e-03	  
 2020-02-02 02:13:38 Iteration 1500 	 Training Loss: 4.206e-02 	 Loss in Target Net: 4.089e-03	  
 2020-02-02 02:15:30 Iteration 1550 	 Training Loss: 4.012e-02 	 Loss in Target Net: 3.008e-03	  
 2020-02-02 02:17:22 Iteration 1600 	 Training Loss: 3.886e-02 	 Loss in Target Net: 4.218e-03	  
 2020-02-02 02:19:13 Iteration 1650 	 Training Loss: 3.762e-02 	 Loss in Target Net: 3.959e-03	  
 2020-02-02 02:21:04 Iteration 1700 	 Training Loss: 4.004e-02 	 Loss in Target Net: 4.375e-03	  
 2020-02-02 02:22:55 Iteration 1750 	 Training Loss: 3.938e-02 	 Loss in Target Net: 2.821e-03	  
 2020-02-02 02:24:46 Iteration 1800 	 Training Loss: 3.940e-02 	 Loss in Target Net: 2.767e-03	  
 2020-02-02 02:26:37 Iteration 1850 	 Training Loss: 4.087e-02 	 Loss in Target Net: 3.522e-03	  
 2020-02-02 02:28:28 Iteration 1900 	 Training Loss: 3.992e-02 	 Loss in Target Net: 3.878e-03	  
 2020-02-02 02:30:20 Iteration 1950 	 Training Loss: 3.851e-02 	 Loss in Target Net: 3.024e-03	  
 2020-02-02 02:32:12 Iteration 2000 	 Training Loss: 4.085e-02 	 Loss in Target Net: 3.231e-03	  
 2020-02-02 02:34:03 Iteration 2050 	 Training Loss: 3.867e-02 	 Loss in Target Net: 4.232e-03	  
 2020-02-02 02:35:53 Iteration 2100 	 Training Loss: 4.019e-02 	 Loss in Target Net: 2.386e-03	  
 2020-02-02 02:37:43 Iteration 2150 	 Training Loss: 4.142e-02 	 Loss in Target Net: 2.299e-03	  
 2020-02-02 02:39:34 Iteration 2200 	 Training Loss: 3.902e-02 	 Loss in Target Net: 2.695e-03	  
 2020-02-02 02:41:25 Iteration 2250 	 Training Loss: 3.937e-02 	 Loss in Target Net: 2.901e-03	  
 2020-02-02 02:43:16 Iteration 2300 	 Training Loss: 4.137e-02 	 Loss in Target Net: 3.396e-03	  
 2020-02-02 02:45:08 Iteration 2350 	 Training Loss: 3.749e-02 	 Loss in Target Net: 3.276e-03	  
 2020-02-02 02:46:59 Iteration 2400 	 Training Loss: 3.894e-02 	 Loss in Target Net: 2.919e-03	  
 2020-02-02 02:48:52 Iteration 2450 	 Training Loss: 3.863e-02 	 Loss in Target Net: 3.570e-03	  
 2020-02-02 02:50:44 Iteration 2500 	 Training Loss: 3.939e-02 	 Loss in Target Net: 3.586e-03	  
 2020-02-02 02:52:35 Iteration 2550 	 Training Loss: 4.049e-02 	 Loss in Target Net: 3.980e-03	  
 2020-02-02 02:54:25 Iteration 2600 	 Training Loss: 3.958e-02 	 Loss in Target Net: 2.570e-03	  
 2020-02-02 02:56:16 Iteration 2650 	 Training Loss: 3.921e-02 	 Loss in Target Net: 2.853e-03	  
 2020-02-02 02:58:08 Iteration 2700 	 Training Loss: 4.060e-02 	 Loss in Target Net: 2.680e-03	  
 2020-02-02 03:00:01 Iteration 2750 	 Training Loss: 3.848e-02 	 Loss in Target Net: 2.616e-03	  
 2020-02-02 03:01:52 Iteration 2800 	 Training Loss: 3.751e-02 	 Loss in Target Net: 2.898e-03	  
 2020-02-02 03:03:42 Iteration 2850 	 Training Loss: 4.022e-02 	 Loss in Target Net: 2.753e-03	  
 2020-02-02 03:05:33 Iteration 2900 	 Training Loss: 3.782e-02 	 Loss in Target Net: 3.280e-03	  
 2020-02-02 03:07:25 Iteration 2950 	 Training Loss: 3.865e-02 	 Loss in Target Net: 3.897e-03	  
 2020-02-02 03:09:15 Iteration 3000 	 Training Loss: 3.925e-02 	 Loss in Target Net: 2.072e-03	  
 2020-02-02 03:11:06 Iteration 3050 	 Training Loss: 3.960e-02 	 Loss in Target Net: 2.987e-03	  
 2020-02-02 03:12:57 Iteration 3100 	 Training Loss: 4.038e-02 	 Loss in Target Net: 2.574e-03	  
 2020-02-02 03:14:48 Iteration 3150 	 Training Loss: 3.814e-02 	 Loss in Target Net: 2.932e-03	  
 2020-02-02 03:16:39 Iteration 3200 	 Training Loss: 3.715e-02 	 Loss in Target Net: 3.362e-03	  
 2020-02-02 03:18:30 Iteration 3250 	 Training Loss: 3.867e-02 	 Loss in Target Net: 2.507e-03	  
 2020-02-02 03:20:21 Iteration 3300 	 Training Loss: 3.843e-02 	 Loss in Target Net: 4.041e-03	  
 2020-02-02 03:22:12 Iteration 3350 	 Training Loss: 3.782e-02 	 Loss in Target Net: 3.290e-03	  
 2020-02-02 03:24:02 Iteration 3400 	 Training Loss: 4.037e-02 	 Loss in Target Net: 3.220e-03	  
 2020-02-02 03:25:53 Iteration 3450 	 Training Loss: 3.979e-02 	 Loss in Target Net: 2.989e-03	  
 2020-02-02 03:27:43 Iteration 3500 	 Training Loss: 4.074e-02 	 Loss in Target Net: 2.736e-03	  
 2020-02-02 03:29:34 Iteration 3550 	 Training Loss: 4.075e-02 	 Loss in Target Net: 3.565e-03	  
 2020-02-02 03:31:24 Iteration 3600 	 Training Loss: 3.923e-02 	 Loss in Target Net: 3.180e-03	  
 2020-02-02 03:33:15 Iteration 3650 	 Training Loss: 3.888e-02 	 Loss in Target Net: 2.362e-03	  
 2020-02-02 03:35:05 Iteration 3700 	 Training Loss: 3.997e-02 	 Loss in Target Net: 2.111e-03	  
 2020-02-02 03:36:55 Iteration 3750 	 Training Loss: 3.849e-02 	 Loss in Target Net: 2.424e-03	  
 2020-02-02 03:38:46 Iteration 3800 	 Training Loss: 3.778e-02 	 Loss in Target Net: 2.260e-03	  
 2020-02-02 03:40:36 Iteration 3850 	 Training Loss: 3.896e-02 	 Loss in Target Net: 1.780e-03	  
 2020-02-02 03:42:27 Iteration 3900 	 Training Loss: 3.956e-02 	 Loss in Target Net: 2.483e-03	  
 2020-02-02 03:44:17 Iteration 3950 	 Training Loss: 3.908e-02 	 Loss in Target Net: 2.717e-03	  
 2020-02-02 03:46:05 Iteration 3999 	 Training Loss: 4.099e-02 	 Loss in Target Net: 2.552e-03	  
Evaluating against victims networks
DPN92
Using Adam for retraining
Files already downloaded and verified
2020-02-02 03:46:10, Epoch 0, Iteration 7, loss 3.356 (4.880), acc 78.846 (64.200)
2020-02-02 03:46:11, Epoch 30, Iteration 7, loss 0.049 (0.100), acc 98.077 (97.200)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[20.083109, -40.013912, -32.166782, 10.146037, -27.978558, 1.6297307, 46.080944, -68.43093, 45.776897, -99.52056], Poisons' Predictions:[8, 8, 8, 8, 6]
2020-02-02 03:46:16 Epoch 59, Val iteration 0, acc 91.000 (91.000)
2020-02-02 03:46:23 Epoch 59, Val iteration 19, acc 92.400 (92.190)
* Prec: 92.1900016784668
--------
SENet18
Using Adam for retraining
Files already downloaded and verified
2020-02-02 03:46:25, Epoch 0, Iteration 7, loss 0.019 (0.914), acc 98.077 (87.200)
2020-02-02 03:46:26, Epoch 30, Iteration 7, loss 0.097 (0.214), acc 98.077 (96.200)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[2.156618, -7.098483, -13.760514, -7.5874763, 1.4454781, -12.496398, 18.176443, -9.221349, 13.595414, -18.134125], Poisons' Predictions:[6, 8, 6, 6, 6]
2020-02-02 03:46:26 Epoch 59, Val iteration 0, acc 92.600 (92.600)
2020-02-02 03:46:28 Epoch 59, Val iteration 19, acc 93.200 (91.420)
* Prec: 91.42000160217285
--------
ResNet50
Using Adam for retraining
Files already downloaded and verified
2020-02-02 03:46:31, Epoch 0, Iteration 7, loss 0.762 (1.258), acc 96.154 (85.400)
2020-02-02 03:46:31, Epoch 30, Iteration 7, loss 0.062 (0.026), acc 98.077 (99.200)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-15.294702, -24.151764, -37.748882, -17.562311, -45.543533, -105.22772, 26.172173, -58.907436, 22.797152, -49.296314], Poisons' Predictions:[8, 8, 8, 8, 6]
2020-02-02 03:46:32 Epoch 59, Val iteration 0, acc 92.400 (92.400)
2020-02-02 03:46:37 Epoch 59, Val iteration 19, acc 94.000 (92.970)
* Prec: 92.97000122070312
--------
ResNeXt29_2x64d
Using Adam for retraining
Files already downloaded and verified
2020-02-02 03:46:39, Epoch 0, Iteration 7, loss 0.088 (2.082), acc 96.154 (76.400)
2020-02-02 03:46:39, Epoch 30, Iteration 7, loss 0.043 (0.086), acc 98.077 (97.600)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-24.994242, 14.186012, -8.440207, 8.233084, -57.30698, -27.997492, 29.39911, -30.30743, 29.140352, -23.52726], Poisons' Predictions:[8, 8, 8, 8, 6]
2020-02-02 03:46:40 Epoch 59, Val iteration 0, acc 93.600 (93.600)
2020-02-02 03:46:44 Epoch 59, Val iteration 19, acc 93.000 (93.230)
* Prec: 93.23000144958496
--------
GoogLeNet
Using Adam for retraining
Files already downloaded and verified
2020-02-02 03:46:47, Epoch 0, Iteration 7, loss 0.984 (0.615), acc 92.308 (88.200)
2020-02-02 03:46:48, Epoch 30, Iteration 7, loss 0.014 (0.054), acc 100.000 (97.600)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-16.48266, -5.4929814, -10.192614, -0.20672219, -9.912898, -6.5468936, 12.178816, -3.560031, 14.117166, -17.016323], Poisons' Predictions:[8, 8, 6, 6, 6]
2020-02-02 03:46:50 Epoch 59, Val iteration 0, acc 90.800 (90.800)
2020-02-02 03:46:55 Epoch 59, Val iteration 19, acc 92.200 (92.160)
* Prec: 92.16000289916992
--------
MobileNetV2
Using Adam for retraining
Files already downloaded and verified
2020-02-02 03:46:57, Epoch 0, Iteration 7, loss 0.813 (3.072), acc 92.308 (64.200)
2020-02-02 03:46:57, Epoch 30, Iteration 7, loss 0.305 (0.207), acc 92.308 (93.200)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-2.6627624, -25.277327, -10.650433, 13.748118, -13.897275, -6.899555, 23.268957, -26.823605, 22.238882, -29.967485], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-02-02 03:46:58 Epoch 59, Val iteration 0, acc 86.000 (86.000)
2020-02-02 03:47:00 Epoch 59, Val iteration 19, acc 87.000 (86.480)
* Prec: 86.4800018310547
--------
ResNet18
Using Adam for retraining
Files already downloaded and verified
2020-02-02 03:47:02, Epoch 0, Iteration 7, loss 0.870 (1.090), acc 88.462 (79.000)
2020-02-02 03:47:02, Epoch 30, Iteration 7, loss 0.006 (0.031), acc 100.000 (98.800)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-30.8416, -15.772068, -16.656448, -2.4131444, -45.36949, -13.494788, 7.61867, -20.308994, 5.4000573, -34.81856], Poisons' Predictions:[8, 8, 8, 6, 6]
2020-02-02 03:47:03 Epoch 59, Val iteration 0, acc 93.000 (93.000)
2020-02-02 03:47:05 Epoch 59, Val iteration 19, acc 93.800 (92.610)
* Prec: 92.61000213623046
--------
DenseNet121
Using Adam for retraining
Files already downloaded and verified
2020-02-02 03:47:08, Epoch 0, Iteration 7, loss 0.382 (0.403), acc 96.154 (91.800)
2020-02-02 03:47:08, Epoch 30, Iteration 7, loss 0.001 (0.004), acc 100.000 (100.000)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-12.541919, -12.281231, -10.941724, -5.2017, -5.7315717, -3.716913, 4.7426186, -33.912964, 6.873171, -16.635275], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-02-02 03:47:10 Epoch 59, Val iteration 0, acc 93.600 (93.600)
2020-02-02 03:47:14 Epoch 59, Val iteration 19, acc 93.000 (93.150)
* Prec: 93.15000038146972
--------
------SUMMARY------
TIME ELAPSED (mins): 148
TARGET INDEX: 43
DPN92 0
SENet18 0
ResNet50 0
ResNeXt29_2x64d 0
GoogLeNet 1
MobileNetV2 0
ResNet18 0
DenseNet121 1
