Namespace(chk_path='chk-black-ourmean/', chk_subdir='poisons', device='cuda', dset_path='datasets', end2end=False, eval_poison_path='', gpu='0', lr_decay_epoch=[30, 45], mode='mean', model_resume_path='model-chks', nearest=False, net_repeat=5, num_per_class=50, original_grad=True, poison_decay_ites=[], poison_decay_ratio=0.1, poison_epsilon=0.1, poison_ites=4000, poison_label=8, poison_lr=0.04, poison_momentum=0.9, poison_num=5, poison_opt='adam', resume_poison_ite=0, retrain_bsize=64, retrain_epochs=60, retrain_lr=0.1, retrain_momentum=0.9, retrain_opt='adam', retrain_wd=0, subs_chk_name=['ckpt-%s-4800-dp0.200-droplayer0.000-seed1226.t7', 'ckpt-%s-4800-dp0.250-droplayer0.000-seed1226.t7', 'ckpt-%s-4800-dp0.300-droplayer0.000.t7'], subs_dp=[0.2, 0.25, 0.3], subset_group=0, substitute_nets=['DPN92', 'SENet18', 'ResNet50', 'ResNeXt29_2x64d', 'GoogLeNet', 'MobileNetV2'], target_index=16, target_label=6, target_net=['DPN92', 'SENet18', 'ResNet50', 'ResNeXt29_2x64d', 'GoogLeNet', 'MobileNetV2', 'ResNet18', 'DenseNet121'], test_chk_name='ckpt-%s-4800.t7', tol=1e-06, train_data_path='datasets/CIFAR10_TRAIN_Split.pth')
Path: chk-black-ourmean/mean-5Repeat/4000/16
Selected base image indices: [213, 225, 227, 247, 249]
 2020-02-01 10:04:06 Iteration 0 	 Training Loss: 1.134e+00 	 Loss in Target Net: 3.847e-01	  
 2020-02-01 10:05:55 Iteration 50 	 Training Loss: 8.246e-02 	 Loss in Target Net: 2.794e-02	  
 2020-02-01 10:07:42 Iteration 100 	 Training Loss: 6.267e-02 	 Loss in Target Net: 2.368e-02	  
 2020-02-01 10:09:30 Iteration 150 	 Training Loss: 6.028e-02 	 Loss in Target Net: 2.087e-02	  
 2020-02-01 10:11:17 Iteration 200 	 Training Loss: 5.727e-02 	 Loss in Target Net: 1.788e-02	  
 2020-02-01 10:13:06 Iteration 250 	 Training Loss: 5.509e-02 	 Loss in Target Net: 1.719e-02	  
 2020-02-01 10:14:53 Iteration 300 	 Training Loss: 5.110e-02 	 Loss in Target Net: 1.786e-02	  
 2020-02-01 10:16:41 Iteration 350 	 Training Loss: 5.039e-02 	 Loss in Target Net: 1.791e-02	  
 2020-02-01 10:18:28 Iteration 400 	 Training Loss: 4.797e-02 	 Loss in Target Net: 2.085e-02	  
 2020-02-01 10:20:16 Iteration 450 	 Training Loss: 4.963e-02 	 Loss in Target Net: 2.289e-02	  
 2020-02-01 10:22:04 Iteration 500 	 Training Loss: 4.968e-02 	 Loss in Target Net: 2.128e-02	  
 2020-02-01 10:23:51 Iteration 550 	 Training Loss: 4.929e-02 	 Loss in Target Net: 2.016e-02	  
 2020-02-01 10:25:38 Iteration 600 	 Training Loss: 4.746e-02 	 Loss in Target Net: 1.750e-02	  
 2020-02-01 10:27:25 Iteration 650 	 Training Loss: 4.784e-02 	 Loss in Target Net: 1.716e-02	  
 2020-02-01 10:29:12 Iteration 700 	 Training Loss: 4.915e-02 	 Loss in Target Net: 1.628e-02	  
 2020-02-01 10:30:59 Iteration 750 	 Training Loss: 4.715e-02 	 Loss in Target Net: 2.290e-02	  
 2020-02-01 10:32:46 Iteration 800 	 Training Loss: 4.708e-02 	 Loss in Target Net: 1.845e-02	  
 2020-02-01 10:34:33 Iteration 850 	 Training Loss: 4.562e-02 	 Loss in Target Net: 1.950e-02	  
 2020-02-01 10:36:20 Iteration 900 	 Training Loss: 4.738e-02 	 Loss in Target Net: 1.696e-02	  
 2020-02-01 10:38:07 Iteration 950 	 Training Loss: 4.699e-02 	 Loss in Target Net: 1.729e-02	  
 2020-02-01 10:39:54 Iteration 1000 	 Training Loss: 4.940e-02 	 Loss in Target Net: 1.762e-02	  
 2020-02-01 10:41:41 Iteration 1050 	 Training Loss: 4.597e-02 	 Loss in Target Net: 1.802e-02	  
 2020-02-01 10:43:28 Iteration 1100 	 Training Loss: 4.590e-02 	 Loss in Target Net: 1.743e-02	  
 2020-02-01 10:45:15 Iteration 1150 	 Training Loss: 4.579e-02 	 Loss in Target Net: 1.758e-02	  
 2020-02-01 10:47:03 Iteration 1200 	 Training Loss: 4.876e-02 	 Loss in Target Net: 1.697e-02	  
 2020-02-01 10:48:51 Iteration 1250 	 Training Loss: 4.876e-02 	 Loss in Target Net: 1.866e-02	  
 2020-02-01 10:50:38 Iteration 1300 	 Training Loss: 4.856e-02 	 Loss in Target Net: 1.863e-02	  
 2020-02-01 10:52:27 Iteration 1350 	 Training Loss: 4.652e-02 	 Loss in Target Net: 1.799e-02	  
 2020-02-01 10:54:15 Iteration 1400 	 Training Loss: 4.720e-02 	 Loss in Target Net: 1.598e-02	  
 2020-02-01 10:56:04 Iteration 1450 	 Training Loss: 4.762e-02 	 Loss in Target Net: 1.804e-02	  
 2020-02-01 10:57:52 Iteration 1500 	 Training Loss: 4.939e-02 	 Loss in Target Net: 1.661e-02	  
 2020-02-01 10:59:38 Iteration 1550 	 Training Loss: 4.642e-02 	 Loss in Target Net: 2.031e-02	  
 2020-02-01 11:01:27 Iteration 1600 	 Training Loss: 4.814e-02 	 Loss in Target Net: 1.985e-02	  
 2020-02-01 11:03:15 Iteration 1650 	 Training Loss: 4.763e-02 	 Loss in Target Net: 2.088e-02	  
 2020-02-01 11:05:02 Iteration 1700 	 Training Loss: 4.761e-02 	 Loss in Target Net: 1.927e-02	  
 2020-02-01 11:06:49 Iteration 1750 	 Training Loss: 4.445e-02 	 Loss in Target Net: 1.645e-02	  
 2020-02-01 11:08:37 Iteration 1800 	 Training Loss: 4.644e-02 	 Loss in Target Net: 2.028e-02	  
 2020-02-01 11:10:25 Iteration 1850 	 Training Loss: 4.827e-02 	 Loss in Target Net: 2.232e-02	  
 2020-02-01 11:12:12 Iteration 1900 	 Training Loss: 4.703e-02 	 Loss in Target Net: 1.750e-02	  
 2020-02-01 11:13:59 Iteration 1950 	 Training Loss: 4.639e-02 	 Loss in Target Net: 1.913e-02	  
 2020-02-01 11:15:47 Iteration 2000 	 Training Loss: 4.771e-02 	 Loss in Target Net: 2.055e-02	  
 2020-02-01 11:17:34 Iteration 2050 	 Training Loss: 4.549e-02 	 Loss in Target Net: 2.140e-02	  
 2020-02-01 11:19:22 Iteration 2100 	 Training Loss: 4.628e-02 	 Loss in Target Net: 1.917e-02	  
 2020-02-01 11:21:10 Iteration 2150 	 Training Loss: 4.698e-02 	 Loss in Target Net: 2.159e-02	  
 2020-02-01 11:22:58 Iteration 2200 	 Training Loss: 4.636e-02 	 Loss in Target Net: 2.485e-02	  
 2020-02-01 11:24:45 Iteration 2250 	 Training Loss: 4.982e-02 	 Loss in Target Net: 1.894e-02	  
 2020-02-01 11:26:33 Iteration 2300 	 Training Loss: 4.766e-02 	 Loss in Target Net: 2.225e-02	  
 2020-02-01 11:28:21 Iteration 2350 	 Training Loss: 4.583e-02 	 Loss in Target Net: 1.800e-02	  
 2020-02-01 11:30:08 Iteration 2400 	 Training Loss: 4.594e-02 	 Loss in Target Net: 1.810e-02	  
 2020-02-01 11:31:56 Iteration 2450 	 Training Loss: 4.755e-02 	 Loss in Target Net: 1.552e-02	  
 2020-02-01 11:33:44 Iteration 2500 	 Training Loss: 4.667e-02 	 Loss in Target Net: 1.989e-02	  
 2020-02-01 11:35:32 Iteration 2550 	 Training Loss: 4.873e-02 	 Loss in Target Net: 1.926e-02	  
 2020-02-01 11:37:19 Iteration 2600 	 Training Loss: 4.626e-02 	 Loss in Target Net: 1.977e-02	  
 2020-02-01 11:39:06 Iteration 2650 	 Training Loss: 4.725e-02 	 Loss in Target Net: 2.065e-02	  
 2020-02-01 11:40:53 Iteration 2700 	 Training Loss: 4.769e-02 	 Loss in Target Net: 1.652e-02	  
 2020-02-01 11:42:40 Iteration 2750 	 Training Loss: 4.819e-02 	 Loss in Target Net: 2.198e-02	  
 2020-02-01 11:44:27 Iteration 2800 	 Training Loss: 4.800e-02 	 Loss in Target Net: 2.199e-02	  
 2020-02-01 11:46:15 Iteration 2850 	 Training Loss: 4.783e-02 	 Loss in Target Net: 2.174e-02	  
 2020-02-01 11:48:02 Iteration 2900 	 Training Loss: 4.801e-02 	 Loss in Target Net: 1.954e-02	  
 2020-02-01 11:49:51 Iteration 2950 	 Training Loss: 4.981e-02 	 Loss in Target Net: 1.966e-02	  
 2020-02-01 11:51:39 Iteration 3000 	 Training Loss: 4.930e-02 	 Loss in Target Net: 1.850e-02	  
 2020-02-01 11:53:28 Iteration 3050 	 Training Loss: 4.358e-02 	 Loss in Target Net: 2.059e-02	  
 2020-02-01 11:55:15 Iteration 3100 	 Training Loss: 4.527e-02 	 Loss in Target Net: 1.989e-02	  
 2020-02-01 11:57:03 Iteration 3150 	 Training Loss: 4.410e-02 	 Loss in Target Net: 2.043e-02	  
 2020-02-01 11:58:50 Iteration 3200 	 Training Loss: 4.761e-02 	 Loss in Target Net: 1.807e-02	  
 2020-02-01 12:00:37 Iteration 3250 	 Training Loss: 4.384e-02 	 Loss in Target Net: 2.134e-02	  
 2020-02-01 12:02:23 Iteration 3300 	 Training Loss: 4.341e-02 	 Loss in Target Net: 1.876e-02	  
 2020-02-01 12:04:11 Iteration 3350 	 Training Loss: 4.452e-02 	 Loss in Target Net: 1.981e-02	  
 2020-02-01 12:05:59 Iteration 3400 	 Training Loss: 4.588e-02 	 Loss in Target Net: 2.046e-02	  
 2020-02-01 12:07:45 Iteration 3450 	 Training Loss: 4.920e-02 	 Loss in Target Net: 2.141e-02	  
 2020-02-01 12:09:32 Iteration 3500 	 Training Loss: 4.451e-02 	 Loss in Target Net: 2.273e-02	  
 2020-02-01 12:11:20 Iteration 3550 	 Training Loss: 4.585e-02 	 Loss in Target Net: 2.152e-02	  
 2020-02-01 12:13:07 Iteration 3600 	 Training Loss: 4.516e-02 	 Loss in Target Net: 2.301e-02	  
 2020-02-01 12:14:54 Iteration 3650 	 Training Loss: 4.321e-02 	 Loss in Target Net: 1.768e-02	  
 2020-02-01 12:16:42 Iteration 3700 	 Training Loss: 4.867e-02 	 Loss in Target Net: 2.046e-02	  
 2020-02-01 12:18:30 Iteration 3750 	 Training Loss: 4.414e-02 	 Loss in Target Net: 2.002e-02	  
 2020-02-01 12:20:18 Iteration 3800 	 Training Loss: 5.176e-02 	 Loss in Target Net: 1.647e-02	  
 2020-02-01 12:22:05 Iteration 3850 	 Training Loss: 4.727e-02 	 Loss in Target Net: 1.788e-02	  
 2020-02-01 12:23:53 Iteration 3900 	 Training Loss: 4.516e-02 	 Loss in Target Net: 1.899e-02	  
 2020-02-01 12:25:41 Iteration 3950 	 Training Loss: 4.590e-02 	 Loss in Target Net: 2.104e-02	  
 2020-02-01 12:27:27 Iteration 3999 	 Training Loss: 4.667e-02 	 Loss in Target Net: 1.488e-02	  
Evaluating against victims networks
DPN92
Using Adam for retraining
Files already downloaded and verified
2020-02-01 12:27:32, Epoch 0, Iteration 7, loss 1.632 (4.370), acc 90.385 (65.200)
2020-02-01 12:27:33, Epoch 30, Iteration 7, loss 0.060 (0.074), acc 98.077 (97.200)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[3.97821, 12.598081, -49.864803, 2.3888993, -26.96048, -4.4610605, 29.250103, -48.8384, 31.534369, -90.15303], Poisons' Predictions:[8, 8, 6, 8, 6]
2020-02-01 12:27:37 Epoch 59, Val iteration 0, acc 91.000 (91.000)
2020-02-01 12:27:45 Epoch 59, Val iteration 19, acc 92.000 (91.820)
* Prec: 91.82000122070312
--------
SENet18
Using Adam for retraining
Files already downloaded and verified
2020-02-01 12:27:47, Epoch 0, Iteration 7, loss 0.183 (0.720), acc 98.077 (89.200)
2020-02-01 12:27:47, Epoch 30, Iteration 7, loss 0.539 (0.209), acc 90.385 (95.400)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[9.647055, -6.9922094, -10.624997, -3.4146082, 10.375377, -8.156983, 25.275229, -17.524855, 17.589788, -17.640505], Poisons' Predictions:[8, 6, 6, 8, 6]
2020-02-01 12:27:48 Epoch 59, Val iteration 0, acc 92.600 (92.600)
2020-02-01 12:27:50 Epoch 59, Val iteration 19, acc 92.800 (91.720)
* Prec: 91.72000122070312
--------
ResNet50
Using Adam for retraining
Files already downloaded and verified
2020-02-01 12:27:52, Epoch 0, Iteration 7, loss 0.007 (0.575), acc 100.000 (93.000)
2020-02-01 12:27:52, Epoch 30, Iteration 7, loss 0.000 (0.012), acc 100.000 (99.800)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-39.036983, -43.449802, -26.328894, -5.486451, -68.75834, -45.0282, 27.0785, -50.31926, 21.107044, -43.489292], Poisons' Predictions:[8, 8, 6, 8, 8]
2020-02-01 12:27:54 Epoch 59, Val iteration 0, acc 93.200 (93.200)
2020-02-01 12:27:58 Epoch 59, Val iteration 19, acc 93.200 (93.180)
* Prec: 93.18000183105468
--------
ResNeXt29_2x64d
Using Adam for retraining
Files already downloaded and verified
2020-02-01 12:28:00, Epoch 0, Iteration 7, loss 0.613 (2.292), acc 86.538 (73.000)
2020-02-01 12:28:00, Epoch 30, Iteration 7, loss 0.004 (0.053), acc 100.000 (98.000)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-35.308212, 14.356434, -4.4098225, 4.4322467, -83.55189, -37.573685, 26.437054, -42.201714, 22.828863, -24.927069], Poisons' Predictions:[8, 8, 8, 8, 6]
2020-02-01 12:28:02 Epoch 59, Val iteration 0, acc 92.400 (92.400)
2020-02-01 12:28:06 Epoch 59, Val iteration 19, acc 92.600 (92.420)
* Prec: 92.4200008392334
--------
GoogLeNet
Using Adam for retraining
Files already downloaded and verified
2020-02-01 12:28:08, Epoch 0, Iteration 7, loss 0.329 (0.443), acc 94.231 (90.400)
2020-02-01 12:28:08, Epoch 30, Iteration 7, loss 0.029 (0.047), acc 98.077 (98.000)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-21.045513, -3.7598433, -9.053816, -1.1766976, -13.245828, -4.7643814, 10.786333, -2.400509, 8.285354, -15.153844], Poisons' Predictions:[8, 8, 6, 8, 6]
2020-02-01 12:28:11 Epoch 59, Val iteration 0, acc 92.200 (92.200)
2020-02-01 12:28:16 Epoch 59, Val iteration 19, acc 92.600 (92.110)
* Prec: 92.11000137329101
--------
MobileNetV2
Using Adam for retraining
Files already downloaded and verified
2020-02-01 12:28:18, Epoch 0, Iteration 7, loss 1.023 (3.313), acc 82.692 (65.400)
2020-02-01 12:28:18, Epoch 30, Iteration 7, loss 0.062 (0.172), acc 96.154 (93.800)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[7.762468, -6.3561482, -7.862817, 11.835631, -17.10357, 3.918291, 27.975367, -20.718035, 20.666365, -21.924454], Poisons' Predictions:[6, 8, 8, 8, 8]
2020-02-01 12:28:19 Epoch 59, Val iteration 0, acc 88.600 (88.600)
2020-02-01 12:28:21 Epoch 59, Val iteration 19, acc 88.200 (86.600)
* Prec: 86.60000152587891
--------
ResNet18
Using Adam for retraining
Files already downloaded and verified
2020-02-01 12:28:23, Epoch 0, Iteration 7, loss 0.407 (0.973), acc 94.231 (86.400)
2020-02-01 12:28:23, Epoch 30, Iteration 7, loss 0.010 (0.033), acc 100.000 (99.400)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-30.826933, -14.482593, -9.56435, 2.3356369, -35.98645, -7.6162043, 10.525813, -23.71216, 7.4295664, -29.81408], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-02-01 12:28:23 Epoch 59, Val iteration 0, acc 92.200 (92.200)
2020-02-01 12:28:25 Epoch 59, Val iteration 19, acc 93.600 (92.250)
* Prec: 92.25000114440918
--------
DenseNet121
Using Adam for retraining
Files already downloaded and verified
2020-02-01 12:28:28, Epoch 0, Iteration 7, loss 0.344 (0.367), acc 86.538 (92.000)
2020-02-01 12:28:28, Epoch 30, Iteration 7, loss 0.003 (0.006), acc 100.000 (100.000)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-4.3726454, -13.156229, -8.961613, -4.057462, -8.307212, -5.921664, 10.123464, -29.133686, 6.600777, -8.464958], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-02-01 12:28:30 Epoch 59, Val iteration 0, acc 93.600 (93.600)
2020-02-01 12:28:35 Epoch 59, Val iteration 19, acc 92.800 (92.890)
* Prec: 92.89000129699707
--------
------SUMMARY------
TIME ELAPSED (mins): 143
TARGET INDEX: 16
DPN92 1
SENet18 0
ResNet50 0
ResNeXt29_2x64d 0
GoogLeNet 0
MobileNetV2 0
ResNet18 0
DenseNet121 0
