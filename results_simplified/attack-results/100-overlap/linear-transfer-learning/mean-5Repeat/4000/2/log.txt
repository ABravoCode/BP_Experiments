Namespace(chk_path='chk-black-ourmean/', chk_subdir='poisons', device='cuda', dset_path='datasets', end2end=False, eval_poison_path='', gpu='2', lr_decay_epoch=[30, 45], mode='mean', model_resume_path='model-chks', nearest=False, net_repeat=5, num_per_class=50, original_grad=True, poison_decay_ites=[], poison_decay_ratio=0.1, poison_epsilon=0.1, poison_ites=4000, poison_label=8, poison_lr=0.04, poison_momentum=0.9, poison_num=5, poison_opt='adam', resume_poison_ite=0, retrain_bsize=64, retrain_epochs=60, retrain_lr=0.1, retrain_momentum=0.9, retrain_opt='adam', retrain_wd=0, subs_chk_name=['ckpt-%s-4800-dp0.200-droplayer0.000-seed1226.t7', 'ckpt-%s-4800-dp0.250-droplayer0.000-seed1226.t7', 'ckpt-%s-4800-dp0.300-droplayer0.000.t7'], subs_dp=[0.2, 0.25, 0.3], subset_group=0, substitute_nets=['DPN92', 'SENet18', 'ResNet50', 'ResNeXt29_2x64d', 'GoogLeNet', 'MobileNetV2'], target_index=2, target_label=6, target_net=['DPN92', 'SENet18', 'ResNet50', 'ResNeXt29_2x64d', 'GoogLeNet', 'MobileNetV2', 'ResNet18', 'DenseNet121'], test_chk_name='ckpt-%s-4800.t7', tol=1e-06, train_data_path='datasets/CIFAR10_TRAIN_Split.pth')
Path: chk-black-ourmean/mean-5Repeat/4000/2
Selected base image indices: [213, 225, 227, 247, 249]
 2020-02-01 00:37:40 Iteration 0 	 Training Loss: 1.074e+00 	 Loss in Target Net: 3.523e-01	  
 2020-02-01 00:39:26 Iteration 50 	 Training Loss: 6.841e-02 	 Loss in Target Net: 4.929e-03	  
 2020-02-01 00:41:12 Iteration 100 	 Training Loss: 6.334e-02 	 Loss in Target Net: 4.174e-03	  
 2020-02-01 00:42:57 Iteration 150 	 Training Loss: 5.340e-02 	 Loss in Target Net: 3.699e-03	  
 2020-02-01 00:44:42 Iteration 200 	 Training Loss: 5.525e-02 	 Loss in Target Net: 3.633e-03	  
 2020-02-01 00:46:27 Iteration 250 	 Training Loss: 5.490e-02 	 Loss in Target Net: 4.324e-03	  
 2020-02-01 00:48:12 Iteration 300 	 Training Loss: 5.232e-02 	 Loss in Target Net: 2.663e-03	  
 2020-02-01 00:49:57 Iteration 350 	 Training Loss: 5.055e-02 	 Loss in Target Net: 2.593e-03	  
 2020-02-01 00:51:42 Iteration 400 	 Training Loss: 4.638e-02 	 Loss in Target Net: 6.565e-03	  
 2020-02-01 00:53:27 Iteration 450 	 Training Loss: 4.586e-02 	 Loss in Target Net: 3.458e-03	  
 2020-02-01 00:55:12 Iteration 500 	 Training Loss: 4.647e-02 	 Loss in Target Net: 4.290e-03	  
 2020-02-01 00:56:58 Iteration 550 	 Training Loss: 4.610e-02 	 Loss in Target Net: 2.580e-03	  
 2020-02-01 00:58:42 Iteration 600 	 Training Loss: 4.847e-02 	 Loss in Target Net: 3.001e-03	  
 2020-02-01 01:00:27 Iteration 650 	 Training Loss: 4.618e-02 	 Loss in Target Net: 2.691e-03	  
 2020-02-01 01:02:12 Iteration 700 	 Training Loss: 4.592e-02 	 Loss in Target Net: 2.739e-03	  
 2020-02-01 01:03:57 Iteration 750 	 Training Loss: 4.430e-02 	 Loss in Target Net: 3.082e-03	  
 2020-02-01 01:05:42 Iteration 800 	 Training Loss: 4.910e-02 	 Loss in Target Net: 3.301e-03	  
 2020-02-01 01:07:28 Iteration 850 	 Training Loss: 4.607e-02 	 Loss in Target Net: 3.021e-03	  
 2020-02-01 01:09:13 Iteration 900 	 Training Loss: 4.603e-02 	 Loss in Target Net: 3.609e-03	  
 2020-02-01 01:10:59 Iteration 950 	 Training Loss: 4.289e-02 	 Loss in Target Net: 3.131e-03	  
 2020-02-01 01:12:45 Iteration 1000 	 Training Loss: 4.493e-02 	 Loss in Target Net: 2.916e-03	  
 2020-02-01 01:14:30 Iteration 1050 	 Training Loss: 4.577e-02 	 Loss in Target Net: 3.183e-03	  
 2020-02-01 01:16:15 Iteration 1100 	 Training Loss: 4.875e-02 	 Loss in Target Net: 2.681e-03	  
 2020-02-01 01:18:01 Iteration 1150 	 Training Loss: 4.460e-02 	 Loss in Target Net: 2.292e-03	  
 2020-02-01 01:19:47 Iteration 1200 	 Training Loss: 4.652e-02 	 Loss in Target Net: 4.058e-03	  
 2020-02-01 01:21:33 Iteration 1250 	 Training Loss: 4.552e-02 	 Loss in Target Net: 2.969e-03	  
 2020-02-01 01:23:21 Iteration 1300 	 Training Loss: 4.584e-02 	 Loss in Target Net: 2.288e-03	  
 2020-02-01 01:25:09 Iteration 1350 	 Training Loss: 5.075e-02 	 Loss in Target Net: 3.461e-03	  
 2020-02-01 01:26:57 Iteration 1400 	 Training Loss: 4.466e-02 	 Loss in Target Net: 2.399e-03	  
 2020-02-01 01:28:44 Iteration 1450 	 Training Loss: 4.376e-02 	 Loss in Target Net: 3.079e-03	  
 2020-02-01 01:30:29 Iteration 1500 	 Training Loss: 4.422e-02 	 Loss in Target Net: 3.014e-03	  
 2020-02-01 01:32:14 Iteration 1550 	 Training Loss: 4.672e-02 	 Loss in Target Net: 3.029e-03	  
 2020-02-01 01:33:59 Iteration 1600 	 Training Loss: 4.526e-02 	 Loss in Target Net: 3.872e-03	  
 2020-02-01 01:35:45 Iteration 1650 	 Training Loss: 4.529e-02 	 Loss in Target Net: 2.713e-03	  
 2020-02-01 01:37:30 Iteration 1700 	 Training Loss: 4.105e-02 	 Loss in Target Net: 3.777e-03	  
 2020-02-01 01:39:16 Iteration 1750 	 Training Loss: 4.721e-02 	 Loss in Target Net: 2.748e-03	  
 2020-02-01 01:41:01 Iteration 1800 	 Training Loss: 4.450e-02 	 Loss in Target Net: 3.131e-03	  
 2020-02-01 01:42:46 Iteration 1850 	 Training Loss: 4.354e-02 	 Loss in Target Net: 3.292e-03	  
 2020-02-01 01:44:31 Iteration 1900 	 Training Loss: 4.241e-02 	 Loss in Target Net: 3.728e-03	  
 2020-02-01 01:46:16 Iteration 1950 	 Training Loss: 4.347e-02 	 Loss in Target Net: 3.638e-03	  
 2020-02-01 01:48:00 Iteration 2000 	 Training Loss: 4.552e-02 	 Loss in Target Net: 4.019e-03	  
 2020-02-01 01:49:46 Iteration 2050 	 Training Loss: 4.358e-02 	 Loss in Target Net: 3.747e-03	  
 2020-02-01 01:51:31 Iteration 2100 	 Training Loss: 4.359e-02 	 Loss in Target Net: 5.798e-03	  
 2020-02-01 01:53:17 Iteration 2150 	 Training Loss: 4.268e-02 	 Loss in Target Net: 4.301e-03	  
 2020-02-01 01:55:02 Iteration 2200 	 Training Loss: 4.270e-02 	 Loss in Target Net: 4.658e-03	  
 2020-02-01 01:56:47 Iteration 2250 	 Training Loss: 4.643e-02 	 Loss in Target Net: 4.963e-03	  
 2020-02-01 01:58:32 Iteration 2300 	 Training Loss: 4.337e-02 	 Loss in Target Net: 4.417e-03	  
 2020-02-01 02:00:18 Iteration 2350 	 Training Loss: 4.197e-02 	 Loss in Target Net: 2.785e-03	  
 2020-02-01 02:02:05 Iteration 2400 	 Training Loss: 4.302e-02 	 Loss in Target Net: 3.607e-03	  
 2020-02-01 02:03:54 Iteration 2450 	 Training Loss: 4.571e-02 	 Loss in Target Net: 2.999e-03	  
 2020-02-01 02:05:42 Iteration 2500 	 Training Loss: 4.382e-02 	 Loss in Target Net: 3.252e-03	  
 2020-02-01 02:07:26 Iteration 2550 	 Training Loss: 4.413e-02 	 Loss in Target Net: 2.418e-03	  
 2020-02-01 02:09:11 Iteration 2600 	 Training Loss: 4.466e-02 	 Loss in Target Net: 3.540e-03	  
 2020-02-01 02:10:56 Iteration 2650 	 Training Loss: 4.375e-02 	 Loss in Target Net: 4.502e-03	  
 2020-02-01 02:12:42 Iteration 2700 	 Training Loss: 4.600e-02 	 Loss in Target Net: 2.680e-03	  
 2020-02-01 02:14:27 Iteration 2750 	 Training Loss: 4.331e-02 	 Loss in Target Net: 2.357e-03	  
 2020-02-01 02:16:13 Iteration 2800 	 Training Loss: 4.492e-02 	 Loss in Target Net: 2.271e-03	  
 2020-02-01 02:17:58 Iteration 2850 	 Training Loss: 4.486e-02 	 Loss in Target Net: 2.931e-03	  
 2020-02-01 02:19:43 Iteration 2900 	 Training Loss: 4.434e-02 	 Loss in Target Net: 2.335e-03	  
 2020-02-01 02:21:28 Iteration 2950 	 Training Loss: 4.267e-02 	 Loss in Target Net: 1.513e-03	  
 2020-02-01 02:23:14 Iteration 3000 	 Training Loss: 4.387e-02 	 Loss in Target Net: 2.659e-03	  
 2020-02-01 02:24:58 Iteration 3050 	 Training Loss: 4.290e-02 	 Loss in Target Net: 1.972e-03	  
 2020-02-01 02:26:43 Iteration 3100 	 Training Loss: 4.490e-02 	 Loss in Target Net: 3.693e-03	  
 2020-02-01 02:28:29 Iteration 3150 	 Training Loss: 4.254e-02 	 Loss in Target Net: 3.648e-03	  
 2020-02-01 02:30:14 Iteration 3200 	 Training Loss: 4.418e-02 	 Loss in Target Net: 2.725e-03	  
 2020-02-01 02:31:59 Iteration 3250 	 Training Loss: 4.290e-02 	 Loss in Target Net: 2.918e-03	  
 2020-02-01 02:33:45 Iteration 3300 	 Training Loss: 4.289e-02 	 Loss in Target Net: 2.695e-03	  
 2020-02-01 02:35:31 Iteration 3350 	 Training Loss: 4.212e-02 	 Loss in Target Net: 2.702e-03	  
 2020-02-01 02:37:17 Iteration 3400 	 Training Loss: 4.253e-02 	 Loss in Target Net: 1.839e-03	  
 2020-02-01 02:39:03 Iteration 3450 	 Training Loss: 4.380e-02 	 Loss in Target Net: 2.861e-03	  
 2020-02-01 02:40:49 Iteration 3500 	 Training Loss: 4.123e-02 	 Loss in Target Net: 2.372e-03	  
 2020-02-01 02:42:34 Iteration 3550 	 Training Loss: 4.528e-02 	 Loss in Target Net: 2.390e-03	  
 2020-02-01 02:44:20 Iteration 3600 	 Training Loss: 4.501e-02 	 Loss in Target Net: 3.494e-03	  
 2020-02-01 02:46:06 Iteration 3650 	 Training Loss: 4.735e-02 	 Loss in Target Net: 3.948e-03	  
 2020-02-01 02:47:52 Iteration 3700 	 Training Loss: 4.186e-02 	 Loss in Target Net: 2.511e-03	  
 2020-02-01 02:49:37 Iteration 3750 	 Training Loss: 4.309e-02 	 Loss in Target Net: 2.783e-03	  
 2020-02-01 02:51:23 Iteration 3800 	 Training Loss: 4.234e-02 	 Loss in Target Net: 3.470e-03	  
 2020-02-01 02:53:09 Iteration 3850 	 Training Loss: 4.227e-02 	 Loss in Target Net: 2.965e-03	  
 2020-02-01 02:54:55 Iteration 3900 	 Training Loss: 4.239e-02 	 Loss in Target Net: 2.345e-03	  
 2020-02-01 02:56:41 Iteration 3950 	 Training Loss: 4.214e-02 	 Loss in Target Net: 2.903e-03	  
 2020-02-01 02:58:24 Iteration 3999 	 Training Loss: 4.126e-02 	 Loss in Target Net: 2.662e-03	  
Evaluating against victims networks
DPN92
Using Adam for retraining
Files already downloaded and verified
2020-02-01 02:58:29, Epoch 0, Iteration 7, loss 1.407 (3.740), acc 90.385 (72.600)
2020-02-01 02:58:30, Epoch 30, Iteration 7, loss 0.071 (0.220), acc 98.077 (95.600)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-3.3120835, -7.624076, -56.8281, -11.480974, -46.3458, -11.924074, 16.984915, -56.390926, 15.714917, -112.279564], Poisons' Predictions:[8, 8, 8, 6, 8]
2020-02-01 02:58:34 Epoch 59, Val iteration 0, acc 91.200 (91.200)
2020-02-01 02:58:42 Epoch 59, Val iteration 19, acc 92.200 (92.190)
* Prec: 92.19000129699707
--------
SENet18
Using Adam for retraining
Files already downloaded and verified
2020-02-01 02:58:44, Epoch 0, Iteration 7, loss 1.303 (0.754), acc 90.385 (88.200)
2020-02-01 02:58:44, Epoch 30, Iteration 7, loss 0.119 (0.135), acc 96.154 (96.800)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[2.476769, -11.943483, -12.009906, -4.853975, 2.9125977, -11.261193, 18.530611, -11.568003, 15.976215, -12.323946], Poisons' Predictions:[8, 8, 6, 8, 8]
2020-02-01 02:58:45 Epoch 59, Val iteration 0, acc 92.200 (92.200)
2020-02-01 02:58:47 Epoch 59, Val iteration 19, acc 92.800 (91.680)
* Prec: 91.68000221252441
--------
ResNet50
Using Adam for retraining
Files already downloaded and verified
2020-02-01 02:58:49, Epoch 0, Iteration 7, loss 0.018 (0.630), acc 98.077 (89.200)
2020-02-01 02:58:50, Epoch 30, Iteration 7, loss 0.008 (0.009), acc 100.000 (99.800)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-14.575322, -54.405575, -30.737764, -10.923977, -26.166023, -40.592724, 16.281115, -20.470467, 13.612694, -13.812262], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-02-01 02:58:51 Epoch 59, Val iteration 0, acc 92.000 (92.000)
2020-02-01 02:58:55 Epoch 59, Val iteration 19, acc 92.600 (92.510)
* Prec: 92.51000175476074
--------
ResNeXt29_2x64d
Using Adam for retraining
Files already downloaded and verified
2020-02-01 02:58:58, Epoch 0, Iteration 7, loss 0.600 (2.202), acc 92.308 (76.600)
2020-02-01 02:58:58, Epoch 30, Iteration 7, loss 0.003 (0.138), acc 100.000 (97.200)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-49.190506, -24.10505, -10.295731, -5.7250214, -74.696655, -23.52258, 25.445244, -19.494501, 31.226555, -22.774452], Poisons' Predictions:[8, 8, 8, 6, 8]
2020-02-01 02:58:59 Epoch 59, Val iteration 0, acc 91.600 (91.600)
2020-02-01 02:59:03 Epoch 59, Val iteration 19, acc 93.000 (92.790)
* Prec: 92.79000091552734
--------
GoogLeNet
Using Adam for retraining
Files already downloaded and verified
2020-02-01 02:59:06, Epoch 0, Iteration 7, loss 0.287 (0.475), acc 94.231 (87.600)
2020-02-01 02:59:06, Epoch 30, Iteration 7, loss 0.046 (0.074), acc 98.077 (97.000)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-8.292837, -14.587761, -0.69508135, 0.4832933, -4.4914393, 0.47209293, 4.844731, -5.1652527, 3.1726668, -22.45463], Poisons' Predictions:[8, 6, 8, 8, 8]
2020-02-01 02:59:09 Epoch 59, Val iteration 0, acc 91.400 (91.400)
2020-02-01 02:59:14 Epoch 59, Val iteration 19, acc 91.400 (92.020)
* Prec: 92.02000122070312
--------
MobileNetV2
Using Adam for retraining
Files already downloaded and verified
2020-02-01 02:59:16, Epoch 0, Iteration 7, loss 2.565 (3.466), acc 75.000 (63.200)
2020-02-01 02:59:16, Epoch 30, Iteration 7, loss 0.263 (0.250), acc 94.231 (94.600)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[6.532854, -22.076656, 8.076056, 15.080616, -14.855251, -3.9626822, 22.506733, -30.117445, 21.822653, -30.506628], Poisons' Predictions:[8, 8, 8, 8, 6]
2020-02-01 02:59:17 Epoch 59, Val iteration 0, acc 88.400 (88.400)
2020-02-01 02:59:19 Epoch 59, Val iteration 19, acc 89.600 (87.800)
* Prec: 87.80000152587891
--------
ResNet18
Using Adam for retraining
Files already downloaded and verified
2020-02-01 02:59:21, Epoch 0, Iteration 7, loss 1.507 (0.861), acc 88.462 (85.200)
2020-02-01 02:59:21, Epoch 30, Iteration 7, loss 0.002 (0.034), acc 100.000 (99.200)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-27.47603, -1.6945841, -15.06041, 2.289655, -46.321865, -4.925305, 10.789693, -25.711868, 9.016247, -32.558365], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-02-01 02:59:21 Epoch 59, Val iteration 0, acc 92.400 (92.400)
2020-02-01 02:59:23 Epoch 59, Val iteration 19, acc 93.600 (92.610)
* Prec: 92.61000175476075
--------
DenseNet121
Using Adam for retraining
Files already downloaded and verified
2020-02-01 02:59:26, Epoch 0, Iteration 7, loss 0.345 (0.365), acc 98.077 (93.800)
2020-02-01 02:59:27, Epoch 30, Iteration 7, loss 0.004 (0.007), acc 100.000 (99.800)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-11.641489, -20.973389, -14.006411, -5.9281793, -9.109786, -8.812096, 6.4159565, -30.520624, 4.082419, -14.360567], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-02-01 02:59:28 Epoch 59, Val iteration 0, acc 94.200 (94.200)
2020-02-01 02:59:33 Epoch 59, Val iteration 19, acc 92.400 (93.010)
* Prec: 93.01000175476074
--------
------SUMMARY------
TIME ELAPSED (mins): 140
TARGET INDEX: 2
DPN92 0
SENet18 0
ResNet50 0
ResNeXt29_2x64d 1
GoogLeNet 0
MobileNetV2 0
ResNet18 0
DenseNet121 0
