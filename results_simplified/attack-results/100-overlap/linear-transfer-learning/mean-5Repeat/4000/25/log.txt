Namespace(chk_path='chk-black-ourmean/', chk_subdir='poisons', device='cuda', dset_path='datasets', end2end=False, eval_poison_path='', gpu='1', lr_decay_epoch=[30, 45], mode='mean', model_resume_path='model-chks', nearest=False, net_repeat=5, num_per_class=50, original_grad=True, poison_decay_ites=[], poison_decay_ratio=0.1, poison_epsilon=0.1, poison_ites=4000, poison_label=8, poison_lr=0.04, poison_momentum=0.9, poison_num=5, poison_opt='adam', resume_poison_ite=0, retrain_bsize=64, retrain_epochs=60, retrain_lr=0.1, retrain_momentum=0.9, retrain_opt='adam', retrain_wd=0, subs_chk_name=['ckpt-%s-4800-dp0.200-droplayer0.000-seed1226.t7', 'ckpt-%s-4800-dp0.250-droplayer0.000-seed1226.t7', 'ckpt-%s-4800-dp0.300-droplayer0.000.t7'], subs_dp=[0.2, 0.25, 0.3], subset_group=0, substitute_nets=['DPN92', 'SENet18', 'ResNet50', 'ResNeXt29_2x64d', 'GoogLeNet', 'MobileNetV2'], target_index=25, target_label=6, target_net=['DPN92', 'SENet18', 'ResNet50', 'ResNeXt29_2x64d', 'GoogLeNet', 'MobileNetV2', 'ResNet18', 'DenseNet121'], test_chk_name='ckpt-%s-4800.t7', tol=1e-06, train_data_path='datasets/CIFAR10_TRAIN_Split.pth')
Path: chk-black-ourmean/mean-5Repeat/4000/25
Selected base image indices: [213, 225, 227, 247, 249]
 2020-02-01 14:45:40 Iteration 0 	 Training Loss: 1.054e+00 	 Loss in Target Net: 3.492e-01	  
 2020-02-01 14:47:36 Iteration 50 	 Training Loss: 8.225e-02 	 Loss in Target Net: 3.779e-03	  
 2020-02-01 14:49:31 Iteration 100 	 Training Loss: 6.489e-02 	 Loss in Target Net: 4.933e-03	  
 2020-02-01 14:51:14 Iteration 150 	 Training Loss: 6.128e-02 	 Loss in Target Net: 4.114e-03	  
 2020-02-01 14:52:57 Iteration 200 	 Training Loss: 5.816e-02 	 Loss in Target Net: 7.404e-03	  
 2020-02-01 14:54:42 Iteration 250 	 Training Loss: 5.492e-02 	 Loss in Target Net: 6.423e-03	  
 2020-02-01 14:56:26 Iteration 300 	 Training Loss: 5.517e-02 	 Loss in Target Net: 5.795e-03	  
 2020-02-01 14:58:10 Iteration 350 	 Training Loss: 5.272e-02 	 Loss in Target Net: 6.417e-03	  
 2020-02-01 14:59:54 Iteration 400 	 Training Loss: 5.605e-02 	 Loss in Target Net: 6.211e-03	  
 2020-02-01 15:01:39 Iteration 450 	 Training Loss: 5.085e-02 	 Loss in Target Net: 7.121e-03	  
 2020-02-01 15:03:24 Iteration 500 	 Training Loss: 5.432e-02 	 Loss in Target Net: 6.784e-03	  
 2020-02-01 15:05:08 Iteration 550 	 Training Loss: 5.203e-02 	 Loss in Target Net: 7.362e-03	  
 2020-02-01 15:06:53 Iteration 600 	 Training Loss: 5.572e-02 	 Loss in Target Net: 7.870e-03	  
 2020-02-01 15:08:39 Iteration 650 	 Training Loss: 5.253e-02 	 Loss in Target Net: 7.141e-03	  
 2020-02-01 15:10:24 Iteration 700 	 Training Loss: 5.148e-02 	 Loss in Target Net: 6.277e-03	  
 2020-02-01 15:12:09 Iteration 750 	 Training Loss: 5.136e-02 	 Loss in Target Net: 6.259e-03	  
 2020-02-01 15:13:54 Iteration 800 	 Training Loss: 5.142e-02 	 Loss in Target Net: 8.172e-03	  
 2020-02-01 15:15:39 Iteration 850 	 Training Loss: 4.962e-02 	 Loss in Target Net: 6.448e-03	  
 2020-02-01 15:17:23 Iteration 900 	 Training Loss: 5.325e-02 	 Loss in Target Net: 6.895e-03	  
 2020-02-01 15:19:09 Iteration 950 	 Training Loss: 4.997e-02 	 Loss in Target Net: 8.708e-03	  
 2020-02-01 15:20:54 Iteration 1000 	 Training Loss: 5.374e-02 	 Loss in Target Net: 8.227e-03	  
 2020-02-01 15:22:41 Iteration 1050 	 Training Loss: 5.056e-02 	 Loss in Target Net: 8.434e-03	  
 2020-02-01 15:24:31 Iteration 1100 	 Training Loss: 4.700e-02 	 Loss in Target Net: 8.755e-03	  
 2020-02-01 15:26:22 Iteration 1150 	 Training Loss: 5.003e-02 	 Loss in Target Net: 8.099e-03	  
 2020-02-01 15:28:07 Iteration 1200 	 Training Loss: 4.944e-02 	 Loss in Target Net: 8.239e-03	  
 2020-02-01 15:29:50 Iteration 1250 	 Training Loss: 4.827e-02 	 Loss in Target Net: 9.938e-03	  
 2020-02-01 15:31:33 Iteration 1300 	 Training Loss: 5.236e-02 	 Loss in Target Net: 6.856e-03	  
 2020-02-01 15:33:16 Iteration 1350 	 Training Loss: 5.053e-02 	 Loss in Target Net: 8.097e-03	  
 2020-02-01 15:34:59 Iteration 1400 	 Training Loss: 4.876e-02 	 Loss in Target Net: 7.003e-03	  
 2020-02-01 15:36:43 Iteration 1450 	 Training Loss: 5.238e-02 	 Loss in Target Net: 7.571e-03	  
 2020-02-01 15:38:27 Iteration 1500 	 Training Loss: 5.053e-02 	 Loss in Target Net: 7.662e-03	  
 2020-02-01 15:40:10 Iteration 1550 	 Training Loss: 4.866e-02 	 Loss in Target Net: 8.459e-03	  
 2020-02-01 15:41:54 Iteration 1600 	 Training Loss: 5.006e-02 	 Loss in Target Net: 6.378e-03	  
 2020-02-01 15:43:37 Iteration 1650 	 Training Loss: 4.898e-02 	 Loss in Target Net: 7.772e-03	  
 2020-02-01 15:45:21 Iteration 1700 	 Training Loss: 5.193e-02 	 Loss in Target Net: 4.612e-03	  
 2020-02-01 15:47:04 Iteration 1750 	 Training Loss: 5.104e-02 	 Loss in Target Net: 7.406e-03	  
 2020-02-01 15:48:47 Iteration 1800 	 Training Loss: 5.413e-02 	 Loss in Target Net: 8.010e-03	  
 2020-02-01 15:50:31 Iteration 1850 	 Training Loss: 4.933e-02 	 Loss in Target Net: 4.393e-03	  
 2020-02-01 15:52:14 Iteration 1900 	 Training Loss: 5.018e-02 	 Loss in Target Net: 7.058e-03	  
 2020-02-01 15:53:57 Iteration 1950 	 Training Loss: 5.034e-02 	 Loss in Target Net: 6.285e-03	  
 2020-02-01 15:55:40 Iteration 2000 	 Training Loss: 4.888e-02 	 Loss in Target Net: 6.021e-03	  
 2020-02-01 15:57:24 Iteration 2050 	 Training Loss: 4.910e-02 	 Loss in Target Net: 5.355e-03	  
 2020-02-01 15:59:08 Iteration 2100 	 Training Loss: 5.029e-02 	 Loss in Target Net: 5.938e-03	  
 2020-02-01 16:00:51 Iteration 2150 	 Training Loss: 5.472e-02 	 Loss in Target Net: 7.110e-03	  
 2020-02-01 16:02:35 Iteration 2200 	 Training Loss: 4.868e-02 	 Loss in Target Net: 8.275e-03	  
 2020-02-01 16:04:18 Iteration 2250 	 Training Loss: 5.042e-02 	 Loss in Target Net: 9.563e-03	  
 2020-02-01 16:06:01 Iteration 2300 	 Training Loss: 5.008e-02 	 Loss in Target Net: 7.061e-03	  
 2020-02-01 16:07:44 Iteration 2350 	 Training Loss: 5.141e-02 	 Loss in Target Net: 7.396e-03	  
 2020-02-01 16:09:27 Iteration 2400 	 Training Loss: 5.165e-02 	 Loss in Target Net: 7.882e-03	  
 2020-02-01 16:11:10 Iteration 2450 	 Training Loss: 5.015e-02 	 Loss in Target Net: 8.325e-03	  
 2020-02-01 16:12:54 Iteration 2500 	 Training Loss: 4.890e-02 	 Loss in Target Net: 8.765e-03	  
 2020-02-01 16:14:37 Iteration 2550 	 Training Loss: 4.933e-02 	 Loss in Target Net: 8.000e-03	  
 2020-02-01 16:16:20 Iteration 2600 	 Training Loss: 5.033e-02 	 Loss in Target Net: 6.899e-03	  
 2020-02-01 16:18:04 Iteration 2650 	 Training Loss: 5.059e-02 	 Loss in Target Net: 6.007e-03	  
 2020-02-01 16:19:47 Iteration 2700 	 Training Loss: 5.075e-02 	 Loss in Target Net: 6.453e-03	  
 2020-02-01 16:21:30 Iteration 2750 	 Training Loss: 4.914e-02 	 Loss in Target Net: 6.285e-03	  
 2020-02-01 16:23:13 Iteration 2800 	 Training Loss: 4.666e-02 	 Loss in Target Net: 7.321e-03	  
 2020-02-01 16:24:55 Iteration 2850 	 Training Loss: 4.965e-02 	 Loss in Target Net: 6.098e-03	  
 2020-02-01 16:26:39 Iteration 2900 	 Training Loss: 4.979e-02 	 Loss in Target Net: 8.026e-03	  
 2020-02-01 16:28:22 Iteration 2950 	 Training Loss: 4.956e-02 	 Loss in Target Net: 8.271e-03	  
 2020-02-01 16:30:06 Iteration 3000 	 Training Loss: 4.690e-02 	 Loss in Target Net: 7.258e-03	  
 2020-02-01 16:31:49 Iteration 3050 	 Training Loss: 4.942e-02 	 Loss in Target Net: 6.457e-03	  
 2020-02-01 16:33:32 Iteration 3100 	 Training Loss: 4.789e-02 	 Loss in Target Net: 8.052e-03	  
 2020-02-01 16:35:16 Iteration 3150 	 Training Loss: 4.780e-02 	 Loss in Target Net: 8.546e-03	  
 2020-02-01 16:36:59 Iteration 3200 	 Training Loss: 4.657e-02 	 Loss in Target Net: 7.964e-03	  
 2020-02-01 16:38:43 Iteration 3250 	 Training Loss: 4.857e-02 	 Loss in Target Net: 9.497e-03	  
 2020-02-01 16:40:26 Iteration 3300 	 Training Loss: 4.899e-02 	 Loss in Target Net: 8.243e-03	  
 2020-02-01 16:42:09 Iteration 3350 	 Training Loss: 4.872e-02 	 Loss in Target Net: 9.313e-03	  
 2020-02-01 16:43:52 Iteration 3400 	 Training Loss: 4.913e-02 	 Loss in Target Net: 7.838e-03	  
 2020-02-01 16:45:36 Iteration 3450 	 Training Loss: 4.599e-02 	 Loss in Target Net: 9.690e-03	  
 2020-02-01 16:47:20 Iteration 3500 	 Training Loss: 4.768e-02 	 Loss in Target Net: 7.992e-03	  
 2020-02-01 16:49:03 Iteration 3550 	 Training Loss: 4.852e-02 	 Loss in Target Net: 6.002e-03	  
 2020-02-01 16:50:47 Iteration 3600 	 Training Loss: 4.701e-02 	 Loss in Target Net: 7.591e-03	  
 2020-02-01 16:52:31 Iteration 3650 	 Training Loss: 4.674e-02 	 Loss in Target Net: 4.629e-03	  
 2020-02-01 16:54:14 Iteration 3700 	 Training Loss: 4.820e-02 	 Loss in Target Net: 7.299e-03	  
 2020-02-01 16:55:58 Iteration 3750 	 Training Loss: 4.864e-02 	 Loss in Target Net: 8.136e-03	  
 2020-02-01 16:57:42 Iteration 3800 	 Training Loss: 4.635e-02 	 Loss in Target Net: 6.689e-03	  
 2020-02-01 16:59:25 Iteration 3850 	 Training Loss: 4.539e-02 	 Loss in Target Net: 6.019e-03	  
 2020-02-01 17:01:10 Iteration 3900 	 Training Loss: 4.737e-02 	 Loss in Target Net: 6.376e-03	  
 2020-02-01 17:02:53 Iteration 3950 	 Training Loss: 4.970e-02 	 Loss in Target Net: 6.524e-03	  
 2020-02-01 17:04:35 Iteration 3999 	 Training Loss: 5.056e-02 	 Loss in Target Net: 6.315e-03	  
Evaluating against victims networks
DPN92
Using Adam for retraining
Files already downloaded and verified
2020-02-01 17:04:40, Epoch 0, Iteration 7, loss 2.738 (4.485), acc 86.538 (69.800)
2020-02-01 17:04:40, Epoch 30, Iteration 7, loss 0.499 (0.177), acc 98.077 (98.200)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[11.632778, 3.9718156, -26.619091, 11.745783, -20.095943, -1.4676245, 37.765114, -37.687344, 36.561634, -80.68576], Poisons' Predictions:[6, 8, 8, 8, 8]
2020-02-01 17:04:45 Epoch 59, Val iteration 0, acc 92.600 (92.600)
2020-02-01 17:04:52 Epoch 59, Val iteration 19, acc 92.800 (92.850)
* Prec: 92.85000190734863
--------
SENet18
Using Adam for retraining
Files already downloaded and verified
2020-02-01 17:04:54, Epoch 0, Iteration 7, loss 0.837 (1.011), acc 92.308 (85.800)
2020-02-01 17:04:55, Epoch 30, Iteration 7, loss 0.049 (0.218), acc 98.077 (95.800)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-3.0433106, -4.1325936, -1.1396933, 1.1290454, 8.40332, -3.302344, 18.2332, -25.162956, 14.835926, -8.255344], Poisons' Predictions:[6, 6, 8, 6, 6]
2020-02-01 17:04:56 Epoch 59, Val iteration 0, acc 91.800 (91.800)
2020-02-01 17:04:58 Epoch 59, Val iteration 19, acc 92.800 (91.630)
* Prec: 91.63000183105468
--------
ResNet50
Using Adam for retraining
Files already downloaded and verified
2020-02-01 17:05:00, Epoch 0, Iteration 7, loss 0.000 (0.822), acc 100.000 (90.600)
2020-02-01 17:05:00, Epoch 30, Iteration 7, loss 0.000 (0.000), acc 100.000 (100.000)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-44.00555, -44.395504, -34.791363, -18.192, -86.252846, -38.076233, 11.149114, -59.40622, 23.572767, -12.085185], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-02-01 17:05:02 Epoch 59, Val iteration 0, acc 92.800 (92.800)
2020-02-01 17:05:06 Epoch 59, Val iteration 19, acc 94.600 (93.710)
* Prec: 93.71000137329102
--------
ResNeXt29_2x64d
Using Adam for retraining
Files already downloaded and verified
2020-02-01 17:05:08, Epoch 0, Iteration 7, loss 0.823 (2.064), acc 88.462 (73.200)
2020-02-01 17:05:08, Epoch 30, Iteration 7, loss 0.159 (0.083), acc 96.154 (98.200)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-33.10387, 22.542044, -4.7952747, 14.907607, -55.53431, -15.789218, 38.264572, -22.797924, 41.08332, -18.143782], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-02-01 17:05:09 Epoch 59, Val iteration 0, acc 93.400 (93.400)
2020-02-01 17:05:14 Epoch 59, Val iteration 19, acc 92.400 (93.360)
* Prec: 93.36000137329101
--------
GoogLeNet
Using Adam for retraining
Files already downloaded and verified
2020-02-01 17:05:16, Epoch 0, Iteration 7, loss 0.219 (0.464), acc 94.231 (90.000)
2020-02-01 17:05:16, Epoch 30, Iteration 7, loss 0.117 (0.058), acc 96.154 (98.400)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-25.308538, -11.417087, -20.296078, -5.068477, -18.489637, -10.505966, 9.782778, -7.1320996, 9.877899, -29.196478], Poisons' Predictions:[8, 8, 6, 8, 6]
2020-02-01 17:05:19 Epoch 59, Val iteration 0, acc 91.400 (91.400)
2020-02-01 17:05:24 Epoch 59, Val iteration 19, acc 90.600 (91.880)
* Prec: 91.88000221252442
--------
MobileNetV2
Using Adam for retraining
Files already downloaded and verified
2020-02-01 17:05:26, Epoch 0, Iteration 7, loss 0.566 (3.427), acc 84.615 (64.600)
2020-02-01 17:05:26, Epoch 30, Iteration 7, loss 0.122 (0.228), acc 96.154 (95.400)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-11.146465, -3.6083412, -16.534174, -1.2762161, -35.506447, -17.642609, 13.618903, -39.18124, 9.913711, -25.208733], Poisons' Predictions:[8, 8, 8, 8, 6]
2020-02-01 17:05:27 Epoch 59, Val iteration 0, acc 88.200 (88.200)
2020-02-01 17:05:29 Epoch 59, Val iteration 19, acc 87.200 (86.670)
* Prec: 86.67000160217285
--------
ResNet18
Using Adam for retraining
Files already downloaded and verified
2020-02-01 17:05:31, Epoch 0, Iteration 7, loss 0.320 (0.771), acc 98.077 (84.400)
2020-02-01 17:05:31, Epoch 30, Iteration 7, loss 0.031 (0.042), acc 98.077 (98.400)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-32.126606, -3.535219, -14.968349, 2.1122844, -41.364338, -3.511114, 11.51464, -20.827463, 11.886583, -40.038643], Poisons' Predictions:[6, 8, 8, 6, 8]
2020-02-01 17:05:32 Epoch 59, Val iteration 0, acc 93.600 (93.600)
2020-02-01 17:05:34 Epoch 59, Val iteration 19, acc 94.200 (92.740)
* Prec: 92.74000129699706
--------
DenseNet121
Using Adam for retraining
Files already downloaded and verified
2020-02-01 17:05:36, Epoch 0, Iteration 7, loss 0.395 (0.383), acc 92.308 (91.800)
2020-02-01 17:05:37, Epoch 30, Iteration 7, loss 0.002 (0.004), acc 100.000 (100.000)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-12.261747, -20.770147, -20.320278, -8.384575, -7.1169286, -5.3040395, 6.2926664, -38.071, 5.489451, -20.28058], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-02-01 17:05:39 Epoch 59, Val iteration 0, acc 93.000 (93.000)
2020-02-01 17:05:43 Epoch 59, Val iteration 19, acc 92.800 (92.890)
* Prec: 92.89000129699707
--------
------SUMMARY------
TIME ELAPSED (mins): 139
TARGET INDEX: 25
DPN92 0
SENet18 0
ResNet50 1
ResNeXt29_2x64d 1
GoogLeNet 1
MobileNetV2 0
ResNet18 1
DenseNet121 0
