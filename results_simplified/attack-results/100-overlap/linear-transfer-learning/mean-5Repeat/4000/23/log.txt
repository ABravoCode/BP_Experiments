Namespace(chk_path='chk-black-ourmean/', chk_subdir='poisons', device='cuda', dset_path='datasets', end2end=False, eval_poison_path='', gpu='3', lr_decay_epoch=[30, 45], mode='mean', model_resume_path='model-chks', nearest=False, net_repeat=5, num_per_class=50, original_grad=True, poison_decay_ites=[], poison_decay_ratio=0.1, poison_epsilon=0.1, poison_ites=4000, poison_label=8, poison_lr=0.04, poison_momentum=0.9, poison_num=5, poison_opt='adam', resume_poison_ite=0, retrain_bsize=64, retrain_epochs=60, retrain_lr=0.1, retrain_momentum=0.9, retrain_opt='adam', retrain_wd=0, subs_chk_name=['ckpt-%s-4800-dp0.200-droplayer0.000-seed1226.t7', 'ckpt-%s-4800-dp0.250-droplayer0.000-seed1226.t7', 'ckpt-%s-4800-dp0.300-droplayer0.000.t7'], subs_dp=[0.2, 0.25, 0.3], subset_group=0, substitute_nets=['DPN92', 'SENet18', 'ResNet50', 'ResNeXt29_2x64d', 'GoogLeNet', 'MobileNetV2'], target_index=23, target_label=6, target_net=['DPN92', 'SENet18', 'ResNet50', 'ResNeXt29_2x64d', 'GoogLeNet', 'MobileNetV2', 'ResNet18', 'DenseNet121'], test_chk_name='ckpt-%s-4800.t7', tol=1e-06, train_data_path='datasets/CIFAR10_TRAIN_Split.pth')
Path: chk-black-ourmean/mean-5Repeat/4000/23
Selected base image indices: [213, 225, 227, 247, 249]
 2020-02-01 12:56:03 Iteration 0 	 Training Loss: 1.070e+00 	 Loss in Target Net: 3.229e-01	  
 2020-02-01 12:57:52 Iteration 50 	 Training Loss: 6.360e-02 	 Loss in Target Net: 6.917e-03	  
 2020-02-01 12:59:41 Iteration 100 	 Training Loss: 5.238e-02 	 Loss in Target Net: 6.748e-03	  
 2020-02-01 13:01:30 Iteration 150 	 Training Loss: 5.003e-02 	 Loss in Target Net: 5.820e-03	  
 2020-02-01 13:03:18 Iteration 200 	 Training Loss: 4.834e-02 	 Loss in Target Net: 4.474e-03	  
 2020-02-01 13:05:07 Iteration 250 	 Training Loss: 4.504e-02 	 Loss in Target Net: 4.813e-03	  
 2020-02-01 13:06:55 Iteration 300 	 Training Loss: 4.317e-02 	 Loss in Target Net: 5.486e-03	  
 2020-02-01 13:08:43 Iteration 350 	 Training Loss: 4.402e-02 	 Loss in Target Net: 4.065e-03	  
 2020-02-01 13:10:31 Iteration 400 	 Training Loss: 4.316e-02 	 Loss in Target Net: 6.142e-03	  
 2020-02-01 13:12:19 Iteration 450 	 Training Loss: 4.545e-02 	 Loss in Target Net: 4.731e-03	  
 2020-02-01 13:14:07 Iteration 500 	 Training Loss: 4.271e-02 	 Loss in Target Net: 4.764e-03	  
 2020-02-01 13:15:55 Iteration 550 	 Training Loss: 4.244e-02 	 Loss in Target Net: 4.699e-03	  
 2020-02-01 13:17:44 Iteration 600 	 Training Loss: 4.018e-02 	 Loss in Target Net: 7.728e-03	  
 2020-02-01 13:19:32 Iteration 650 	 Training Loss: 4.489e-02 	 Loss in Target Net: 6.511e-03	  
 2020-02-01 13:21:21 Iteration 700 	 Training Loss: 4.178e-02 	 Loss in Target Net: 5.899e-03	  
 2020-02-01 13:23:09 Iteration 750 	 Training Loss: 4.042e-02 	 Loss in Target Net: 6.770e-03	  
 2020-02-01 13:24:58 Iteration 800 	 Training Loss: 4.266e-02 	 Loss in Target Net: 5.231e-03	  
 2020-02-01 13:26:47 Iteration 850 	 Training Loss: 4.040e-02 	 Loss in Target Net: 5.311e-03	  
 2020-02-01 13:28:35 Iteration 900 	 Training Loss: 4.244e-02 	 Loss in Target Net: 5.639e-03	  
 2020-02-01 13:30:24 Iteration 950 	 Training Loss: 4.128e-02 	 Loss in Target Net: 5.337e-03	  
 2020-02-01 13:32:12 Iteration 1000 	 Training Loss: 4.088e-02 	 Loss in Target Net: 6.717e-03	  
 2020-02-01 13:34:00 Iteration 1050 	 Training Loss: 4.203e-02 	 Loss in Target Net: 7.012e-03	  
 2020-02-01 13:35:49 Iteration 1100 	 Training Loss: 4.098e-02 	 Loss in Target Net: 5.237e-03	  
 2020-02-01 13:37:37 Iteration 1150 	 Training Loss: 4.145e-02 	 Loss in Target Net: 4.621e-03	  
 2020-02-01 13:39:26 Iteration 1200 	 Training Loss: 4.219e-02 	 Loss in Target Net: 4.818e-03	  
 2020-02-01 13:41:14 Iteration 1250 	 Training Loss: 4.032e-02 	 Loss in Target Net: 4.234e-03	  
 2020-02-01 13:43:03 Iteration 1300 	 Training Loss: 3.973e-02 	 Loss in Target Net: 4.412e-03	  
 2020-02-01 13:44:52 Iteration 1350 	 Training Loss: 3.914e-02 	 Loss in Target Net: 3.625e-03	  
 2020-02-01 13:46:40 Iteration 1400 	 Training Loss: 4.138e-02 	 Loss in Target Net: 4.639e-03	  
 2020-02-01 13:48:29 Iteration 1450 	 Training Loss: 3.946e-02 	 Loss in Target Net: 5.295e-03	  
 2020-02-01 13:50:17 Iteration 1500 	 Training Loss: 4.306e-02 	 Loss in Target Net: 5.471e-03	  
 2020-02-01 13:52:05 Iteration 1550 	 Training Loss: 4.162e-02 	 Loss in Target Net: 3.785e-03	  
 2020-02-01 13:53:54 Iteration 1600 	 Training Loss: 4.117e-02 	 Loss in Target Net: 4.515e-03	  
 2020-02-01 13:55:43 Iteration 1650 	 Training Loss: 4.312e-02 	 Loss in Target Net: 4.345e-03	  
 2020-02-01 13:57:30 Iteration 1700 	 Training Loss: 4.161e-02 	 Loss in Target Net: 4.828e-03	  
 2020-02-01 13:59:19 Iteration 1750 	 Training Loss: 4.208e-02 	 Loss in Target Net: 3.893e-03	  
 2020-02-01 14:01:07 Iteration 1800 	 Training Loss: 4.116e-02 	 Loss in Target Net: 3.776e-03	  
 2020-02-01 14:02:55 Iteration 1850 	 Training Loss: 4.143e-02 	 Loss in Target Net: 5.395e-03	  
 2020-02-01 14:04:43 Iteration 1900 	 Training Loss: 4.028e-02 	 Loss in Target Net: 5.138e-03	  
 2020-02-01 14:06:31 Iteration 1950 	 Training Loss: 3.870e-02 	 Loss in Target Net: 4.442e-03	  
 2020-02-01 14:08:20 Iteration 2000 	 Training Loss: 3.917e-02 	 Loss in Target Net: 4.162e-03	  
 2020-02-01 14:10:08 Iteration 2050 	 Training Loss: 4.076e-02 	 Loss in Target Net: 5.144e-03	  
 2020-02-01 14:11:56 Iteration 2100 	 Training Loss: 3.964e-02 	 Loss in Target Net: 5.811e-03	  
 2020-02-01 14:13:44 Iteration 2150 	 Training Loss: 3.970e-02 	 Loss in Target Net: 5.337e-03	  
 2020-02-01 14:15:32 Iteration 2200 	 Training Loss: 3.847e-02 	 Loss in Target Net: 6.821e-03	  
 2020-02-01 14:17:20 Iteration 2250 	 Training Loss: 4.253e-02 	 Loss in Target Net: 6.450e-03	  
 2020-02-01 14:19:08 Iteration 2300 	 Training Loss: 4.376e-02 	 Loss in Target Net: 4.544e-03	  
 2020-02-01 14:20:56 Iteration 2350 	 Training Loss: 3.926e-02 	 Loss in Target Net: 5.769e-03	  
 2020-02-01 14:22:44 Iteration 2400 	 Training Loss: 3.976e-02 	 Loss in Target Net: 4.406e-03	  
 2020-02-01 14:24:32 Iteration 2450 	 Training Loss: 4.145e-02 	 Loss in Target Net: 3.924e-03	  
 2020-02-01 14:26:20 Iteration 2500 	 Training Loss: 3.906e-02 	 Loss in Target Net: 5.319e-03	  
 2020-02-01 14:28:09 Iteration 2550 	 Training Loss: 4.093e-02 	 Loss in Target Net: 4.366e-03	  
 2020-02-01 14:29:57 Iteration 2600 	 Training Loss: 4.011e-02 	 Loss in Target Net: 6.795e-03	  
 2020-02-01 14:31:45 Iteration 2650 	 Training Loss: 4.149e-02 	 Loss in Target Net: 4.654e-03	  
 2020-02-01 14:33:34 Iteration 2700 	 Training Loss: 3.961e-02 	 Loss in Target Net: 5.115e-03	  
 2020-02-01 14:35:22 Iteration 2750 	 Training Loss: 4.047e-02 	 Loss in Target Net: 5.350e-03	  
 2020-02-01 14:37:10 Iteration 2800 	 Training Loss: 4.136e-02 	 Loss in Target Net: 6.072e-03	  
 2020-02-01 14:38:59 Iteration 2850 	 Training Loss: 4.236e-02 	 Loss in Target Net: 3.968e-03	  
 2020-02-01 14:40:47 Iteration 2900 	 Training Loss: 4.199e-02 	 Loss in Target Net: 4.200e-03	  
 2020-02-01 14:42:36 Iteration 2950 	 Training Loss: 3.858e-02 	 Loss in Target Net: 3.759e-03	  
 2020-02-01 14:44:24 Iteration 3000 	 Training Loss: 4.116e-02 	 Loss in Target Net: 4.678e-03	  
 2020-02-01 14:46:13 Iteration 3050 	 Training Loss: 4.055e-02 	 Loss in Target Net: 4.779e-03	  
 2020-02-01 14:48:01 Iteration 3100 	 Training Loss: 4.026e-02 	 Loss in Target Net: 4.952e-03	  
 2020-02-01 14:49:50 Iteration 3150 	 Training Loss: 4.100e-02 	 Loss in Target Net: 5.255e-03	  
 2020-02-01 14:51:39 Iteration 3200 	 Training Loss: 3.910e-02 	 Loss in Target Net: 5.375e-03	  
 2020-02-01 14:53:27 Iteration 3250 	 Training Loss: 3.778e-02 	 Loss in Target Net: 4.301e-03	  
 2020-02-01 14:55:16 Iteration 3300 	 Training Loss: 3.993e-02 	 Loss in Target Net: 4.739e-03	  
 2020-02-01 14:57:06 Iteration 3350 	 Training Loss: 3.901e-02 	 Loss in Target Net: 5.182e-03	  
 2020-02-01 14:58:54 Iteration 3400 	 Training Loss: 3.876e-02 	 Loss in Target Net: 3.953e-03	  
 2020-02-01 15:00:43 Iteration 3450 	 Training Loss: 3.977e-02 	 Loss in Target Net: 5.337e-03	  
 2020-02-01 15:02:31 Iteration 3500 	 Training Loss: 3.881e-02 	 Loss in Target Net: 5.463e-03	  
 2020-02-01 15:04:19 Iteration 3550 	 Training Loss: 3.787e-02 	 Loss in Target Net: 6.569e-03	  
 2020-02-01 15:06:07 Iteration 3600 	 Training Loss: 4.090e-02 	 Loss in Target Net: 5.550e-03	  
 2020-02-01 15:07:55 Iteration 3650 	 Training Loss: 3.923e-02 	 Loss in Target Net: 6.225e-03	  
 2020-02-01 15:09:43 Iteration 3700 	 Training Loss: 4.161e-02 	 Loss in Target Net: 4.848e-03	  
 2020-02-01 15:11:31 Iteration 3750 	 Training Loss: 3.945e-02 	 Loss in Target Net: 5.329e-03	  
 2020-02-01 15:13:20 Iteration 3800 	 Training Loss: 4.176e-02 	 Loss in Target Net: 5.529e-03	  
 2020-02-01 15:15:08 Iteration 3850 	 Training Loss: 4.311e-02 	 Loss in Target Net: 3.863e-03	  
 2020-02-01 15:16:56 Iteration 3900 	 Training Loss: 4.074e-02 	 Loss in Target Net: 4.157e-03	  
 2020-02-01 15:18:44 Iteration 3950 	 Training Loss: 3.929e-02 	 Loss in Target Net: 3.730e-03	  
 2020-02-01 15:20:30 Iteration 3999 	 Training Loss: 4.179e-02 	 Loss in Target Net: 4.545e-03	  
Evaluating against victims networks
DPN92
Using Adam for retraining
Files already downloaded and verified
2020-02-01 15:20:34, Epoch 0, Iteration 7, loss 0.506 (4.238), acc 92.308 (71.600)
2020-02-01 15:20:35, Epoch 30, Iteration 7, loss 0.035 (0.217), acc 98.077 (96.400)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-14.243518, -30.683834, -76.1683, -22.927492, -58.364212, -18.228779, 19.783108, -66.56385, 18.882944, -121.12761], Poisons' Predictions:[8, 8, 8, 6, 8]
2020-02-01 15:20:40 Epoch 59, Val iteration 0, acc 91.600 (91.600)
2020-02-01 15:20:47 Epoch 59, Val iteration 19, acc 93.000 (92.940)
* Prec: 92.94000091552735
--------
SENet18
Using Adam for retraining
Files already downloaded and verified
2020-02-01 15:20:49, Epoch 0, Iteration 7, loss 0.853 (0.753), acc 88.462 (89.000)
2020-02-01 15:20:50, Epoch 30, Iteration 7, loss 0.570 (0.366), acc 96.154 (95.600)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[3.106696, 1.0862391, -17.31196, -2.5735126, 11.527346, -9.155282, 26.209793, -21.069311, 18.615952, -12.652504], Poisons' Predictions:[8, 8, 6, 6, 6]
2020-02-01 15:20:51 Epoch 59, Val iteration 0, acc 91.800 (91.800)
2020-02-01 15:20:53 Epoch 59, Val iteration 19, acc 93.400 (90.940)
* Prec: 90.94000129699707
--------
ResNet50
Using Adam for retraining
Files already downloaded and verified
2020-02-01 15:20:55, Epoch 0, Iteration 7, loss 0.000 (1.037), acc 100.000 (89.400)
2020-02-01 15:20:55, Epoch 30, Iteration 7, loss 0.000 (0.020), acc 100.000 (99.600)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-62.172295, -64.57387, -52.630634, -67.52957, -57.831516, -45.464603, 19.67598, -70.052574, 22.774899, -89.52939], Poisons' Predictions:[8, 8, 8, 6, 8]
2020-02-01 15:20:57 Epoch 59, Val iteration 0, acc 91.600 (91.600)
2020-02-01 15:21:01 Epoch 59, Val iteration 19, acc 92.600 (91.690)
* Prec: 91.69000129699707
--------
ResNeXt29_2x64d
Using Adam for retraining
Files already downloaded and verified
2020-02-01 15:21:03, Epoch 0, Iteration 7, loss 0.594 (1.717), acc 88.462 (79.200)
2020-02-01 15:21:03, Epoch 30, Iteration 7, loss 0.002 (0.082), acc 100.000 (98.000)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-35.662235, 3.1914454, -9.098107, -2.7433274, -69.89657, -37.922176, 17.782917, -14.351102, 20.64728, -32.820927], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-02-01 15:21:05 Epoch 59, Val iteration 0, acc 92.200 (92.200)
2020-02-01 15:21:09 Epoch 59, Val iteration 19, acc 92.800 (93.020)
* Prec: 93.02000122070312
--------
GoogLeNet
Using Adam for retraining
Files already downloaded and verified
2020-02-01 15:21:12, Epoch 0, Iteration 7, loss 0.232 (0.441), acc 90.385 (90.400)
2020-02-01 15:21:12, Epoch 30, Iteration 7, loss 0.028 (0.081), acc 98.077 (96.400)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-32.813835, -4.9569364, -16.81499, -4.5655065, -16.141817, -10.80361, 11.786177, -5.8443823, 12.949565, -17.057596], Poisons' Predictions:[8, 8, 6, 8, 6]
2020-02-01 15:21:14 Epoch 59, Val iteration 0, acc 91.400 (91.400)
2020-02-01 15:21:19 Epoch 59, Val iteration 19, acc 91.600 (92.030)
* Prec: 92.03000068664551
--------
MobileNetV2
Using Adam for retraining
Files already downloaded and verified
2020-02-01 15:21:21, Epoch 0, Iteration 7, loss 2.667 (4.509), acc 73.077 (57.000)
2020-02-01 15:21:21, Epoch 30, Iteration 7, loss 0.023 (0.449), acc 100.000 (91.800)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-3.6177335, 14.692116, -4.4357095, 9.672832, -14.777816, -5.8222737, 27.4666, -24.428661, 20.455236, -10.891242], Poisons' Predictions:[6, 8, 8, 8, 8]
2020-02-01 15:21:22 Epoch 59, Val iteration 0, acc 88.200 (88.200)
2020-02-01 15:21:24 Epoch 59, Val iteration 19, acc 87.600 (87.190)
* Prec: 87.19000205993652
--------
ResNet18
Using Adam for retraining
Files already downloaded and verified
2020-02-01 15:21:26, Epoch 0, Iteration 7, loss 1.181 (0.874), acc 90.385 (85.000)
2020-02-01 15:21:26, Epoch 30, Iteration 7, loss 0.039 (0.020), acc 98.077 (99.200)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-34.37597, -6.824574, -19.922552, 5.9483685, -39.267937, -3.2208836, 14.495015, -17.234123, 14.181017, -49.03377], Poisons' Predictions:[8, 8, 6, 8, 8]
2020-02-01 15:21:27 Epoch 59, Val iteration 0, acc 92.200 (92.200)
2020-02-01 15:21:29 Epoch 59, Val iteration 19, acc 93.200 (92.460)
* Prec: 92.46000213623047
--------
DenseNet121
Using Adam for retraining
Files already downloaded and verified
2020-02-01 15:21:32, Epoch 0, Iteration 7, loss 0.623 (0.313), acc 86.538 (92.200)
2020-02-01 15:21:32, Epoch 30, Iteration 7, loss 0.004 (0.010), acc 100.000 (99.800)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-8.41105, -19.355505, -16.285393, -6.93014, -6.014153, -7.5560102, 6.7952743, -32.5507, 4.5230484, -10.395094], Poisons' Predictions:[8, 8, 8, 6, 8]
2020-02-01 15:21:34 Epoch 59, Val iteration 0, acc 93.200 (93.200)
2020-02-01 15:21:38 Epoch 59, Val iteration 19, acc 92.800 (92.850)
* Prec: 92.85000114440918
--------
------SUMMARY------
TIME ELAPSED (mins): 144
TARGET INDEX: 23
DPN92 0
SENet18 0
ResNet50 1
ResNeXt29_2x64d 1
GoogLeNet 1
MobileNetV2 0
ResNet18 0
DenseNet121 0
