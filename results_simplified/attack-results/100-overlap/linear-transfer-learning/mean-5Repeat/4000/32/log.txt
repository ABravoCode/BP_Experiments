Namespace(chk_path='chk-black-ourmean/', chk_subdir='poisons', device='cuda', dset_path='datasets', end2end=False, eval_poison_path='', gpu='0', lr_decay_epoch=[30, 45], mode='mean', model_resume_path='model-chks', nearest=False, net_repeat=5, num_per_class=50, original_grad=True, poison_decay_ites=[], poison_decay_ratio=0.1, poison_epsilon=0.1, poison_ites=4000, poison_label=8, poison_lr=0.04, poison_momentum=0.9, poison_num=5, poison_opt='adam', resume_poison_ite=0, retrain_bsize=64, retrain_epochs=60, retrain_lr=0.1, retrain_momentum=0.9, retrain_opt='adam', retrain_wd=0, subs_chk_name=['ckpt-%s-4800-dp0.200-droplayer0.000-seed1226.t7', 'ckpt-%s-4800-dp0.250-droplayer0.000-seed1226.t7', 'ckpt-%s-4800-dp0.300-droplayer0.000.t7'], subs_dp=[0.2, 0.25, 0.3], subset_group=0, substitute_nets=['DPN92', 'SENet18', 'ResNet50', 'ResNeXt29_2x64d', 'GoogLeNet', 'MobileNetV2'], target_index=32, target_label=6, target_net=['DPN92', 'SENet18', 'ResNet50', 'ResNeXt29_2x64d', 'GoogLeNet', 'MobileNetV2', 'ResNet18', 'DenseNet121'], test_chk_name='ckpt-%s-4800.t7', tol=1e-06, train_data_path='datasets/CIFAR10_TRAIN_Split.pth')
Path: chk-black-ourmean/mean-5Repeat/4000/32
Selected base image indices: [213, 225, 227, 247, 249]
 2020-02-01 19:42:03 Iteration 0 	 Training Loss: 1.098e+00 	 Loss in Target Net: 4.130e-01	  
 2020-02-01 19:43:52 Iteration 50 	 Training Loss: 8.600e-02 	 Loss in Target Net: 5.919e-03	  
 2020-02-01 19:45:39 Iteration 100 	 Training Loss: 7.158e-02 	 Loss in Target Net: 3.621e-03	  
 2020-02-01 19:47:27 Iteration 150 	 Training Loss: 6.060e-02 	 Loss in Target Net: 5.479e-03	  
 2020-02-01 19:49:14 Iteration 200 	 Training Loss: 6.395e-02 	 Loss in Target Net: 5.213e-03	  
 2020-02-01 19:51:02 Iteration 250 	 Training Loss: 6.367e-02 	 Loss in Target Net: 1.179e-02	  
 2020-02-01 19:52:49 Iteration 300 	 Training Loss: 5.854e-02 	 Loss in Target Net: 1.125e-02	  
 2020-02-01 19:54:37 Iteration 350 	 Training Loss: 5.734e-02 	 Loss in Target Net: 1.176e-02	  
 2020-02-01 19:56:24 Iteration 400 	 Training Loss: 5.803e-02 	 Loss in Target Net: 1.326e-02	  
 2020-02-01 19:58:11 Iteration 450 	 Training Loss: 5.695e-02 	 Loss in Target Net: 1.150e-02	  
 2020-02-01 19:59:58 Iteration 500 	 Training Loss: 5.643e-02 	 Loss in Target Net: 8.592e-03	  
 2020-02-01 20:01:46 Iteration 550 	 Training Loss: 5.660e-02 	 Loss in Target Net: 1.716e-02	  
 2020-02-01 20:03:33 Iteration 600 	 Training Loss: 5.328e-02 	 Loss in Target Net: 6.392e-03	  
 2020-02-01 20:05:20 Iteration 650 	 Training Loss: 5.407e-02 	 Loss in Target Net: 9.028e-03	  
 2020-02-01 20:07:07 Iteration 700 	 Training Loss: 5.510e-02 	 Loss in Target Net: 9.154e-03	  
 2020-02-01 20:08:55 Iteration 750 	 Training Loss: 5.205e-02 	 Loss in Target Net: 9.389e-03	  
 2020-02-01 20:10:43 Iteration 800 	 Training Loss: 5.262e-02 	 Loss in Target Net: 5.639e-03	  
 2020-02-01 20:12:30 Iteration 850 	 Training Loss: 4.649e-02 	 Loss in Target Net: 5.405e-03	  
 2020-02-01 20:14:18 Iteration 900 	 Training Loss: 5.183e-02 	 Loss in Target Net: 8.954e-03	  
 2020-02-01 20:16:06 Iteration 950 	 Training Loss: 5.377e-02 	 Loss in Target Net: 7.511e-03	  
 2020-02-01 20:17:54 Iteration 1000 	 Training Loss: 5.276e-02 	 Loss in Target Net: 1.235e-02	  
 2020-02-01 20:19:41 Iteration 1050 	 Training Loss: 5.249e-02 	 Loss in Target Net: 5.426e-03	  
 2020-02-01 20:21:29 Iteration 1100 	 Training Loss: 5.094e-02 	 Loss in Target Net: 7.073e-03	  
 2020-02-01 20:23:17 Iteration 1150 	 Training Loss: 4.978e-02 	 Loss in Target Net: 6.982e-03	  
 2020-02-01 20:25:05 Iteration 1200 	 Training Loss: 5.229e-02 	 Loss in Target Net: 6.060e-03	  
 2020-02-01 20:26:54 Iteration 1250 	 Training Loss: 5.028e-02 	 Loss in Target Net: 6.386e-03	  
 2020-02-01 20:28:42 Iteration 1300 	 Training Loss: 4.934e-02 	 Loss in Target Net: 7.227e-03	  
 2020-02-01 20:30:31 Iteration 1350 	 Training Loss: 5.655e-02 	 Loss in Target Net: 9.503e-03	  
 2020-02-01 20:32:19 Iteration 1400 	 Training Loss: 5.028e-02 	 Loss in Target Net: 8.449e-03	  
 2020-02-01 20:34:08 Iteration 1450 	 Training Loss: 5.308e-02 	 Loss in Target Net: 6.656e-03	  
 2020-02-01 20:35:57 Iteration 1500 	 Training Loss: 4.952e-02 	 Loss in Target Net: 7.612e-03	  
 2020-02-01 20:37:46 Iteration 1550 	 Training Loss: 5.554e-02 	 Loss in Target Net: 1.083e-02	  
 2020-02-01 20:39:34 Iteration 1600 	 Training Loss: 4.924e-02 	 Loss in Target Net: 9.651e-03	  
 2020-02-01 20:41:22 Iteration 1650 	 Training Loss: 5.321e-02 	 Loss in Target Net: 7.918e-03	  
 2020-02-01 20:43:11 Iteration 1700 	 Training Loss: 5.196e-02 	 Loss in Target Net: 9.524e-03	  
 2020-02-01 20:44:59 Iteration 1750 	 Training Loss: 5.130e-02 	 Loss in Target Net: 8.402e-03	  
 2020-02-01 20:46:48 Iteration 1800 	 Training Loss: 5.112e-02 	 Loss in Target Net: 1.138e-02	  
 2020-02-01 20:48:37 Iteration 1850 	 Training Loss: 4.825e-02 	 Loss in Target Net: 5.308e-03	  
 2020-02-01 20:50:25 Iteration 1900 	 Training Loss: 4.670e-02 	 Loss in Target Net: 7.395e-03	  
 2020-02-01 20:52:14 Iteration 1950 	 Training Loss: 5.093e-02 	 Loss in Target Net: 5.991e-03	  
 2020-02-01 20:54:03 Iteration 2000 	 Training Loss: 5.470e-02 	 Loss in Target Net: 6.739e-03	  
 2020-02-01 20:55:52 Iteration 2050 	 Training Loss: 5.053e-02 	 Loss in Target Net: 6.924e-03	  
 2020-02-01 20:57:40 Iteration 2100 	 Training Loss: 5.140e-02 	 Loss in Target Net: 7.905e-03	  
 2020-02-01 20:59:29 Iteration 2150 	 Training Loss: 4.919e-02 	 Loss in Target Net: 1.039e-02	  
 2020-02-01 21:01:18 Iteration 2200 	 Training Loss: 4.621e-02 	 Loss in Target Net: 1.596e-02	  
 2020-02-01 21:03:06 Iteration 2250 	 Training Loss: 5.344e-02 	 Loss in Target Net: 7.426e-03	  
 2020-02-01 21:04:53 Iteration 2300 	 Training Loss: 4.882e-02 	 Loss in Target Net: 8.402e-03	  
 2020-02-01 21:06:42 Iteration 2350 	 Training Loss: 5.660e-02 	 Loss in Target Net: 7.176e-03	  
 2020-02-01 21:08:31 Iteration 2400 	 Training Loss: 4.781e-02 	 Loss in Target Net: 5.648e-03	  
 2020-02-01 21:10:21 Iteration 2450 	 Training Loss: 5.102e-02 	 Loss in Target Net: 7.983e-03	  
 2020-02-01 21:12:09 Iteration 2500 	 Training Loss: 4.971e-02 	 Loss in Target Net: 6.887e-03	  
 2020-02-01 21:13:58 Iteration 2550 	 Training Loss: 5.092e-02 	 Loss in Target Net: 6.536e-03	  
 2020-02-01 21:15:47 Iteration 2600 	 Training Loss: 5.212e-02 	 Loss in Target Net: 8.335e-03	  
 2020-02-01 21:17:36 Iteration 2650 	 Training Loss: 5.286e-02 	 Loss in Target Net: 6.139e-03	  
 2020-02-01 21:19:24 Iteration 2700 	 Training Loss: 4.871e-02 	 Loss in Target Net: 8.764e-03	  
 2020-02-01 21:21:13 Iteration 2750 	 Training Loss: 4.980e-02 	 Loss in Target Net: 1.013e-02	  
 2020-02-01 21:23:02 Iteration 2800 	 Training Loss: 5.146e-02 	 Loss in Target Net: 8.571e-03	  
 2020-02-01 21:24:50 Iteration 2850 	 Training Loss: 4.934e-02 	 Loss in Target Net: 6.557e-03	  
 2020-02-01 21:26:38 Iteration 2900 	 Training Loss: 5.599e-02 	 Loss in Target Net: 6.008e-03	  
 2020-02-01 21:28:27 Iteration 2950 	 Training Loss: 4.721e-02 	 Loss in Target Net: 6.584e-03	  
 2020-02-01 21:30:14 Iteration 3000 	 Training Loss: 5.066e-02 	 Loss in Target Net: 6.675e-03	  
 2020-02-01 21:32:02 Iteration 3050 	 Training Loss: 5.181e-02 	 Loss in Target Net: 1.101e-02	  
 2020-02-01 21:33:51 Iteration 3100 	 Training Loss: 5.108e-02 	 Loss in Target Net: 1.171e-02	  
 2020-02-01 21:35:40 Iteration 3150 	 Training Loss: 4.966e-02 	 Loss in Target Net: 6.753e-03	  
 2020-02-01 21:37:28 Iteration 3200 	 Training Loss: 4.723e-02 	 Loss in Target Net: 6.623e-03	  
 2020-02-01 21:39:16 Iteration 3250 	 Training Loss: 4.945e-02 	 Loss in Target Net: 7.636e-03	  
 2020-02-01 21:41:04 Iteration 3300 	 Training Loss: 5.119e-02 	 Loss in Target Net: 1.003e-02	  
 2020-02-01 21:42:55 Iteration 3350 	 Training Loss: 5.169e-02 	 Loss in Target Net: 6.263e-03	  
 2020-02-01 21:44:46 Iteration 3400 	 Training Loss: 5.051e-02 	 Loss in Target Net: 6.767e-03	  
 2020-02-01 21:46:35 Iteration 3450 	 Training Loss: 4.914e-02 	 Loss in Target Net: 9.299e-03	  
 2020-02-01 21:48:24 Iteration 3500 	 Training Loss: 4.984e-02 	 Loss in Target Net: 6.643e-03	  
 2020-02-01 21:50:12 Iteration 3550 	 Training Loss: 5.090e-02 	 Loss in Target Net: 7.189e-03	  
 2020-02-01 21:52:01 Iteration 3600 	 Training Loss: 4.904e-02 	 Loss in Target Net: 6.305e-03	  
 2020-02-01 21:53:49 Iteration 3650 	 Training Loss: 5.267e-02 	 Loss in Target Net: 5.891e-03	  
 2020-02-01 21:55:38 Iteration 3700 	 Training Loss: 4.908e-02 	 Loss in Target Net: 4.827e-03	  
 2020-02-01 21:57:26 Iteration 3750 	 Training Loss: 4.915e-02 	 Loss in Target Net: 6.743e-03	  
 2020-02-01 21:59:15 Iteration 3800 	 Training Loss: 5.072e-02 	 Loss in Target Net: 5.188e-03	  
 2020-02-01 22:01:03 Iteration 3850 	 Training Loss: 4.830e-02 	 Loss in Target Net: 5.100e-03	  
 2020-02-01 22:02:51 Iteration 3900 	 Training Loss: 5.057e-02 	 Loss in Target Net: 7.750e-03	  
 2020-02-01 22:04:40 Iteration 3950 	 Training Loss: 5.125e-02 	 Loss in Target Net: 7.697e-03	  
 2020-02-01 22:06:27 Iteration 3999 	 Training Loss: 5.103e-02 	 Loss in Target Net: 7.670e-03	  
Evaluating against victims networks
DPN92
Using Adam for retraining
Files already downloaded and verified
2020-02-01 22:06:32, Epoch 0, Iteration 7, loss 1.805 (3.546), acc 88.462 (68.800)
2020-02-01 22:06:32, Epoch 30, Iteration 7, loss 0.028 (0.051), acc 98.077 (98.600)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-7.755687, -29.071316, -49.061596, 7.4894547, -19.446192, 6.3101864, 34.90149, -66.33487, 38.49825, -76.37283], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-02-01 22:06:38 Epoch 59, Val iteration 0, acc 91.400 (91.400)
2020-02-01 22:06:45 Epoch 59, Val iteration 19, acc 92.800 (92.400)
* Prec: 92.40000114440917
--------
SENet18
Using Adam for retraining
Files already downloaded and verified
2020-02-01 22:06:47, Epoch 0, Iteration 7, loss 1.356 (0.873), acc 86.538 (86.600)
2020-02-01 22:06:48, Epoch 30, Iteration 7, loss 0.186 (0.216), acc 96.154 (95.800)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-13.846343, -10.470415, -8.302923, -2.0183558, 6.3699036, -4.559898, 27.731539, -21.823978, 11.485242, -13.483642], Poisons' Predictions:[8, 8, 6, 8, 8]
2020-02-01 22:06:48 Epoch 59, Val iteration 0, acc 91.200 (91.200)
2020-02-01 22:06:50 Epoch 59, Val iteration 19, acc 92.400 (91.140)
* Prec: 91.14000205993652
--------
ResNet50
Using Adam for retraining
Files already downloaded and verified
2020-02-01 22:06:53, Epoch 0, Iteration 7, loss 1.144 (1.622), acc 84.615 (82.800)
2020-02-01 22:06:53, Epoch 30, Iteration 7, loss 0.183 (0.068), acc 98.077 (99.400)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-25.673897, -28.66003, -49.239662, 10.086472, -57.361855, -50.842323, 39.460545, -72.37562, 50.358593, -1.7846156], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-02-01 22:06:55 Epoch 59, Val iteration 0, acc 93.200 (93.200)
2020-02-01 22:06:59 Epoch 59, Val iteration 19, acc 94.800 (93.780)
* Prec: 93.78000144958496
--------
ResNeXt29_2x64d
Using Adam for retraining
Files already downloaded and verified
2020-02-01 22:07:01, Epoch 0, Iteration 7, loss 0.393 (1.919), acc 88.462 (75.200)
2020-02-01 22:07:01, Epoch 30, Iteration 7, loss 0.011 (0.027), acc 100.000 (98.800)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-34.997627, -32.587463, -8.646308, 4.0290356, -49.86166, -20.330795, 21.217552, -40.15681, 17.874088, -19.230885], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-02-01 22:07:03 Epoch 59, Val iteration 0, acc 92.800 (92.800)
2020-02-01 22:07:07 Epoch 59, Val iteration 19, acc 92.200 (92.410)
* Prec: 92.41000175476074
--------
GoogLeNet
Using Adam for retraining
Files already downloaded and verified
2020-02-01 22:07:10, Epoch 0, Iteration 7, loss 0.359 (0.393), acc 92.308 (90.800)
2020-02-01 22:07:10, Epoch 30, Iteration 7, loss 0.034 (0.037), acc 98.077 (98.600)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-19.605467, -7.547272, -5.5316367, -0.41025543, -9.697334, 0.35846215, 8.134164, -9.916503, 5.873067, -13.2668495], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-02-01 22:07:12 Epoch 59, Val iteration 0, acc 91.000 (91.000)
2020-02-01 22:07:17 Epoch 59, Val iteration 19, acc 91.800 (92.250)
* Prec: 92.2500015258789
--------
MobileNetV2
Using Adam for retraining
Files already downloaded and verified
2020-02-01 22:07:19, Epoch 0, Iteration 7, loss 3.029 (4.152), acc 65.385 (58.000)
2020-02-01 22:07:19, Epoch 30, Iteration 7, loss 0.029 (0.412), acc 98.077 (91.600)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-5.418642, -14.082078, 5.190578, 13.685684, -7.9140944, -8.186786, 21.75749, -16.826956, 19.014435, -19.11778], Poisons' Predictions:[8, 8, 8, 6, 8]
2020-02-01 22:07:20 Epoch 59, Val iteration 0, acc 89.000 (89.000)
2020-02-01 22:07:22 Epoch 59, Val iteration 19, acc 89.600 (87.670)
* Prec: 87.6700008392334
--------
ResNet18
Using Adam for retraining
Files already downloaded and verified
2020-02-01 22:07:24, Epoch 0, Iteration 7, loss 0.286 (0.952), acc 92.308 (84.000)
2020-02-01 22:07:24, Epoch 30, Iteration 7, loss 0.013 (0.050), acc 100.000 (98.000)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-34.630352, -10.6164465, -14.240867, 1.81497, -39.762787, -8.575011, 11.026796, -37.46641, 9.056031, -31.041449], Poisons' Predictions:[8, 8, 8, 6, 8]
2020-02-01 22:07:25 Epoch 59, Val iteration 0, acc 93.800 (93.800)
2020-02-01 22:07:27 Epoch 59, Val iteration 19, acc 94.400 (92.940)
* Prec: 92.94000129699707
--------
DenseNet121
Using Adam for retraining
Files already downloaded and verified
2020-02-01 22:07:30, Epoch 0, Iteration 7, loss 0.452 (0.455), acc 86.538 (92.600)
2020-02-01 22:07:30, Epoch 30, Iteration 7, loss 0.001 (0.003), acc 100.000 (100.000)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-10.6638975, -13.096071, -14.027604, -3.2623205, -8.607599, -6.5591526, 7.347325, -28.013105, 5.861103, -14.462579], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-02-01 22:07:32 Epoch 59, Val iteration 0, acc 93.400 (93.400)
2020-02-01 22:07:36 Epoch 59, Val iteration 19, acc 93.800 (93.150)
* Prec: 93.15000076293946
--------
------SUMMARY------
TIME ELAPSED (mins): 144
TARGET INDEX: 32
DPN92 1
SENet18 0
ResNet50 1
ResNeXt29_2x64d 0
GoogLeNet 0
MobileNetV2 0
ResNet18 0
DenseNet121 0
