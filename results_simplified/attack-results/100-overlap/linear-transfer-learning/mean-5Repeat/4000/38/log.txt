Namespace(chk_path='chk-black-ourmean/', chk_subdir='poisons', device='cuda', dset_path='datasets', end2end=False, eval_poison_path='', gpu='2', lr_decay_epoch=[30, 45], mode='mean', model_resume_path='model-chks', nearest=False, net_repeat=5, num_per_class=50, original_grad=True, poison_decay_ites=[], poison_decay_ratio=0.1, poison_epsilon=0.1, poison_ites=4000, poison_label=8, poison_lr=0.04, poison_momentum=0.9, poison_num=5, poison_opt='adam', resume_poison_ite=0, retrain_bsize=64, retrain_epochs=60, retrain_lr=0.1, retrain_momentum=0.9, retrain_opt='adam', retrain_wd=0, subs_chk_name=['ckpt-%s-4800-dp0.200-droplayer0.000-seed1226.t7', 'ckpt-%s-4800-dp0.250-droplayer0.000-seed1226.t7', 'ckpt-%s-4800-dp0.300-droplayer0.000.t7'], subs_dp=[0.2, 0.25, 0.3], subset_group=0, substitute_nets=['DPN92', 'SENet18', 'ResNet50', 'ResNeXt29_2x64d', 'GoogLeNet', 'MobileNetV2'], target_index=38, target_label=6, target_net=['DPN92', 'SENet18', 'ResNet50', 'ResNeXt29_2x64d', 'GoogLeNet', 'MobileNetV2', 'ResNet18', 'DenseNet121'], test_chk_name='ckpt-%s-4800.t7', tol=1e-06, train_data_path='datasets/CIFAR10_TRAIN_Split.pth')
Path: chk-black-ourmean/mean-5Repeat/4000/38
Selected base image indices: [213, 225, 227, 247, 249]
 2020-02-01 21:45:46 Iteration 0 	 Training Loss: 1.048e+00 	 Loss in Target Net: 3.702e-01	  
 2020-02-01 21:47:34 Iteration 50 	 Training Loss: 7.018e-02 	 Loss in Target Net: 9.776e-03	  
 2020-02-01 21:49:21 Iteration 100 	 Training Loss: 6.320e-02 	 Loss in Target Net: 4.964e-03	  
 2020-02-01 21:51:09 Iteration 150 	 Training Loss: 5.765e-02 	 Loss in Target Net: 5.026e-03	  
 2020-02-01 21:52:56 Iteration 200 	 Training Loss: 5.421e-02 	 Loss in Target Net: 4.867e-03	  
 2020-02-01 21:54:44 Iteration 250 	 Training Loss: 5.516e-02 	 Loss in Target Net: 4.150e-03	  
 2020-02-01 21:56:31 Iteration 300 	 Training Loss: 5.424e-02 	 Loss in Target Net: 4.831e-03	  
 2020-02-01 21:58:17 Iteration 350 	 Training Loss: 5.223e-02 	 Loss in Target Net: 8.179e-03	  
 2020-02-01 22:00:04 Iteration 400 	 Training Loss: 5.056e-02 	 Loss in Target Net: 7.590e-03	  
 2020-02-01 22:01:51 Iteration 450 	 Training Loss: 5.366e-02 	 Loss in Target Net: 8.464e-03	  
 2020-02-01 22:03:38 Iteration 500 	 Training Loss: 5.163e-02 	 Loss in Target Net: 7.525e-03	  
 2020-02-01 22:05:26 Iteration 550 	 Training Loss: 4.710e-02 	 Loss in Target Net: 6.517e-03	  
 2020-02-01 22:07:13 Iteration 600 	 Training Loss: 5.000e-02 	 Loss in Target Net: 7.613e-03	  
 2020-02-01 22:08:56 Iteration 650 	 Training Loss: 4.721e-02 	 Loss in Target Net: 7.397e-03	  
 2020-02-01 22:10:37 Iteration 700 	 Training Loss: 4.929e-02 	 Loss in Target Net: 7.505e-03	  
 2020-02-01 22:12:18 Iteration 750 	 Training Loss: 4.834e-02 	 Loss in Target Net: 6.361e-03	  
 2020-02-01 22:13:59 Iteration 800 	 Training Loss: 4.646e-02 	 Loss in Target Net: 6.739e-03	  
 2020-02-01 22:15:39 Iteration 850 	 Training Loss: 5.194e-02 	 Loss in Target Net: 7.005e-03	  
 2020-02-01 22:17:19 Iteration 900 	 Training Loss: 5.120e-02 	 Loss in Target Net: 7.070e-03	  
 2020-02-01 22:18:59 Iteration 950 	 Training Loss: 4.902e-02 	 Loss in Target Net: 5.222e-03	  
 2020-02-01 22:20:40 Iteration 1000 	 Training Loss: 4.892e-02 	 Loss in Target Net: 4.007e-03	  
 2020-02-01 22:22:20 Iteration 1050 	 Training Loss: 4.703e-02 	 Loss in Target Net: 7.407e-03	  
 2020-02-01 22:24:00 Iteration 1100 	 Training Loss: 4.998e-02 	 Loss in Target Net: 5.342e-03	  
 2020-02-01 22:25:41 Iteration 1150 	 Training Loss: 5.215e-02 	 Loss in Target Net: 6.776e-03	  
 2020-02-01 22:27:22 Iteration 1200 	 Training Loss: 4.802e-02 	 Loss in Target Net: 3.974e-03	  
 2020-02-01 22:29:03 Iteration 1250 	 Training Loss: 4.858e-02 	 Loss in Target Net: 4.099e-03	  
 2020-02-01 22:30:43 Iteration 1300 	 Training Loss: 4.542e-02 	 Loss in Target Net: 7.036e-03	  
 2020-02-01 22:32:23 Iteration 1350 	 Training Loss: 4.736e-02 	 Loss in Target Net: 4.622e-03	  
 2020-02-01 22:34:04 Iteration 1400 	 Training Loss: 4.721e-02 	 Loss in Target Net: 5.304e-03	  
 2020-02-01 22:35:43 Iteration 1450 	 Training Loss: 4.637e-02 	 Loss in Target Net: 7.216e-03	  
 2020-02-01 22:37:23 Iteration 1500 	 Training Loss: 4.811e-02 	 Loss in Target Net: 6.773e-03	  
 2020-02-01 22:39:03 Iteration 1550 	 Training Loss: 5.034e-02 	 Loss in Target Net: 8.290e-03	  
 2020-02-01 22:40:43 Iteration 1600 	 Training Loss: 4.806e-02 	 Loss in Target Net: 8.600e-03	  
 2020-02-01 22:42:23 Iteration 1650 	 Training Loss: 4.726e-02 	 Loss in Target Net: 9.118e-03	  
 2020-02-01 22:44:03 Iteration 1700 	 Training Loss: 5.003e-02 	 Loss in Target Net: 7.384e-03	  
 2020-02-01 22:45:43 Iteration 1750 	 Training Loss: 4.637e-02 	 Loss in Target Net: 7.827e-03	  
 2020-02-01 22:47:24 Iteration 1800 	 Training Loss: 4.596e-02 	 Loss in Target Net: 5.663e-03	  
 2020-02-01 22:49:06 Iteration 1850 	 Training Loss: 4.584e-02 	 Loss in Target Net: 7.724e-03	  
 2020-02-01 22:50:57 Iteration 1900 	 Training Loss: 4.798e-02 	 Loss in Target Net: 7.621e-03	  
 2020-02-01 22:52:48 Iteration 1950 	 Training Loss: 4.676e-02 	 Loss in Target Net: 8.818e-03	  
 2020-02-01 22:54:39 Iteration 2000 	 Training Loss: 4.561e-02 	 Loss in Target Net: 1.009e-02	  
 2020-02-01 22:56:29 Iteration 2050 	 Training Loss: 4.588e-02 	 Loss in Target Net: 7.278e-03	  
 2020-02-01 22:58:21 Iteration 2100 	 Training Loss: 4.834e-02 	 Loss in Target Net: 6.169e-03	  
 2020-02-01 23:00:14 Iteration 2150 	 Training Loss: 4.522e-02 	 Loss in Target Net: 1.034e-02	  
 2020-02-01 23:02:06 Iteration 2200 	 Training Loss: 5.213e-02 	 Loss in Target Net: 8.209e-03	  
 2020-02-01 23:04:00 Iteration 2250 	 Training Loss: 4.635e-02 	 Loss in Target Net: 6.724e-03	  
 2020-02-01 23:05:54 Iteration 2300 	 Training Loss: 4.589e-02 	 Loss in Target Net: 5.350e-03	  
 2020-02-01 23:07:44 Iteration 2350 	 Training Loss: 4.718e-02 	 Loss in Target Net: 7.558e-03	  
 2020-02-01 23:09:36 Iteration 2400 	 Training Loss: 4.989e-02 	 Loss in Target Net: 9.997e-03	  
 2020-02-01 23:11:16 Iteration 2450 	 Training Loss: 5.237e-02 	 Loss in Target Net: 1.089e-02	  
 2020-02-01 23:12:56 Iteration 2500 	 Training Loss: 5.043e-02 	 Loss in Target Net: 7.045e-03	  
 2020-02-01 23:14:36 Iteration 2550 	 Training Loss: 4.813e-02 	 Loss in Target Net: 8.370e-03	  
 2020-02-01 23:16:16 Iteration 2600 	 Training Loss: 5.017e-02 	 Loss in Target Net: 8.418e-03	  
 2020-02-01 23:17:56 Iteration 2650 	 Training Loss: 4.686e-02 	 Loss in Target Net: 1.177e-02	  
 2020-02-01 23:19:37 Iteration 2700 	 Training Loss: 4.618e-02 	 Loss in Target Net: 8.686e-03	  
 2020-02-01 23:21:17 Iteration 2750 	 Training Loss: 4.526e-02 	 Loss in Target Net: 6.746e-03	  
 2020-02-01 23:22:58 Iteration 2800 	 Training Loss: 4.623e-02 	 Loss in Target Net: 7.368e-03	  
 2020-02-01 23:24:39 Iteration 2850 	 Training Loss: 4.866e-02 	 Loss in Target Net: 9.082e-03	  
 2020-02-01 23:26:19 Iteration 2900 	 Training Loss: 4.563e-02 	 Loss in Target Net: 1.101e-02	  
 2020-02-01 23:27:59 Iteration 2950 	 Training Loss: 4.747e-02 	 Loss in Target Net: 7.936e-03	  
 2020-02-01 23:29:39 Iteration 3000 	 Training Loss: 4.739e-02 	 Loss in Target Net: 7.709e-03	  
 2020-02-01 23:31:19 Iteration 3050 	 Training Loss: 4.962e-02 	 Loss in Target Net: 6.884e-03	  
 2020-02-01 23:32:59 Iteration 3100 	 Training Loss: 4.551e-02 	 Loss in Target Net: 6.515e-03	  
 2020-02-01 23:34:41 Iteration 3150 	 Training Loss: 4.623e-02 	 Loss in Target Net: 1.052e-02	  
 2020-02-01 23:36:21 Iteration 3200 	 Training Loss: 4.463e-02 	 Loss in Target Net: 7.382e-03	  
 2020-02-01 23:38:02 Iteration 3250 	 Training Loss: 4.588e-02 	 Loss in Target Net: 5.841e-03	  
 2020-02-01 23:39:42 Iteration 3300 	 Training Loss: 4.462e-02 	 Loss in Target Net: 6.855e-03	  
 2020-02-01 23:41:22 Iteration 3350 	 Training Loss: 4.731e-02 	 Loss in Target Net: 1.036e-02	  
 2020-02-01 23:43:02 Iteration 3400 	 Training Loss: 4.459e-02 	 Loss in Target Net: 8.863e-03	  
 2020-02-01 23:44:41 Iteration 3450 	 Training Loss: 4.595e-02 	 Loss in Target Net: 6.664e-03	  
 2020-02-01 23:46:22 Iteration 3500 	 Training Loss: 4.874e-02 	 Loss in Target Net: 8.269e-03	  
 2020-02-01 23:48:01 Iteration 3550 	 Training Loss: 4.904e-02 	 Loss in Target Net: 6.984e-03	  
 2020-02-01 23:49:41 Iteration 3600 	 Training Loss: 4.790e-02 	 Loss in Target Net: 5.027e-03	  
 2020-02-01 23:51:21 Iteration 3650 	 Training Loss: 4.424e-02 	 Loss in Target Net: 7.122e-03	  
 2020-02-01 23:53:02 Iteration 3700 	 Training Loss: 4.724e-02 	 Loss in Target Net: 6.864e-03	  
 2020-02-01 23:54:42 Iteration 3750 	 Training Loss: 4.650e-02 	 Loss in Target Net: 1.030e-02	  
 2020-02-01 23:56:22 Iteration 3800 	 Training Loss: 4.687e-02 	 Loss in Target Net: 9.843e-03	  
 2020-02-01 23:58:02 Iteration 3850 	 Training Loss: 4.721e-02 	 Loss in Target Net: 8.414e-03	  
 2020-02-01 23:59:42 Iteration 3900 	 Training Loss: 4.512e-02 	 Loss in Target Net: 6.395e-03	  
 2020-02-02 00:01:22 Iteration 3950 	 Training Loss: 4.799e-02 	 Loss in Target Net: 8.439e-03	  
 2020-02-02 00:02:59 Iteration 3999 	 Training Loss: 4.893e-02 	 Loss in Target Net: 7.495e-03	  
Evaluating against victims networks
DPN92
Using Adam for retraining
Files already downloaded and verified
2020-02-02 00:03:04, Epoch 0, Iteration 7, loss 1.331 (3.500), acc 90.385 (70.800)
2020-02-02 00:03:04, Epoch 30, Iteration 7, loss 0.001 (0.144), acc 100.000 (97.000)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[43.517544, -18.196863, -40.323963, 15.11642, -28.667255, 0.726645, 55.939903, -72.802704, 49.568836, -88.509605], Poisons' Predictions:[6, 8, 8, 6, 8]
2020-02-02 00:03:09 Epoch 59, Val iteration 0, acc 91.200 (91.200)
2020-02-02 00:03:17 Epoch 59, Val iteration 19, acc 92.000 (92.380)
* Prec: 92.38000144958497
--------
SENet18
Using Adam for retraining
Files already downloaded and verified
2020-02-02 00:03:19, Epoch 0, Iteration 7, loss 2.070 (1.113), acc 90.385 (86.400)
2020-02-02 00:03:19, Epoch 30, Iteration 7, loss 0.123 (0.155), acc 98.077 (96.200)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-2.3034942, -10.289988, -4.619177, -2.5450234, 2.2295458, -14.578505, 17.476225, -16.059195, 17.982782, -14.340511], Poisons' Predictions:[8, 8, 8, 8, 6]
2020-02-02 00:03:20 Epoch 59, Val iteration 0, acc 92.200 (92.200)
2020-02-02 00:03:22 Epoch 59, Val iteration 19, acc 93.200 (91.870)
* Prec: 91.87000160217285
--------
ResNet50
Using Adam for retraining
Files already downloaded and verified
2020-02-02 00:03:24, Epoch 0, Iteration 7, loss 0.004 (1.169), acc 100.000 (88.600)
2020-02-02 00:03:25, Epoch 30, Iteration 7, loss 0.000 (0.155), acc 100.000 (99.000)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-47.754257, -57.019238, -37.431854, -50.151054, -47.980206, -60.64972, 26.537203, -52.235397, 31.492115, -28.529806], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-02-02 00:03:26 Epoch 59, Val iteration 0, acc 92.400 (92.400)
2020-02-02 00:03:30 Epoch 59, Val iteration 19, acc 92.400 (93.080)
* Prec: 93.08000183105469
--------
ResNeXt29_2x64d
Using Adam for retraining
Files already downloaded and verified
2020-02-02 00:03:32, Epoch 0, Iteration 7, loss 0.891 (1.960), acc 86.538 (74.800)
2020-02-02 00:03:33, Epoch 30, Iteration 7, loss 0.002 (0.107), acc 100.000 (98.000)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-27.33757, -38.721706, -0.51658195, 11.567872, -49.26323, -21.585897, 30.37833, -23.7204, 25.069767, -32.386948], Poisons' Predictions:[8, 6, 8, 6, 8]
2020-02-02 00:03:34 Epoch 59, Val iteration 0, acc 93.200 (93.200)
2020-02-02 00:03:38 Epoch 59, Val iteration 19, acc 93.000 (92.780)
* Prec: 92.78000144958496
--------
GoogLeNet
Using Adam for retraining
Files already downloaded and verified
2020-02-02 00:03:41, Epoch 0, Iteration 7, loss 0.746 (0.413), acc 78.846 (88.600)
2020-02-02 00:03:41, Epoch 30, Iteration 7, loss 0.064 (0.058), acc 96.154 (98.000)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-25.458733, -11.170606, -14.011454, -2.117778, -3.3360937, -1.6261382, 10.345457, -12.561034, 1.3672055, -16.967403], Poisons' Predictions:[8, 8, 8, 6, 8]
2020-02-02 00:03:43 Epoch 59, Val iteration 0, acc 91.600 (91.600)
2020-02-02 00:03:48 Epoch 59, Val iteration 19, acc 91.400 (91.940)
* Prec: 91.94000091552735
--------
MobileNetV2
Using Adam for retraining
Files already downloaded and verified
2020-02-02 00:03:50, Epoch 0, Iteration 7, loss 2.347 (3.862), acc 82.692 (59.800)
2020-02-02 00:03:51, Epoch 30, Iteration 7, loss 0.075 (0.163), acc 96.154 (95.200)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[1.2498411, -26.90432, -1.7631161, 13.965258, -5.930981, 4.303499, 21.377932, -18.720284, 14.4679365, -14.025009], Poisons' Predictions:[6, 8, 8, 6, 6]
2020-02-02 00:03:51 Epoch 59, Val iteration 0, acc 88.400 (88.400)
2020-02-02 00:03:53 Epoch 59, Val iteration 19, acc 88.200 (86.730)
* Prec: 86.73000221252441
--------
ResNet18
Using Adam for retraining
Files already downloaded and verified
2020-02-02 00:03:55, Epoch 0, Iteration 7, loss 0.137 (0.757), acc 90.385 (87.000)
2020-02-02 00:03:56, Epoch 30, Iteration 7, loss 0.003 (0.032), acc 100.000 (98.400)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-31.076754, -10.272642, -28.83333, 3.153514, -44.183052, -2.6866264, 12.27229, -39.519497, 10.819239, -64.52499], Poisons' Predictions:[6, 8, 8, 6, 8]
2020-02-02 00:03:56 Epoch 59, Val iteration 0, acc 94.000 (94.000)
2020-02-02 00:03:58 Epoch 59, Val iteration 19, acc 93.600 (92.700)
* Prec: 92.7000015258789
--------
DenseNet121
Using Adam for retraining
Files already downloaded and verified
2020-02-02 00:04:01, Epoch 0, Iteration 7, loss 0.241 (0.384), acc 98.077 (92.600)
2020-02-02 00:04:01, Epoch 30, Iteration 7, loss 0.002 (0.028), acc 100.000 (99.000)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-13.4469185, -19.42726, -15.704057, -5.9921203, -8.836647, -9.736777, 6.820291, -36.560867, 5.2535195, -22.417683], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-02-02 00:04:03 Epoch 59, Val iteration 0, acc 94.000 (94.000)
2020-02-02 00:04:07 Epoch 59, Val iteration 19, acc 93.600 (93.230)
* Prec: 93.23000106811523
--------
------SUMMARY------
TIME ELAPSED (mins): 137
TARGET INDEX: 38
DPN92 0
SENet18 1
ResNet50 1
ResNeXt29_2x64d 0
GoogLeNet 0
MobileNetV2 0
ResNet18 0
DenseNet121 0
