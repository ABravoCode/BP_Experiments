Namespace(chk_path='chk-black-ourmean/', chk_subdir='poisons', device='cuda', dset_path='datasets', end2end=False, eval_poison_path='', gpu='1', lr_decay_epoch=[30, 45], mode='mean', model_resume_path='model-chks', nearest=False, net_repeat=5, num_per_class=50, original_grad=True, poison_decay_ites=[], poison_decay_ratio=0.1, poison_epsilon=0.1, poison_ites=4000, poison_label=8, poison_lr=0.04, poison_momentum=0.9, poison_num=5, poison_opt='adam', resume_poison_ite=0, retrain_bsize=64, retrain_epochs=60, retrain_lr=0.1, retrain_momentum=0.9, retrain_opt='adam', retrain_wd=0, subs_chk_name=['ckpt-%s-4800-dp0.200-droplayer0.000-seed1226.t7', 'ckpt-%s-4800-dp0.250-droplayer0.000-seed1226.t7', 'ckpt-%s-4800-dp0.300-droplayer0.000.t7'], subs_dp=[0.2, 0.25, 0.3], subset_group=0, substitute_nets=['DPN92', 'SENet18', 'ResNet50', 'ResNeXt29_2x64d', 'GoogLeNet', 'MobileNetV2'], target_index=17, target_label=6, target_net=['DPN92', 'SENet18', 'ResNet50', 'ResNeXt29_2x64d', 'GoogLeNet', 'MobileNetV2', 'ResNet18', 'DenseNet121'], test_chk_name='ckpt-%s-4800.t7', tol=1e-06, train_data_path='datasets/CIFAR10_TRAIN_Split.pth')
Path: chk-black-ourmean/mean-5Repeat/4000/17
Selected base image indices: [213, 225, 227, 247, 249]
 2020-02-01 10:01:59 Iteration 0 	 Training Loss: 1.088e+00 	 Loss in Target Net: 3.762e-01	  
 2020-02-01 10:03:59 Iteration 50 	 Training Loss: 5.894e-02 	 Loss in Target Net: 5.736e-03	  
 2020-02-01 10:05:46 Iteration 100 	 Training Loss: 4.943e-02 	 Loss in Target Net: 6.070e-03	  
 2020-02-01 10:07:33 Iteration 150 	 Training Loss: 4.689e-02 	 Loss in Target Net: 5.333e-03	  
 2020-02-01 10:09:20 Iteration 200 	 Training Loss: 4.559e-02 	 Loss in Target Net: 5.667e-03	  
 2020-02-01 10:11:05 Iteration 250 	 Training Loss: 4.093e-02 	 Loss in Target Net: 5.182e-03	  
 2020-02-01 10:12:52 Iteration 300 	 Training Loss: 4.209e-02 	 Loss in Target Net: 6.294e-03	  
 2020-02-01 10:14:38 Iteration 350 	 Training Loss: 4.585e-02 	 Loss in Target Net: 6.862e-03	  
 2020-02-01 10:16:24 Iteration 400 	 Training Loss: 4.020e-02 	 Loss in Target Net: 7.765e-03	  
 2020-02-01 10:18:11 Iteration 450 	 Training Loss: 4.209e-02 	 Loss in Target Net: 5.322e-03	  
 2020-02-01 10:19:59 Iteration 500 	 Training Loss: 4.420e-02 	 Loss in Target Net: 5.491e-03	  
 2020-02-01 10:21:46 Iteration 550 	 Training Loss: 3.957e-02 	 Loss in Target Net: 7.313e-03	  
 2020-02-01 10:23:32 Iteration 600 	 Training Loss: 4.258e-02 	 Loss in Target Net: 7.174e-03	  
 2020-02-01 10:25:18 Iteration 650 	 Training Loss: 3.989e-02 	 Loss in Target Net: 8.675e-03	  
 2020-02-01 10:27:05 Iteration 700 	 Training Loss: 4.073e-02 	 Loss in Target Net: 6.848e-03	  
 2020-02-01 10:28:52 Iteration 750 	 Training Loss: 4.074e-02 	 Loss in Target Net: 6.140e-03	  
 2020-02-01 10:30:39 Iteration 800 	 Training Loss: 4.265e-02 	 Loss in Target Net: 3.634e-03	  
 2020-02-01 10:32:25 Iteration 850 	 Training Loss: 4.074e-02 	 Loss in Target Net: 5.451e-03	  
 2020-02-01 10:34:12 Iteration 900 	 Training Loss: 4.586e-02 	 Loss in Target Net: 5.552e-03	  
 2020-02-01 10:35:58 Iteration 950 	 Training Loss: 3.995e-02 	 Loss in Target Net: 5.112e-03	  
 2020-02-01 10:37:44 Iteration 1000 	 Training Loss: 4.028e-02 	 Loss in Target Net: 5.645e-03	  
 2020-02-01 10:39:31 Iteration 1050 	 Training Loss: 3.926e-02 	 Loss in Target Net: 6.498e-03	  
 2020-02-01 10:41:17 Iteration 1100 	 Training Loss: 3.931e-02 	 Loss in Target Net: 5.412e-03	  
 2020-02-01 10:43:03 Iteration 1150 	 Training Loss: 4.050e-02 	 Loss in Target Net: 5.910e-03	  
 2020-02-01 10:44:49 Iteration 1200 	 Training Loss: 4.179e-02 	 Loss in Target Net: 4.343e-03	  
 2020-02-01 10:46:35 Iteration 1250 	 Training Loss: 4.060e-02 	 Loss in Target Net: 4.433e-03	  
 2020-02-01 10:48:20 Iteration 1300 	 Training Loss: 4.096e-02 	 Loss in Target Net: 5.578e-03	  
 2020-02-01 10:50:07 Iteration 1350 	 Training Loss: 4.093e-02 	 Loss in Target Net: 3.149e-03	  
 2020-02-01 10:51:52 Iteration 1400 	 Training Loss: 4.074e-02 	 Loss in Target Net: 3.261e-03	  
 2020-02-01 10:53:39 Iteration 1450 	 Training Loss: 4.180e-02 	 Loss in Target Net: 4.114e-03	  
 2020-02-01 10:55:25 Iteration 1500 	 Training Loss: 3.931e-02 	 Loss in Target Net: 3.148e-03	  
 2020-02-01 10:57:11 Iteration 1550 	 Training Loss: 4.045e-02 	 Loss in Target Net: 3.203e-03	  
 2020-02-01 10:58:57 Iteration 1600 	 Training Loss: 4.070e-02 	 Loss in Target Net: 3.843e-03	  
 2020-02-01 11:00:43 Iteration 1650 	 Training Loss: 3.954e-02 	 Loss in Target Net: 5.267e-03	  
 2020-02-01 11:02:31 Iteration 1700 	 Training Loss: 4.007e-02 	 Loss in Target Net: 4.305e-03	  
 2020-02-01 11:04:18 Iteration 1750 	 Training Loss: 3.920e-02 	 Loss in Target Net: 4.191e-03	  
 2020-02-01 11:06:04 Iteration 1800 	 Training Loss: 4.416e-02 	 Loss in Target Net: 3.738e-03	  
 2020-02-01 11:07:51 Iteration 1850 	 Training Loss: 4.050e-02 	 Loss in Target Net: 3.393e-03	  
 2020-02-01 11:09:36 Iteration 1900 	 Training Loss: 4.039e-02 	 Loss in Target Net: 2.905e-03	  
 2020-02-01 11:11:23 Iteration 1950 	 Training Loss: 3.976e-02 	 Loss in Target Net: 5.251e-03	  
 2020-02-01 11:13:09 Iteration 2000 	 Training Loss: 3.729e-02 	 Loss in Target Net: 2.689e-03	  
 2020-02-01 11:14:55 Iteration 2050 	 Training Loss: 4.122e-02 	 Loss in Target Net: 5.110e-03	  
 2020-02-01 11:16:41 Iteration 2100 	 Training Loss: 4.063e-02 	 Loss in Target Net: 3.807e-03	  
 2020-02-01 11:18:27 Iteration 2150 	 Training Loss: 3.673e-02 	 Loss in Target Net: 4.808e-03	  
 2020-02-01 11:20:13 Iteration 2200 	 Training Loss: 3.968e-02 	 Loss in Target Net: 3.504e-03	  
 2020-02-01 11:21:59 Iteration 2250 	 Training Loss: 3.775e-02 	 Loss in Target Net: 3.705e-03	  
 2020-02-01 11:23:46 Iteration 2300 	 Training Loss: 4.221e-02 	 Loss in Target Net: 3.611e-03	  
 2020-02-01 11:25:31 Iteration 2350 	 Training Loss: 3.869e-02 	 Loss in Target Net: 4.033e-03	  
 2020-02-01 11:27:17 Iteration 2400 	 Training Loss: 3.950e-02 	 Loss in Target Net: 2.841e-03	  
 2020-02-01 11:29:03 Iteration 2450 	 Training Loss: 3.761e-02 	 Loss in Target Net: 3.869e-03	  
 2020-02-01 11:30:48 Iteration 2500 	 Training Loss: 3.883e-02 	 Loss in Target Net: 2.764e-03	  
 2020-02-01 11:32:34 Iteration 2550 	 Training Loss: 3.837e-02 	 Loss in Target Net: 2.502e-03	  
 2020-02-01 11:34:20 Iteration 2600 	 Training Loss: 4.209e-02 	 Loss in Target Net: 4.352e-03	  
 2020-02-01 11:36:06 Iteration 2650 	 Training Loss: 4.029e-02 	 Loss in Target Net: 3.938e-03	  
 2020-02-01 11:37:51 Iteration 2700 	 Training Loss: 3.802e-02 	 Loss in Target Net: 3.062e-03	  
 2020-02-01 11:39:36 Iteration 2750 	 Training Loss: 3.859e-02 	 Loss in Target Net: 2.966e-03	  
 2020-02-01 11:41:22 Iteration 2800 	 Training Loss: 3.805e-02 	 Loss in Target Net: 2.814e-03	  
 2020-02-01 11:43:07 Iteration 2850 	 Training Loss: 4.070e-02 	 Loss in Target Net: 1.119e-03	  
 2020-02-01 11:44:53 Iteration 2900 	 Training Loss: 4.032e-02 	 Loss in Target Net: 2.201e-03	  
 2020-02-01 11:46:39 Iteration 2950 	 Training Loss: 3.885e-02 	 Loss in Target Net: 2.613e-03	  
 2020-02-01 11:48:24 Iteration 3000 	 Training Loss: 3.840e-02 	 Loss in Target Net: 2.643e-03	  
 2020-02-01 11:50:10 Iteration 3050 	 Training Loss: 3.880e-02 	 Loss in Target Net: 3.160e-03	  
 2020-02-01 11:51:56 Iteration 3100 	 Training Loss: 4.052e-02 	 Loss in Target Net: 2.229e-03	  
 2020-02-01 11:53:42 Iteration 3150 	 Training Loss: 4.306e-02 	 Loss in Target Net: 3.160e-03	  
 2020-02-01 11:55:28 Iteration 3200 	 Training Loss: 3.918e-02 	 Loss in Target Net: 4.448e-03	  
 2020-02-01 11:57:14 Iteration 3250 	 Training Loss: 3.719e-02 	 Loss in Target Net: 2.920e-03	  
 2020-02-01 11:59:01 Iteration 3300 	 Training Loss: 3.852e-02 	 Loss in Target Net: 3.380e-03	  
 2020-02-01 12:00:46 Iteration 3350 	 Training Loss: 3.860e-02 	 Loss in Target Net: 3.461e-03	  
 2020-02-01 12:02:32 Iteration 3400 	 Training Loss: 3.888e-02 	 Loss in Target Net: 3.045e-03	  
 2020-02-01 12:04:18 Iteration 3450 	 Training Loss: 4.202e-02 	 Loss in Target Net: 2.362e-03	  
 2020-02-01 12:06:05 Iteration 3500 	 Training Loss: 3.955e-02 	 Loss in Target Net: 1.968e-03	  
 2020-02-01 12:07:50 Iteration 3550 	 Training Loss: 4.161e-02 	 Loss in Target Net: 2.737e-03	  
 2020-02-01 12:09:38 Iteration 3600 	 Training Loss: 3.991e-02 	 Loss in Target Net: 2.137e-03	  
 2020-02-01 12:11:24 Iteration 3650 	 Training Loss: 3.776e-02 	 Loss in Target Net: 3.063e-03	  
 2020-02-01 12:13:11 Iteration 3700 	 Training Loss: 3.950e-02 	 Loss in Target Net: 2.558e-03	  
 2020-02-01 12:14:56 Iteration 3750 	 Training Loss: 3.819e-02 	 Loss in Target Net: 5.175e-03	  
 2020-02-01 12:16:40 Iteration 3800 	 Training Loss: 3.836e-02 	 Loss in Target Net: 3.345e-03	  
 2020-02-01 12:18:26 Iteration 3850 	 Training Loss: 3.793e-02 	 Loss in Target Net: 4.009e-03	  
 2020-02-01 12:20:10 Iteration 3900 	 Training Loss: 4.056e-02 	 Loss in Target Net: 3.059e-03	  
 2020-02-01 12:21:55 Iteration 3950 	 Training Loss: 4.102e-02 	 Loss in Target Net: 4.893e-03	  
 2020-02-01 12:23:38 Iteration 3999 	 Training Loss: 3.698e-02 	 Loss in Target Net: 5.012e-03	  
Evaluating against victims networks
DPN92
Using Adam for retraining
Files already downloaded and verified
2020-02-01 12:23:43, Epoch 0, Iteration 7, loss 1.580 (3.841), acc 90.385 (69.000)
2020-02-01 12:23:43, Epoch 30, Iteration 7, loss 0.001 (0.175), acc 100.000 (97.200)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-0.7160517, -23.2215, -65.71961, -4.2522335, -40.617126, -5.1555295, 34.208775, -61.79998, 30.177197, -126.25274], Poisons' Predictions:[6, 8, 8, 6, 8]
2020-02-01 12:23:48 Epoch 59, Val iteration 0, acc 91.400 (91.400)
2020-02-01 12:23:55 Epoch 59, Val iteration 19, acc 92.600 (92.120)
* Prec: 92.12000160217285
--------
SENet18
Using Adam for retraining
Files already downloaded and verified
2020-02-01 12:23:57, Epoch 0, Iteration 7, loss 1.610 (1.049), acc 88.462 (87.800)
2020-02-01 12:23:58, Epoch 30, Iteration 7, loss 0.210 (0.224), acc 94.231 (95.400)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-1.4684193, -3.002842, -14.218652, -6.653191, 7.640479, -11.998075, 30.410675, -11.403739, 20.413403, -15.1412325], Poisons' Predictions:[6, 6, 6, 8, 8]
2020-02-01 12:23:58 Epoch 59, Val iteration 0, acc 91.400 (91.400)
2020-02-01 12:24:00 Epoch 59, Val iteration 19, acc 92.400 (91.080)
* Prec: 91.08000144958496
--------
ResNet50
Using Adam for retraining
Files already downloaded and verified
2020-02-01 12:24:03, Epoch 0, Iteration 7, loss 2.056 (1.337), acc 96.154 (87.000)
2020-02-01 12:24:03, Epoch 30, Iteration 7, loss 0.004 (0.022), acc 100.000 (99.400)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-45.191425, -3.2512867, -36.903248, -22.256641, -33.83365, -74.21074, 19.053308, -63.097404, 15.9711895, -21.555492], Poisons' Predictions:[6, 8, 8, 8, 8]
2020-02-01 12:24:05 Epoch 59, Val iteration 0, acc 92.000 (92.000)
2020-02-01 12:24:09 Epoch 59, Val iteration 19, acc 93.600 (91.970)
* Prec: 91.97000122070312
--------
ResNeXt29_2x64d
Using Adam for retraining
Files already downloaded and verified
2020-02-01 12:24:11, Epoch 0, Iteration 7, loss 0.839 (2.467), acc 82.692 (66.600)
2020-02-01 12:24:12, Epoch 30, Iteration 7, loss 0.005 (0.040), acc 100.000 (98.400)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-27.331612, 13.629291, -13.374444, 6.7073846, -51.99424, -24.384161, 32.935825, -37.209446, 31.030201, -23.766527], Poisons' Predictions:[8, 8, 6, 8, 8]
2020-02-01 12:24:13 Epoch 59, Val iteration 0, acc 93.200 (93.200)
2020-02-01 12:24:17 Epoch 59, Val iteration 19, acc 92.800 (92.450)
* Prec: 92.45000114440919
--------
GoogLeNet
Using Adam for retraining
Files already downloaded and verified
2020-02-01 12:24:20, Epoch 0, Iteration 7, loss 0.289 (0.347), acc 90.385 (90.000)
2020-02-01 12:24:20, Epoch 30, Iteration 7, loss 0.012 (0.099), acc 100.000 (97.200)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-22.42079, -7.0594015, -4.051339, 1.2554857, -11.936842, -2.711044, 13.6301365, -4.4937353, 9.903399, -24.36632], Poisons' Predictions:[6, 8, 8, 8, 8]
2020-02-01 12:24:23 Epoch 59, Val iteration 0, acc 91.200 (91.200)
2020-02-01 12:24:28 Epoch 59, Val iteration 19, acc 91.800 (91.450)
* Prec: 91.45000190734864
--------
MobileNetV2
Using Adam for retraining
Files already downloaded and verified
2020-02-01 12:24:30, Epoch 0, Iteration 7, loss 0.865 (4.168), acc 78.846 (53.800)
2020-02-01 12:24:31, Epoch 30, Iteration 7, loss 0.087 (0.478), acc 98.077 (91.800)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[0.13226539, 0.8109457, 2.7157507, 16.952894, -1.4251075, -2.3436275, 28.445803, -20.945942, 22.143753, -11.779021], Poisons' Predictions:[8, 8, 6, 8, 8]
2020-02-01 12:24:31 Epoch 59, Val iteration 0, acc 88.800 (88.800)
2020-02-01 12:24:34 Epoch 59, Val iteration 19, acc 87.400 (86.840)
* Prec: 86.84000167846679
--------
ResNet18
Using Adam for retraining
Files already downloaded and verified
2020-02-01 12:24:36, Epoch 0, Iteration 7, loss 0.484 (0.705), acc 90.385 (87.600)
2020-02-01 12:24:36, Epoch 30, Iteration 7, loss 0.001 (0.045), acc 100.000 (98.800)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-32.20784, -1.3437006, -12.564393, 6.708954, -28.115238, -3.8628218, 15.095307, -15.7308035, 13.309546, -25.362305], Poisons' Predictions:[6, 8, 8, 6, 6]
2020-02-01 12:24:37 Epoch 59, Val iteration 0, acc 93.800 (93.800)
2020-02-01 12:24:39 Epoch 59, Val iteration 19, acc 94.200 (92.620)
* Prec: 92.6200023651123
--------
DenseNet121
Using Adam for retraining
Files already downloaded and verified
2020-02-01 12:24:42, Epoch 0, Iteration 7, loss 0.284 (0.386), acc 90.385 (90.800)
2020-02-01 12:24:42, Epoch 30, Iteration 7, loss 0.007 (0.008), acc 100.000 (100.000)
Target Label: 6, Poison label: 8, Prediction:6, Target's Score:[-15.767703, -12.599068, -20.037413, -2.567452, -6.2658815, -5.9912252, 6.6192937, -32.520123, 6.420059, -16.342249], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-02-01 12:24:44 Epoch 59, Val iteration 0, acc 93.600 (93.600)
2020-02-01 12:24:49 Epoch 59, Val iteration 19, acc 93.400 (92.850)
* Prec: 92.85000038146973
--------
------SUMMARY------
TIME ELAPSED (mins): 141
TARGET INDEX: 17
DPN92 0
SENet18 0
ResNet50 0
ResNeXt29_2x64d 0
GoogLeNet 0
MobileNetV2 0
ResNet18 0
DenseNet121 0
