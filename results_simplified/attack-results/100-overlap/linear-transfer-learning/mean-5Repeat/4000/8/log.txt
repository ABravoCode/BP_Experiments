Namespace(chk_path='chk-black-ourmean/', chk_subdir='poisons', device='cuda', dset_path='datasets', end2end=False, eval_poison_path='', gpu='0', lr_decay_epoch=[30, 45], mode='mean', model_resume_path='model-chks', nearest=False, net_repeat=5, num_per_class=50, original_grad=True, poison_decay_ites=[], poison_decay_ratio=0.1, poison_epsilon=0.1, poison_ites=4000, poison_label=8, poison_lr=0.04, poison_momentum=0.9, poison_num=5, poison_opt='adam', resume_poison_ite=0, retrain_bsize=64, retrain_epochs=60, retrain_lr=0.1, retrain_momentum=0.9, retrain_opt='adam', retrain_wd=0, subs_chk_name=['ckpt-%s-4800-dp0.200-droplayer0.000-seed1226.t7', 'ckpt-%s-4800-dp0.250-droplayer0.000-seed1226.t7', 'ckpt-%s-4800-dp0.300-droplayer0.000.t7'], subs_dp=[0.2, 0.25, 0.3], subset_group=0, substitute_nets=['DPN92', 'SENet18', 'ResNet50', 'ResNeXt29_2x64d', 'GoogLeNet', 'MobileNetV2'], target_index=8, target_label=6, target_net=['DPN92', 'SENet18', 'ResNet50', 'ResNeXt29_2x64d', 'GoogLeNet', 'MobileNetV2', 'ResNet18', 'DenseNet121'], test_chk_name='ckpt-%s-4800.t7', tol=1e-06, train_data_path='datasets/CIFAR10_TRAIN_Split.pth')
Path: chk-black-ourmean/mean-5Repeat/4000/8
Selected base image indices: [213, 225, 227, 247, 249]
 2020-02-01 05:16:38 Iteration 0 	 Training Loss: 1.013e+00 	 Loss in Target Net: 3.606e-01	  
 2020-02-01 05:18:34 Iteration 50 	 Training Loss: 8.321e-02 	 Loss in Target Net: 1.086e-02	  
 2020-02-01 05:20:29 Iteration 100 	 Training Loss: 6.625e-02 	 Loss in Target Net: 5.631e-03	  
 2020-02-01 05:22:23 Iteration 150 	 Training Loss: 6.029e-02 	 Loss in Target Net: 9.360e-03	  
 2020-02-01 05:24:16 Iteration 200 	 Training Loss: 6.634e-02 	 Loss in Target Net: 9.268e-03	  
 2020-02-01 05:26:11 Iteration 250 	 Training Loss: 5.773e-02 	 Loss in Target Net: 1.092e-02	  
 2020-02-01 05:28:04 Iteration 300 	 Training Loss: 6.021e-02 	 Loss in Target Net: 7.866e-03	  
 2020-02-01 05:29:50 Iteration 350 	 Training Loss: 5.795e-02 	 Loss in Target Net: 7.921e-03	  
 2020-02-01 05:31:37 Iteration 400 	 Training Loss: 5.957e-02 	 Loss in Target Net: 7.349e-03	  
 2020-02-01 05:33:19 Iteration 450 	 Training Loss: 5.592e-02 	 Loss in Target Net: 9.851e-03	  
 2020-02-01 05:35:02 Iteration 500 	 Training Loss: 5.982e-02 	 Loss in Target Net: 5.016e-03	  
 2020-02-01 05:36:45 Iteration 550 	 Training Loss: 5.620e-02 	 Loss in Target Net: 6.435e-03	  
 2020-02-01 05:38:27 Iteration 600 	 Training Loss: 5.611e-02 	 Loss in Target Net: 1.168e-02	  
 2020-02-01 05:40:10 Iteration 650 	 Training Loss: 5.142e-02 	 Loss in Target Net: 1.257e-02	  
 2020-02-01 05:41:53 Iteration 700 	 Training Loss: 5.589e-02 	 Loss in Target Net: 1.036e-02	  
 2020-02-01 05:43:38 Iteration 750 	 Training Loss: 5.607e-02 	 Loss in Target Net: 9.999e-03	  
 2020-02-01 05:45:23 Iteration 800 	 Training Loss: 5.538e-02 	 Loss in Target Net: 1.377e-02	  
 2020-02-01 05:47:08 Iteration 850 	 Training Loss: 5.882e-02 	 Loss in Target Net: 1.057e-02	  
 2020-02-01 05:48:53 Iteration 900 	 Training Loss: 5.327e-02 	 Loss in Target Net: 8.934e-03	  
 2020-02-01 05:50:37 Iteration 950 	 Training Loss: 5.408e-02 	 Loss in Target Net: 6.181e-03	  
 2020-02-01 05:52:22 Iteration 1000 	 Training Loss: 5.486e-02 	 Loss in Target Net: 4.055e-03	  
 2020-02-01 05:54:07 Iteration 1050 	 Training Loss: 5.551e-02 	 Loss in Target Net: 1.080e-02	  
 2020-02-01 05:55:52 Iteration 1100 	 Training Loss: 5.304e-02 	 Loss in Target Net: 9.520e-03	  
 2020-02-01 05:57:37 Iteration 1150 	 Training Loss: 6.095e-02 	 Loss in Target Net: 1.150e-02	  
 2020-02-01 05:59:22 Iteration 1200 	 Training Loss: 5.284e-02 	 Loss in Target Net: 5.544e-03	  
 2020-02-01 06:01:06 Iteration 1250 	 Training Loss: 5.474e-02 	 Loss in Target Net: 7.894e-03	  
 2020-02-01 06:02:52 Iteration 1300 	 Training Loss: 5.357e-02 	 Loss in Target Net: 9.319e-03	  
 2020-02-01 06:04:37 Iteration 1350 	 Training Loss: 5.317e-02 	 Loss in Target Net: 9.155e-03	  
 2020-02-01 06:06:22 Iteration 1400 	 Training Loss: 5.446e-02 	 Loss in Target Net: 1.135e-02	  
 2020-02-01 06:08:07 Iteration 1450 	 Training Loss: 5.554e-02 	 Loss in Target Net: 7.811e-03	  
 2020-02-01 06:09:52 Iteration 1500 	 Training Loss: 5.606e-02 	 Loss in Target Net: 6.894e-03	  
 2020-02-01 06:11:37 Iteration 1550 	 Training Loss: 5.370e-02 	 Loss in Target Net: 8.888e-03	  
 2020-02-01 06:13:22 Iteration 1600 	 Training Loss: 5.681e-02 	 Loss in Target Net: 7.830e-03	  
 2020-02-01 06:15:07 Iteration 1650 	 Training Loss: 5.417e-02 	 Loss in Target Net: 8.662e-03	  
 2020-02-01 06:16:51 Iteration 1700 	 Training Loss: 5.276e-02 	 Loss in Target Net: 6.897e-03	  
 2020-02-01 06:18:33 Iteration 1750 	 Training Loss: 5.388e-02 	 Loss in Target Net: 4.825e-03	  
 2020-02-01 06:20:17 Iteration 1800 	 Training Loss: 5.357e-02 	 Loss in Target Net: 5.600e-03	  
 2020-02-01 06:22:00 Iteration 1850 	 Training Loss: 5.489e-02 	 Loss in Target Net: 8.208e-03	  
 2020-02-01 06:23:42 Iteration 1900 	 Training Loss: 5.235e-02 	 Loss in Target Net: 6.402e-03	  
 2020-02-01 06:25:24 Iteration 1950 	 Training Loss: 5.584e-02 	 Loss in Target Net: 8.985e-03	  
 2020-02-01 06:27:07 Iteration 2000 	 Training Loss: 5.610e-02 	 Loss in Target Net: 5.211e-03	  
 2020-02-01 06:28:49 Iteration 2050 	 Training Loss: 5.372e-02 	 Loss in Target Net: 1.126e-02	  
 2020-02-01 06:30:32 Iteration 2100 	 Training Loss: 5.339e-02 	 Loss in Target Net: 7.597e-03	  
 2020-02-01 06:32:14 Iteration 2150 	 Training Loss: 5.040e-02 	 Loss in Target Net: 6.687e-03	  
 2020-02-01 06:33:56 Iteration 2200 	 Training Loss: 5.456e-02 	 Loss in Target Net: 7.961e-03	  
 2020-02-01 06:35:40 Iteration 2250 	 Training Loss: 5.286e-02 	 Loss in Target Net: 8.104e-03	  
 2020-02-01 06:37:23 Iteration 2300 	 Training Loss: 5.460e-02 	 Loss in Target Net: 6.168e-03	  
 2020-02-01 06:39:06 Iteration 2350 	 Training Loss: 5.115e-02 	 Loss in Target Net: 5.753e-03	  
 2020-02-01 06:40:49 Iteration 2400 	 Training Loss: 5.176e-02 	 Loss in Target Net: 4.576e-03	  
 2020-02-01 06:42:31 Iteration 2450 	 Training Loss: 5.330e-02 	 Loss in Target Net: 6.201e-03	  
 2020-02-01 06:44:13 Iteration 2500 	 Training Loss: 5.769e-02 	 Loss in Target Net: 5.420e-03	  
 2020-02-01 06:45:55 Iteration 2550 	 Training Loss: 5.289e-02 	 Loss in Target Net: 8.167e-03	  
 2020-02-01 06:47:37 Iteration 2600 	 Training Loss: 5.309e-02 	 Loss in Target Net: 5.720e-03	  
 2020-02-01 06:49:19 Iteration 2650 	 Training Loss: 5.150e-02 	 Loss in Target Net: 5.905e-03	  
 2020-02-01 06:51:02 Iteration 2700 	 Training Loss: 5.265e-02 	 Loss in Target Net: 6.349e-03	  
 2020-02-01 06:52:45 Iteration 2750 	 Training Loss: 5.300e-02 	 Loss in Target Net: 5.976e-03	  
 2020-02-01 06:54:28 Iteration 2800 	 Training Loss: 5.335e-02 	 Loss in Target Net: 7.181e-03	  
 2020-02-01 06:56:10 Iteration 2850 	 Training Loss: 5.281e-02 	 Loss in Target Net: 8.178e-03	  
 2020-02-01 06:57:52 Iteration 2900 	 Training Loss: 5.315e-02 	 Loss in Target Net: 5.593e-03	  
 2020-02-01 06:59:35 Iteration 2950 	 Training Loss: 5.515e-02 	 Loss in Target Net: 5.227e-03	  
 2020-02-01 07:01:17 Iteration 3000 	 Training Loss: 5.594e-02 	 Loss in Target Net: 6.080e-03	  
 2020-02-01 07:02:59 Iteration 3050 	 Training Loss: 5.126e-02 	 Loss in Target Net: 4.328e-03	  
 2020-02-01 07:04:42 Iteration 3100 	 Training Loss: 5.009e-02 	 Loss in Target Net: 5.444e-03	  
 2020-02-01 07:06:27 Iteration 3150 	 Training Loss: 5.384e-02 	 Loss in Target Net: 6.190e-03	  
 2020-02-01 07:08:12 Iteration 3200 	 Training Loss: 5.020e-02 	 Loss in Target Net: 5.026e-03	  
 2020-02-01 07:09:57 Iteration 3250 	 Training Loss: 5.578e-02 	 Loss in Target Net: 4.529e-03	  
 2020-02-01 07:11:42 Iteration 3300 	 Training Loss: 5.016e-02 	 Loss in Target Net: 4.680e-03	  
 2020-02-01 07:13:27 Iteration 3350 	 Training Loss: 5.208e-02 	 Loss in Target Net: 5.025e-03	  
 2020-02-01 07:15:11 Iteration 3400 	 Training Loss: 5.063e-02 	 Loss in Target Net: 4.464e-03	  
 2020-02-01 07:16:56 Iteration 3450 	 Training Loss: 5.208e-02 	 Loss in Target Net: 4.370e-03	  
 2020-02-01 07:18:41 Iteration 3500 	 Training Loss: 5.151e-02 	 Loss in Target Net: 3.766e-03	  
 2020-02-01 07:20:26 Iteration 3550 	 Training Loss: 5.288e-02 	 Loss in Target Net: 4.190e-03	  
 2020-02-01 07:22:11 Iteration 3600 	 Training Loss: 5.116e-02 	 Loss in Target Net: 6.114e-03	  
 2020-02-01 07:23:56 Iteration 3650 	 Training Loss: 5.507e-02 	 Loss in Target Net: 3.618e-03	  
 2020-02-01 07:25:41 Iteration 3700 	 Training Loss: 5.250e-02 	 Loss in Target Net: 3.905e-03	  
 2020-02-01 07:27:26 Iteration 3750 	 Training Loss: 5.427e-02 	 Loss in Target Net: 4.368e-03	  
 2020-02-01 07:29:12 Iteration 3800 	 Training Loss: 5.430e-02 	 Loss in Target Net: 4.718e-03	  
 2020-02-01 07:30:57 Iteration 3850 	 Training Loss: 5.131e-02 	 Loss in Target Net: 7.064e-03	  
 2020-02-01 07:32:42 Iteration 3900 	 Training Loss: 5.329e-02 	 Loss in Target Net: 5.926e-03	  
 2020-02-01 07:34:26 Iteration 3950 	 Training Loss: 4.998e-02 	 Loss in Target Net: 5.074e-03	  
 2020-02-01 07:36:19 Iteration 3999 	 Training Loss: 5.086e-02 	 Loss in Target Net: 5.528e-03	  
Evaluating against victims networks
DPN92
Using Adam for retraining
Files already downloaded and verified
2020-02-01 07:36:24, Epoch 0, Iteration 7, loss 2.252 (4.365), acc 80.769 (62.400)
2020-02-01 07:36:24, Epoch 30, Iteration 7, loss 0.000 (0.086), acc 100.000 (98.600)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[16.498968, -9.198847, -40.83475, 7.664541, -4.0282, -0.24633911, 25.577799, -28.173464, 49.242664, -59.40921], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-02-01 07:36:29 Epoch 59, Val iteration 0, acc 91.400 (91.400)
2020-02-01 07:36:37 Epoch 59, Val iteration 19, acc 92.400 (92.370)
* Prec: 92.37000160217285
--------
SENet18
Using Adam for retraining
Files already downloaded and verified
2020-02-01 07:36:39, Epoch 0, Iteration 7, loss 0.850 (0.667), acc 86.538 (87.200)
2020-02-01 07:36:40, Epoch 30, Iteration 7, loss 0.464 (0.115), acc 94.231 (96.600)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[13.643113, -13.728445, -8.527318, -0.1959523, 7.205143, -4.781525, 22.357054, -20.992638, 31.144575, -17.341156], Poisons' Predictions:[8, 6, 8, 8, 8]
2020-02-01 07:36:40 Epoch 59, Val iteration 0, acc 91.400 (91.400)
2020-02-01 07:36:42 Epoch 59, Val iteration 19, acc 93.000 (90.970)
* Prec: 90.97000160217286
--------
ResNet50
Using Adam for retraining
Files already downloaded and verified
2020-02-01 07:36:45, Epoch 0, Iteration 7, loss 0.000 (1.349), acc 100.000 (89.600)
2020-02-01 07:36:45, Epoch 30, Iteration 7, loss 0.000 (0.000), acc 100.000 (100.000)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-50.276016, -60.74656, -92.06487, -69.98352, -33.888176, -57.231464, 23.536732, -29.797342, 32.90415, -84.402725], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-02-01 07:36:47 Epoch 59, Val iteration 0, acc 92.800 (92.800)
2020-02-01 07:36:51 Epoch 59, Val iteration 19, acc 92.600 (92.420)
* Prec: 92.4200008392334
--------
ResNeXt29_2x64d
Using Adam for retraining
Files already downloaded and verified
2020-02-01 07:36:53, Epoch 0, Iteration 7, loss 1.709 (3.092), acc 76.923 (66.000)
2020-02-01 07:36:53, Epoch 30, Iteration 7, loss 0.001 (0.016), acc 100.000 (99.000)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-8.188966, -10.720474, -10.551718, 1.8316267, -65.75044, -17.48962, 11.749259, -27.354454, 22.30871, -20.888348], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-02-01 07:36:55 Epoch 59, Val iteration 0, acc 93.400 (93.400)
2020-02-01 07:36:59 Epoch 59, Val iteration 19, acc 92.800 (93.060)
* Prec: 93.06000175476075
--------
GoogLeNet
Using Adam for retraining
Files already downloaded and verified
2020-02-01 07:37:02, Epoch 0, Iteration 7, loss 0.782 (0.370), acc 86.538 (92.200)
2020-02-01 07:37:02, Epoch 30, Iteration 7, loss 0.054 (0.057), acc 98.077 (97.400)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-14.6233635, -7.643987, -9.776244, 0.69050527, -9.574038, -5.8262014, 5.4640665, -9.393466, 10.090487, -16.100817], Poisons' Predictions:[8, 8, 6, 8, 8]
2020-02-01 07:37:05 Epoch 59, Val iteration 0, acc 91.600 (91.600)
2020-02-01 07:37:10 Epoch 59, Val iteration 19, acc 90.800 (92.010)
* Prec: 92.01000137329102
--------
MobileNetV2
Using Adam for retraining
Files already downloaded and verified
2020-02-01 07:37:12, Epoch 0, Iteration 7, loss 0.808 (3.962), acc 82.692 (57.400)
2020-02-01 07:37:12, Epoch 30, Iteration 7, loss 0.234 (0.226), acc 94.231 (94.400)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[7.405408, -15.849937, -7.952978, 10.016707, -37.476643, -3.1153233, 13.568156, -29.794333, 19.047815, -1.6945155], Poisons' Predictions:[8, 8, 8, 8, 6]
2020-02-01 07:37:13 Epoch 59, Val iteration 0, acc 88.200 (88.200)
2020-02-01 07:37:15 Epoch 59, Val iteration 19, acc 88.400 (86.610)
* Prec: 86.61000175476075
--------
ResNet18
Using Adam for retraining
Files already downloaded and verified
2020-02-01 07:37:17, Epoch 0, Iteration 7, loss 0.230 (0.465), acc 94.231 (89.800)
2020-02-01 07:37:17, Epoch 30, Iteration 7, loss 0.024 (0.015), acc 98.077 (99.200)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-26.587519, -27.300459, -8.903406, -1.1211605, -31.014519, -3.272805, 10.295412, -20.025896, 14.2313, -34.175323], Poisons' Predictions:[8, 6, 8, 8, 8]
2020-02-01 07:37:18 Epoch 59, Val iteration 0, acc 93.000 (93.000)
2020-02-01 07:37:20 Epoch 59, Val iteration 19, acc 93.200 (92.560)
* Prec: 92.56000175476075
--------
DenseNet121
Using Adam for retraining
Files already downloaded and verified
2020-02-01 07:37:22, Epoch 0, Iteration 7, loss 0.560 (0.430), acc 90.385 (92.600)
2020-02-01 07:37:23, Epoch 30, Iteration 7, loss 0.002 (0.002), acc 100.000 (100.000)
Target Label: 6, Poison label: 8, Prediction:8, Target's Score:[-11.655399, -19.930166, -14.510139, -3.3020248, -11.101987, -5.0120683, 5.5164857, -36.875717, 6.8318925, -12.88352], Poisons' Predictions:[8, 8, 8, 8, 8]
2020-02-01 07:37:25 Epoch 59, Val iteration 0, acc 93.000 (93.000)
2020-02-01 07:37:29 Epoch 59, Val iteration 19, acc 93.800 (93.100)
* Prec: 93.10000228881836
--------
------SUMMARY------
TIME ELAPSED (mins): 139
TARGET INDEX: 8
DPN92 1
SENet18 1
ResNet50 1
ResNeXt29_2x64d 1
GoogLeNet 1
MobileNetV2 1
ResNet18 1
DenseNet121 1
